{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.nn.functional import InterpolationMode\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging \n",
    "import datetime\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_df_path = \"data_validation/processed_gloss.csv\"\n",
    "gloss_df = pd.read_csv(gloss_df_path)\n",
    "gloss_df.dropna(inplace=True)\n",
    "gloss_df.replace(to_replace=\"ASHAG\", value=\"AŞAĞI\", inplace=True)\n",
    "gloss_df['glossRange'] = gloss_df['glossEnd'] - gloss_df['glossStart']\n",
    "# gloss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(gloss_df.gloss.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler\n",
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorchvideo.data import labeled_video_dataset\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomAdjustSharpness,\n",
    "    Resize\n",
    ")\n",
    "\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transform = Compose([\n",
    "    ApplyTransformToKey(key=\"video\",\n",
    "    transform=Compose([\n",
    "        UniformTemporalSubsample(25),\n",
    "        Lambda(lambda x: x/255),\n",
    "        Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "        RandomShortSideScale(min_size=224, max_size=256),\n",
    "        CenterCropVideo(224),\n",
    "    ]),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/toghrul/SLR/data/train\"\n",
    "val_path = \"/home/toghrul/SLR/data/val\"\n",
    "test_path = \"/home/toghrul/SLR/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "video_model = torch.hub.load('facebookresearch/pytorchvideo', 'efficient_x3d_xs', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randn(size=(8, num_classes)).requires_grad_()\n",
    "# b = torch.randint(5, size=(8, ), dtype=torch.long)\n",
    "# a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = F.one_hot(b, num_classes=num_classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(input, target)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoModel(LightningModule):\n",
    "    def __init__(self, ):\n",
    "        super(VideoModel, self).__init__()\n",
    "\n",
    "        self.video_model = torch.hub.load('facebookresearch/pytorchvideo', 'efficient_x3d_xs', pretrained=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(400, num_classes)\n",
    "\n",
    "        self.lr = 1e-1\n",
    "        self.batch_size = 8\n",
    "        self.num_worker = 4\n",
    "        self.num_steps_train = 0\n",
    "        self.num_steps_val = 0\n",
    "\n",
    "        self.metric = torchmetrics.classification.MultilabelAccuracy(num_labels=num_classes)\n",
    "\n",
    "        #loss\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.video_model(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(params=self.parameters(), lr = self.lr)\n",
    "        scheduler = ReduceLROnPlateau(opt, mode=\"max\", factor=0.05, patience=2, min_lr=1e-6)\n",
    "        # scheduler = CosineAnnealingLR(opt, T_max=10, eta_min=1e-6, last_epoch=-1)\n",
    "        return {'optimizer': opt,\n",
    "                'lr_scheduler': scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = labeled_video_dataset(train_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self(video)\n",
    "        print(f\">>> Training step No.{self.num_steps_train}:\")\n",
    "        # print(\"Pred:\", out)\n",
    "        # print(\"GT:\", label)\n",
    "        # print(f\"Pred:\\n{out}\")\n",
    "        # print(f\"Pred shape:\\n{out.shape}\")\n",
    "        # print(f\"Label:\\n{label}\")\n",
    "        # print(f\"Label shape:\\n{label.shape}\")\n",
    "        # print(\">>> INFO: Computing Training Loss\")\n",
    "        loss = self.criterion(out, label)\n",
    "        print(f\"Loss: {loss}\")\n",
    "        self.num_steps_train += 1\n",
    "        # print(\">>> INFO: Training Loss Computed\")\n",
    "        # print(\">>> INFO: Computing Training Metric\")\n",
    "        metric = self.metric(out, label)\n",
    "        print(f\"Accuracy: {metric}\")\n",
    "\n",
    "        values = {\"loss\": loss,\n",
    "                \"metric\": metric.detach()}\n",
    "        \n",
    "        self.log_dict({\"step_loss\": loss,\n",
    "                        \"step_metric\": metric.detach()})\n",
    "        \n",
    "        return values\n",
    "        \n",
    "        # return {\"loss\": loss}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        \n",
    "        self.log('training_loss', loss)\n",
    "        print(f\">>> Epoch end loss: {loss}\")\n",
    "        self.log('training_metric', metric)\n",
    "        \n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = labeled_video_dataset(val_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self(video)\n",
    "        # print(\">>> INFO: Computing Val Loss\")\n",
    "        print(f\">>> Validation step No.{self.num_steps_val}:\")\n",
    "        loss = self.criterion(out, label)\n",
    "        print(f\"Loss: {loss}\")\n",
    "        self.num_steps_val += 1\n",
    "        # print(\">>> INFO: Val Loss Computed\")\n",
    "        # print(\">>> INFO: Computing Val Metric\")\n",
    "        metric = self.metric(out, label)\n",
    "        print(f\"Accuracy: {metric}\")\n",
    "        \n",
    "\n",
    "        return {\"loss\": loss,\n",
    "                \"metric\": metric.detach()}\n",
    "        \n",
    "        # return {\"loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_metric', metric)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = labeled_video_dataset(test_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self.forward(video)\n",
    "        metric = self.metric(out, label)\n",
    "\n",
    "        return {\"label\": label,\n",
    "                \"pred\": out.detach(),}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        label=torch.cat([x['label'] for x in outputs]).cpu().numpy()\n",
    "        pred = torch.cat([x['pred'] for x in outputs]).cpu().numpy()\n",
    "        # self.log('test_loss', loss)\n",
    "        # self.log('test_metric', metric)\n",
    "        class_labels = label.argmax(axis=1)\n",
    "        class_pred = pred.argmax(axis=1)\n",
    "        print(f\">> Label: {class_labels}\\nPred: {class_pred}\")\n",
    "        \n",
    "        return {\"prediction\": class_pred,\n",
    "                \"labels\": class_labels}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath=\"checkpoints\", \n",
    "                                    verbose=True, save_last=True, save_top_k=2)\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "Global seed set to 0\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel()\n",
    "seed_everything(0)\n",
    "\n",
    "trainer = Trainer(max_epochs=15,\n",
    "                accelerator=\"gpu\", devices=-1,\n",
    "                precision=16,\n",
    "                # accumulate_grad_batches=2,\n",
    "                enable_progress_bar=True,\n",
    "                # num_sanity_val_steps=0,\n",
    "                callbacks=[lr_monitor, checkpoint_callback],\n",
    "                log_every_n_steps=5,\n",
    "                limit_train_batches=25,\n",
    "                limit_val_batches=10,\n",
    "                limit_test_batches=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/toghrul/SLR/sign-lang/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | video_model | EfficientX3d       | 3.8 M \n",
      "1 | relu        | ReLU               | 0     \n",
      "2 | fc          | Linear             | 93.8 K\n",
      "3 | metric      | MultilabelAccuracy | 0     \n",
      "4 | criterion   | BCEWithLogitsLoss  | 0     \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "7.776     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a686fe7d07a4b87b608c605b4396d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.0:\n",
      "Loss: 0.780345618724823\n",
      "Accuracy: 0.4967949390411377\n",
      ">>> Validation step No.1:\n",
      "Loss: 0.7818716168403625\n",
      "Accuracy: 0.4978632926940918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00251503d3e54b3faf5c860520d969de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training step No.0:\n",
      "Loss: 0.7260846495628357\n",
      "Accuracy: 0.5080128312110901\n",
      ">>> Training step No.1:\n",
      "Loss: 17.298078536987305\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.2:\n",
      "Loss: 15.163996696472168\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.3:\n",
      "Loss: 16.778846740722656\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.4:\n",
      "Loss: 17.770299911499023\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.5:\n",
      "Loss: 18.096155166625977\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.6:\n",
      "Loss: 0.20587994158267975\n",
      "Accuracy: 0.9396368265151978\n",
      ">>> Training step No.7:\n",
      "Loss: 0.18232017755508423\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.8:\n",
      "Loss: 0.05963601544499397\n",
      "Accuracy: 0.9941239953041077\n",
      ">>> Training step No.9:\n",
      "Loss: 0.5338335037231445\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.10:\n",
      "Loss: 0.07731971144676208\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.11:\n",
      "Loss: 0.1022660955786705\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.12:\n",
      "Loss: 0.14754699170589447\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.13:\n",
      "Loss: 0.18111473321914673\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.14:\n",
      "Loss: 0.1756041944026947\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.15:\n",
      "Loss: 0.22463025152683258\n",
      "Accuracy: 0.9877137541770935\n",
      ">>> Training step No.16:\n",
      "Loss: 0.21345040202140808\n",
      "Accuracy: 0.9909188151359558\n",
      ">>> Training step No.17:\n",
      "Loss: 0.12687340378761292\n",
      "Accuracy: 0.9941239356994629\n",
      ">>> Training step No.18:\n",
      "Loss: 0.1020665317773819\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.19:\n",
      "Loss: 0.05515942722558975\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.20:\n",
      "Loss: 0.08065344393253326\n",
      "Accuracy: 0.9941239356994629\n",
      ">>> Training step No.21:\n",
      "Loss: 0.06338087469339371\n",
      "Accuracy: 0.9941239356994629\n",
      ">>> Training step No.22:\n",
      "Loss: 0.13552793860435486\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.23:\n",
      "Loss: 0.09505047649145126\n",
      "Accuracy: 0.9941239953041077\n",
      ">>> Training step No.24:\n",
      "Loss: 0.09338376671075821\n",
      "Accuracy: 0.9919872283935547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b87f68a36244a7f9557aa3ac7574483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.2:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.3:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.4:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.5:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.6:\n",
      "Loss: nan\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.7:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.8:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.9:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.10:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 25: 'val_loss' reached inf (best inf), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=0-step=25.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.11:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Epoch end loss: 3.549999952316284\n",
      ">>> Training step No.25:\n",
      "Loss: 0.08719785511493683\n",
      "Accuracy: 0.9946581125259399\n",
      ">>> Training step No.26:\n",
      "Loss: 0.08570262044668198\n",
      "Accuracy: 0.9946581125259399\n",
      ">>> Training step No.27:\n",
      "Loss: 0.06835073232650757\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.28:\n",
      "Loss: 0.03951725363731384\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.29:\n",
      "Loss: 0.07398799806833267\n",
      "Accuracy: 0.9951924085617065\n",
      ">>> Training step No.30:\n",
      "Loss: 0.05794275179505348\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.31:\n",
      "Loss: 0.04270576685667038\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.32:\n",
      "Loss: 0.09394583851099014\n",
      "Accuracy: 0.9919871687889099\n",
      ">>> Training step No.33:\n",
      "Loss: 0.030971430242061615\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.34:\n",
      "Loss: 0.06777947396039963\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.35:\n",
      "Loss: 0.06998925656080246\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.36:\n",
      "Loss: 0.06986986100673676\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.37:\n",
      "Loss: 0.07195337861776352\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.38:\n",
      "Loss: 0.07996384799480438\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.39:\n",
      "Loss: 0.07011321187019348\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.40:\n",
      "Loss: 0.06205897033214569\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.41:\n",
      "Loss: 0.06293787062168121\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.42:\n",
      "Loss: 0.03249529004096985\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.43:\n",
      "Loss: 0.09580551832914352\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.44:\n",
      "Loss: 0.07523075491189957\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.45:\n",
      "Loss: 0.06190852075815201\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.46:\n",
      "Loss: 0.06319227814674377\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.47:\n",
      "Loss: 0.025779077783226967\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.48:\n",
      "Loss: 0.08292151242494583\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.49:\n",
      "Loss: 0.06220844015479088\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8cb9c113344079880ba98147295bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.12:\n",
      "Loss: 0.11127234250307083\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.13:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.14:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.15:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.16:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.17:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.18:\n",
      "Loss: 0.1226559579372406\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.19:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.20:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 50: 'val_loss' reached inf (best inf), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=1-step=50.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.21:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.07000000029802322\n",
      ">>> Training step No.50:\n",
      "Loss: 0.11299194395542145\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.51:\n",
      "Loss: 0.10063796490430832\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.52:\n",
      "Loss: 0.08851438015699387\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.53:\n",
      "Loss: 0.08000265061855316\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.54:\n",
      "Loss: 0.07261714339256287\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.55:\n",
      "Loss: 0.05522032454609871\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.56:\n",
      "Loss: 0.0566275529563427\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.57:\n",
      "Loss: 0.04784576594829559\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.58:\n",
      "Loss: 0.08608642220497131\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.59:\n",
      "Loss: 0.07049043476581573\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.60:\n",
      "Loss: 0.04874521121382713\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.61:\n",
      "Loss: 0.047390833497047424\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.62:\n",
      "Loss: 0.06719891726970673\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.63:\n",
      "Loss: 0.06409692019224167\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.64:\n",
      "Loss: 0.04978109151124954\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.65:\n",
      "Loss: 0.04843682423233986\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.66:\n",
      "Loss: 0.0729624330997467\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.67:\n",
      "Loss: 0.04077357053756714\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.68:\n",
      "Loss: 0.052128762006759644\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.69:\n",
      "Loss: 0.04623953253030777\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.70:\n",
      "Loss: 0.05265439674258232\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.71:\n",
      "Loss: 0.04533620551228523\n",
      "Accuracy: 0.995192289352417\n",
      ">>> Training step No.72:\n",
      "Loss: 0.04044651240110397\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.73:\n",
      "Loss: 0.05019165202975273\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.74:\n",
      "Loss: 0.0484684482216835\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605777e46ef34a61a59854066306afec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.22:\n",
      "Loss: 0.05909876152873039\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.23:\n",
      "Loss: 0.07054317742586136\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.24:\n",
      "Loss: 0.0722387433052063\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.25:\n",
      "Loss: 0.06143872067332268\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.26:\n",
      "Loss: 0.0544322207570076\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.27:\n",
      "Loss: 0.06278114765882492\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.28:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.29:\n",
      "Loss: 0.058759041130542755\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 75: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.30:\n",
      "Loss: 0.052642617374658585\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.31:\n",
      "Loss: 0.06395786255598068\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Epoch end loss: 0.05999999865889549\n",
      ">>> Training step No.75:\n",
      "Loss: 0.04340694099664688\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.76:\n",
      "Loss: 0.04616884887218475\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.77:\n",
      "Loss: 0.04120767489075661\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.78:\n",
      "Loss: 0.05147215351462364\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.79:\n",
      "Loss: 0.047493889927864075\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.80:\n",
      "Loss: 0.04737385734915733\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.81:\n",
      "Loss: 0.03760957717895508\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.82:\n",
      "Loss: 0.05100543424487114\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.83:\n",
      "Loss: 0.040514808148145676\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.84:\n",
      "Loss: 0.042950551956892014\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.85:\n",
      "Loss: 0.04070202261209488\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.86:\n",
      "Loss: 0.03988935053348541\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.87:\n",
      "Loss: 0.04873264953494072\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.88:\n",
      "Loss: 0.039475880563259125\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.89:\n",
      "Loss: 0.040740326046943665\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.90:\n",
      "Loss: 0.04873018339276314\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.91:\n",
      "Loss: 0.054738812148571014\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.92:\n",
      "Loss: 0.03360047563910484\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.93:\n",
      "Loss: 0.03606322780251503\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.94:\n",
      "Loss: 0.03959769383072853\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.95:\n",
      "Loss: 0.05107002332806587\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.96:\n",
      "Loss: 0.03701228275895119\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.97:\n",
      "Loss: 0.03850114718079567\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.98:\n",
      "Loss: 0.04911533743143082\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.99:\n",
      "Loss: 0.0493711493909359\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4290b95d0345adb24337431e035b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.32:\n",
      "Loss: 0.0435602106153965\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.33:\n",
      "Loss: 0.03590359911322594\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.34:\n",
      "Loss: 0.04152476787567139\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.35:\n",
      "Loss: 0.02902022935450077\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.36:\n",
      "Loss: 0.03242967650294304\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.37:\n",
      "Loss: 0.03318386524915695\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.38:\n",
      "Loss: 0.03331933170557022\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.39:\n",
      "Loss: 0.03661597520112991\n",
      "Accuracy: 0.995726466178894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 100: 'val_loss' reached 0.03000 (best 0.03000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=3-step=100.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.40:\n",
      "Loss: 0.03276558592915535\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.41:\n",
      "Loss: 0.03067222237586975\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.100:\n",
      "Loss: 0.03948822245001793\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.101:\n",
      "Loss: 0.044240303337574005\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.102:\n",
      "Loss: 0.04188461974263191\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.103:\n",
      "Loss: 0.045752234756946564\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.104:\n",
      "Loss: 0.038957107812166214\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.105:\n",
      "Loss: 0.050299301743507385\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.106:\n",
      "Loss: 0.0606098547577858\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.107:\n",
      "Loss: 0.027466731145977974\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.108:\n",
      "Loss: 0.04252275079488754\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.109:\n",
      "Loss: 0.04802075773477554\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.110:\n",
      "Loss: 0.05979094281792641\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.111:\n",
      "Loss: 0.03363785892724991\n",
      "Accuracy: 0.9935897588729858\n",
      ">>> Training step No.112:\n",
      "Loss: 0.03355187177658081\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.113:\n",
      "Loss: 0.03824203088879585\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.114:\n",
      "Loss: 0.054106052964925766\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.115:\n",
      "Loss: 0.0421799011528492\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.116:\n",
      "Loss: 0.03542458638548851\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.117:\n",
      "Loss: 0.03362767770886421\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.118:\n",
      "Loss: 0.03794761747121811\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.119:\n",
      "Loss: 0.040659595280885696\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.120:\n",
      "Loss: 0.03752779960632324\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.121:\n",
      "Loss: 0.03913601487874985\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.122:\n",
      "Loss: 0.04371519386768341\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.123:\n",
      "Loss: 0.039648205041885376\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.124:\n",
      "Loss: 0.04295989125967026\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8cc76e80e4412290d4ba21017d76c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.42:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.43:\n",
      "Loss: 0.03401276469230652\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.44:\n",
      "Loss: 0.041041553020477295\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.45:\n",
      "Loss: 0.03107324242591858\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.46:\n",
      "Loss: 0.0298679880797863\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.47:\n",
      "Loss: 0.033219609409570694\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.48:\n",
      "Loss: 0.03141753375530243\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.49:\n",
      "Loss: 0.02680155821144581\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 125: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.50:\n",
      "Loss: 0.041568003594875336\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.51:\n",
      "Loss: 0.031158724799752235\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.125:\n",
      "Loss: 0.03892538323998451\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.126:\n",
      "Loss: 0.039195381104946136\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.127:\n",
      "Loss: 0.03981209918856621\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.128:\n",
      "Loss: 0.037298399955034256\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.129:\n",
      "Loss: 0.03935471922159195\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.130:\n",
      "Loss: 0.038709528744220734\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.131:\n",
      "Loss: 0.03799859434366226\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.132:\n",
      "Loss: 0.03473443537950516\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.133:\n",
      "Loss: 0.033674292266368866\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.134:\n",
      "Loss: 0.038601845502853394\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.135:\n",
      "Loss: 0.04007929936051369\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.136:\n",
      "Loss: 0.04188389331102371\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.137:\n",
      "Loss: 0.041239310055971146\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.138:\n",
      "Loss: 0.034155864268541336\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.139:\n",
      "Loss: 0.04107952490448952\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.140:\n",
      "Loss: 0.03653119504451752\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.141:\n",
      "Loss: 0.03620690479874611\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.142:\n",
      "Loss: 0.03823824226856232\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.143:\n",
      "Loss: 0.03431254252791405\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.144:\n",
      "Loss: 0.03478655219078064\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.145:\n",
      "Loss: 0.035104721784591675\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.146:\n",
      "Loss: 0.03304561227560043\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.147:\n",
      "Loss: 0.03338409960269928\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.148:\n",
      "Loss: 0.0375455841422081\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.149:\n",
      "Loss: 0.042441848665475845\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b667b986f29e4769892bb055be54cbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.52:\n",
      "Loss: 0.030431125313043594\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.53:\n",
      "Loss: 0.028905201703310013\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.54:\n",
      "Loss: 0.029534071683883667\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.55:\n",
      "Loss: 0.03116505965590477\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.56:\n",
      "Loss: 0.03005978651344776\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.57:\n",
      "Loss: 0.030852185562253\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.58:\n",
      "Loss: 0.0305323489010334\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.59:\n",
      "Loss: 0.032511837780475616\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.60:\n",
      "Loss: 0.03113267384469509\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 150: 'val_loss' reached 0.03000 (best 0.03000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=5-step=150.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.61:\n",
      "Loss: 0.029177315533161163\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.150:\n",
      "Loss: 0.03550383076071739\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.151:\n",
      "Loss: 0.027441253885626793\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.152:\n",
      "Loss: 0.0563591793179512\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.153:\n",
      "Loss: 0.035529423505067825\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.154:\n",
      "Loss: 0.07210836559534073\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.155:\n",
      "Loss: 0.034472718834877014\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.156:\n",
      "Loss: 0.034188687801361084\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.157:\n",
      "Loss: 0.03820059075951576\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.158:\n",
      "Loss: 0.035591788589954376\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.159:\n",
      "Loss: 0.045197099447250366\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.160:\n",
      "Loss: 0.03094520792365074\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.161:\n",
      "Loss: 0.03825993835926056\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.162:\n",
      "Loss: 0.03753185272216797\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.163:\n",
      "Loss: 0.04081033542752266\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.164:\n",
      "Loss: 0.031318966299295425\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.165:\n",
      "Loss: 0.03424596041440964\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.166:\n",
      "Loss: 0.026094727218151093\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.167:\n",
      "Loss: 0.03593441843986511\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.168:\n",
      "Loss: 0.036257222294807434\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.169:\n",
      "Loss: 0.03737960383296013\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.170:\n",
      "Loss: 0.03797261416912079\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.171:\n",
      "Loss: 0.03119679167866707\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.172:\n",
      "Loss: 0.03255942836403847\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.173:\n",
      "Loss: 0.03531135246157646\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.174:\n",
      "Loss: 0.03393332660198212\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9831e74c804a3d914e48ad7b35f837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.62:\n",
      "Loss: 0.03361805900931358\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.63:\n",
      "Loss: 0.027283303439617157\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.64:\n",
      "Loss: 0.0336541123688221\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.65:\n",
      "Loss: 0.0317046158015728\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.66:\n",
      "Loss: 0.03157265484333038\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.67:\n",
      "Loss: 0.030622415244579315\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.68:\n",
      "Loss: 0.030864914879202843\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.69:\n",
      "Loss: 0.031935323029756546\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 175: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.70:\n",
      "Loss: 0.028634972870349884\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.71:\n",
      "Loss: 0.031751226633787155\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.175:\n",
      "Loss: 0.02787158638238907\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.176:\n",
      "Loss: 0.028621699661016464\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.177:\n",
      "Loss: 0.034552641212940216\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.178:\n",
      "Loss: 0.0358256921172142\n",
      "Accuracy: 0.9925214648246765\n",
      ">>> Training step No.179:\n",
      "Loss: 0.03245843946933746\n",
      "Accuracy: 0.9935898184776306\n",
      ">>> Training step No.180:\n",
      "Loss: 0.03432825952768326\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.181:\n",
      "Loss: 0.025744566693902016\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.182:\n",
      "Loss: 0.03801196813583374\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.183:\n",
      "Loss: 0.03261846676468849\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.184:\n",
      "Loss: 0.02545584738254547\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.185:\n",
      "Loss: 0.05396853759884834\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.186:\n",
      "Loss: 0.04294515773653984\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.187:\n",
      "Loss: 0.03502484783530235\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.188:\n",
      "Loss: 0.036212459206581116\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.189:\n",
      "Loss: 0.03494134172797203\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.190:\n",
      "Loss: 0.0359974168241024\n",
      "Accuracy: 0.9925214648246765\n",
      ">>> Training step No.191:\n",
      "Loss: 0.02905944734811783\n",
      "Accuracy: 0.9935898184776306\n",
      ">>> Training step No.192:\n",
      "Loss: 0.0348421111702919\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.193:\n",
      "Loss: 0.03759569302201271\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.194:\n",
      "Loss: 0.03027850016951561\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.195:\n",
      "Loss: 0.030276259407401085\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.196:\n",
      "Loss: 0.03709280863404274\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.197:\n",
      "Loss: 0.03531293943524361\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.198:\n",
      "Loss: 0.04040650650858879\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.199:\n",
      "Loss: 0.026449985802173615\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143f89a2b8c54d66831da8e0a276eb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.72:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.73:\n",
      "Loss: 0.03022582270205021\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.74:\n",
      "Loss: 0.2952842116355896\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Validation step No.75:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.76:\n",
      "Loss: 0.029630467295646667\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.77:\n",
      "Loss: 0.03268050402402878\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.78:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.79:\n",
      "Loss: 0.03078160434961319\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.80:\n",
      "Loss: 0.03046138770878315\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 200: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.81:\n",
      "Loss: 0.02707068808376789\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.029999999329447746\n",
      ">>> Training step No.200:\n",
      "Loss: 0.03064432367682457\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.201:\n",
      "Loss: 0.037518300116062164\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.202:\n",
      "Loss: 0.03535318002104759\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.203:\n",
      "Loss: 0.03199875354766846\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.204:\n",
      "Loss: 0.041969481855630875\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.205:\n",
      "Loss: 0.042169392108917236\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.206:\n",
      "Loss: 0.03267808258533478\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.207:\n",
      "Loss: 0.04061218351125717\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.208:\n",
      "Loss: 0.03216974437236786\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.209:\n",
      "Loss: 0.02289682812988758\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.210:\n",
      "Loss: 0.037125345319509506\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.211:\n",
      "Loss: 0.033752668648958206\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.212:\n",
      "Loss: 0.037666432559490204\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.213:\n",
      "Loss: 0.025982491672039032\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.214:\n",
      "Loss: 0.038900502026081085\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.215:\n",
      "Loss: 0.03897682949900627\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.216:\n",
      "Loss: 0.026837391778826714\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.217:\n",
      "Loss: 0.04773586988449097\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.218:\n",
      "Loss: 0.03394550457596779\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.219:\n",
      "Loss: 0.033097200095653534\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.220:\n",
      "Loss: 0.037372197955846786\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.221:\n",
      "Loss: 0.03267589583992958\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.222:\n",
      "Loss: 0.03843584284186363\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.223:\n",
      "Loss: 0.024106459692120552\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.224:\n",
      "Loss: 0.033582501113414764\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ea5bda965b49e49d1d374cf00a963d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.82:\n",
      "Loss: 0.03577712923288345\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Validation step No.83:\n",
      "Loss: 0.030167575925588608\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.84:\n",
      "Loss: 0.03584771975874901\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.85:\n",
      "Loss: 0.03243468701839447\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.86:\n",
      "Loss: 0.029479362070560455\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.87:\n",
      "Loss: 0.026518139988183975\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.88:\n",
      "Loss: 0.03390679135918617\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.89:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.90:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 225: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.91:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.029999999329447746\n",
      ">>> Training step No.225:\n",
      "Loss: 0.02812057174742222\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.226:\n",
      "Loss: 0.03797449544072151\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.227:\n",
      "Loss: 0.03735112026333809\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.228:\n",
      "Loss: 0.04178230091929436\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.229:\n",
      "Loss: 0.02631322108209133\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.230:\n",
      "Loss: 0.038423337042331696\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.231:\n",
      "Loss: 0.030696773901581764\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.232:\n",
      "Loss: 0.03198517858982086\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.233:\n",
      "Loss: 0.03369417041540146\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.234:\n",
      "Loss: 0.03018847107887268\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.235:\n",
      "Loss: 0.032248057425022125\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.236:\n",
      "Loss: 0.039674062281847\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.237:\n",
      "Loss: 0.031454794108867645\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.238:\n",
      "Loss: 0.04068740829825401\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.239:\n",
      "Loss: 0.02978169359266758\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.240:\n",
      "Loss: 0.04838625341653824\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.241:\n",
      "Loss: 0.030772393569350243\n",
      "Accuracy: 0.9930556416511536\n",
      ">>> Training step No.242:\n",
      "Loss: 0.035969946533441544\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.243:\n",
      "Loss: 0.034690532833337784\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.244:\n",
      "Loss: 0.03554510325193405\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.245:\n",
      "Loss: 0.04272129759192467\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.246:\n",
      "Loss: 0.0355461984872818\n",
      "Accuracy: 0.9935897588729858\n",
      ">>> Training step No.247:\n",
      "Loss: 0.04829740524291992\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.248:\n",
      "Loss: 0.027127351611852646\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.249:\n",
      "Loss: 0.035080429166555405\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c378deaf5a7489b8070e47590d0f7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.92:\n",
      "Loss: 0.03405063971877098\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.93:\n",
      "Loss: 0.029141610488295555\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.94:\n",
      "Loss: 0.038843825459480286\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.95:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.96:\n",
      "Loss: 0.030382277444005013\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.97:\n",
      "Loss: 0.03145251050591469\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.98:\n",
      "Loss: 0.03137460723519325\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.99:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 250: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.100:\n",
      "Loss: 0.031540099531412125\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.101:\n",
      "Loss: 0.029796643182635307\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.250:\n",
      "Loss: 0.03637436404824257\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.251:\n",
      "Loss: 0.032342784106731415\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.252:\n",
      "Loss: 0.03945644572377205\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.253:\n",
      "Loss: 0.039685431867837906\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.254:\n",
      "Loss: 0.04098494350910187\n",
      "Accuracy: 0.9941239356994629\n",
      ">>> Training step No.255:\n",
      "Loss: 0.027089321985840797\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.256:\n",
      "Loss: 0.0367673821747303\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.257:\n",
      "Loss: 0.03293439745903015\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.258:\n",
      "Loss: 0.04947381094098091\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.259:\n",
      "Loss: 0.04871361702680588\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.260:\n",
      "Loss: 0.031122351065278053\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.261:\n",
      "Loss: 0.030903784558176994\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.262:\n",
      "Loss: 0.04223145544528961\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.263:\n",
      "Loss: 0.035896796733140945\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.264:\n",
      "Loss: 0.03588586300611496\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.265:\n",
      "Loss: 0.02986188419163227\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.266:\n",
      "Loss: 0.029697464779019356\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.267:\n",
      "Loss: 0.04586745426058769\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.268:\n",
      "Loss: 0.036610327661037445\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.269:\n",
      "Loss: 0.034660812467336655\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.270:\n",
      "Loss: 0.02672526426613331\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.271:\n",
      "Loss: 0.037124067544937134\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.272:\n",
      "Loss: 0.02911246195435524\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.273:\n",
      "Loss: 0.04070304334163666\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.274:\n",
      "Loss: 0.029115930199623108\n",
      "Accuracy: 0.9925214052200317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589a4ee2bacc4fb78df26d6841beef61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.102:\n",
      "Loss: 0.027228565886616707\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.103:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.104:\n",
      "Loss: 0.0268240999430418\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.105:\n",
      "Loss: 0.030938291922211647\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.106:\n",
      "Loss: 0.028180694207549095\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.107:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.108:\n",
      "Loss: 0.03002038039267063\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.109:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.110:\n",
      "Loss: 0.029740341007709503\n",
      "Accuracy: 0.995726466178894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 275: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.111:\n",
      "Loss: 0.02875295653939247\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.275:\n",
      "Loss: 0.038821637630462646\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.276:\n",
      "Loss: 0.0352114774286747\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.277:\n",
      "Loss: 0.04036852344870567\n",
      "Accuracy: 0.9946581721305847\n",
      ">>> Training step No.278:\n",
      "Loss: 0.034801069647073746\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.279:\n",
      "Loss: 0.03899647668004036\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.280:\n",
      "Loss: 0.03777116909623146\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.281:\n",
      "Loss: 0.050750307738780975\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.282:\n",
      "Loss: 0.03520204499363899\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.283:\n",
      "Loss: 0.03211480751633644\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.284:\n",
      "Loss: 0.045982591807842255\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.285:\n",
      "Loss: 0.033740051090717316\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.286:\n",
      "Loss: 0.03607672452926636\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.287:\n",
      "Loss: 0.02488177828490734\n",
      "Accuracy: 0.9935897588729858\n",
      ">>> Training step No.288:\n",
      "Loss: 0.034993212670087814\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.289:\n",
      "Loss: 0.02827281504869461\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.290:\n",
      "Loss: 0.03619172051548958\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.291:\n",
      "Loss: 0.033148761838674545\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.292:\n",
      "Loss: 0.03504326194524765\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.293:\n",
      "Loss: 0.037899892777204514\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.294:\n",
      "Loss: 0.043220408260822296\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.295:\n",
      "Loss: 0.032405924052000046\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.296:\n",
      "Loss: 0.04399678856134415\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.297:\n",
      "Loss: 0.036437034606933594\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.298:\n",
      "Loss: 0.0383983738720417\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.299:\n",
      "Loss: 0.04043615981936455\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c8fafe193d488eb1b14bd03edcb271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.112:\n",
      "Loss: 0.03009948693215847\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.113:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.114:\n",
      "Loss: 0.028967399150133133\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.115:\n",
      "Loss: 0.030827319249510765\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.116:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.117:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.118:\n",
      "Loss: 0.03250773251056671\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.119:\n",
      "Loss: 0.029259854927659035\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.120:\n",
      "Loss: 0.031077386811375618\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 300: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.121:\n",
      "Loss: 0.030922727659344673\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      ">>> Training step No.300:\n",
      "Loss: 0.04262976348400116\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.301:\n",
      "Loss: 0.03734739124774933\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.302:\n",
      "Loss: 0.04350190609693527\n",
      "Accuracy: 0.9925214648246765\n",
      ">>> Training step No.303:\n",
      "Loss: 0.02560070902109146\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.304:\n",
      "Loss: 0.027057314291596413\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.305:\n",
      "Loss: 0.037225108593702316\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.306:\n",
      "Loss: 0.03599224239587784\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.307:\n",
      "Loss: 0.028462905436754227\n",
      "Accuracy: 0.9946581721305847\n",
      ">>> Training step No.308:\n",
      "Loss: 0.04704805836081505\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.309:\n",
      "Loss: 0.04013960063457489\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.310:\n",
      "Loss: 0.03173840418457985\n",
      "Accuracy: 0.9946582317352295\n",
      ">>> Training step No.311:\n",
      "Loss: 0.026537301018834114\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.312:\n",
      "Loss: 0.026594575494527817\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.313:\n",
      "Loss: 0.03040085732936859\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.314:\n",
      "Loss: 0.03473799303174019\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.315:\n",
      "Loss: 0.027959363535046577\n",
      "Accuracy: 0.9946581721305847\n",
      ">>> Training step No.316:\n",
      "Loss: 0.03224918246269226\n",
      "Accuracy: 0.9935897588729858\n",
      ">>> Training step No.317:\n",
      "Loss: 0.028260765597224236\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.318:\n",
      "Loss: 0.03261149674654007\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.319:\n",
      "Loss: 0.03386293724179268\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.320:\n",
      "Loss: 0.042882855981588364\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.321:\n",
      "Loss: 0.02992904931306839\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.322:\n",
      "Loss: 0.030416810885071754\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.323:\n",
      "Loss: 0.03648438677191734\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.324:\n",
      "Loss: 0.035454824566841125\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c050c500e642d0bd721deb010169e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.122:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.123:\n",
      "Loss: 0.028695780783891678\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.124:\n",
      "Loss: 0.031888626515865326\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.125:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.126:\n",
      "Loss: 0.02885589562356472\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.127:\n",
      "Loss: nan\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.128:\n",
      "Loss: 0.03372647613286972\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.129:\n",
      "Loss: 0.029920127242803574\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 325: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.130:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.131:\n",
      "Loss: 0.02985183708369732\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Epoch end loss: 0.029999999329447746\n",
      ">>> Training step No.325:\n",
      "Loss: 0.042897779494524\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.326:\n",
      "Loss: 0.028932703658938408\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.327:\n",
      "Loss: 0.03232491761445999\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.328:\n",
      "Loss: 0.03967275470495224\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.329:\n",
      "Loss: 0.02941635437309742\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.330:\n",
      "Loss: 0.036832135170698166\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.331:\n",
      "Loss: 0.03518609330058098\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.332:\n",
      "Loss: 0.03724335506558418\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.333:\n",
      "Loss: 0.029225138947367668\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.334:\n",
      "Loss: 0.030803168192505836\n",
      "Accuracy: 0.9930556416511536\n",
      ">>> Training step No.335:\n",
      "Loss: 0.033604759722948074\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.336:\n",
      "Loss: 0.030228815972805023\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.337:\n",
      "Loss: 0.03676756098866463\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.338:\n",
      "Loss: 0.04336309805512428\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.339:\n",
      "Loss: 0.029076583683490753\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.340:\n",
      "Loss: 0.027801090851426125\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.341:\n",
      "Loss: 0.031195329502224922\n",
      "Accuracy: 0.992521345615387\n",
      ">>> Training step No.342:\n",
      "Loss: 0.02072361670434475\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.343:\n",
      "Loss: 0.03133242204785347\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.344:\n",
      "Loss: 0.03865386173129082\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.345:\n",
      "Loss: 0.031059492379426956\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.346:\n",
      "Loss: 0.0325716994702816\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.347:\n",
      "Loss: 0.034123994410037994\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.348:\n",
      "Loss: 0.029465921223163605\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.349:\n",
      "Loss: 0.03730081766843796\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352230169c46461cb822c4f2f355054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.132:\n",
      "Loss: nan\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Validation step No.133:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.134:\n",
      "Loss: 0.029199808835983276\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.135:\n",
      "Loss: 0.029337914660573006\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.136:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.137:\n",
      "Loss: 0.031026842072606087\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.138:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.139:\n",
      "Loss: 0.028721975162625313\n",
      "Accuracy: 0.9957265853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 350: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.140:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.141:\n",
      "Loss: 0.03239017724990845\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Epoch end loss: 0.029999999329447746\n",
      ">>> Training step No.350:\n",
      "Loss: 0.03921698406338692\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.351:\n",
      "Loss: 0.03660821542143822\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.352:\n",
      "Loss: 0.029103407636284828\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.353:\n",
      "Loss: 0.03924057260155678\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.354:\n",
      "Loss: 0.037757888436317444\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.355:\n",
      "Loss: 0.031711503863334656\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.356:\n",
      "Loss: 0.0385625846683979\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.357:\n",
      "Loss: 0.04241446033120155\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.358:\n",
      "Loss: 0.03247305378317833\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.359:\n",
      "Loss: 0.038072794675827026\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.360:\n",
      "Loss: 0.04654641076922417\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.361:\n",
      "Loss: 0.039708588272333145\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.362:\n",
      "Loss: 0.03819070756435394\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.363:\n",
      "Loss: 0.030701715499162674\n",
      "Accuracy: 0.9930555820465088\n",
      ">>> Training step No.364:\n",
      "Loss: 0.04017620533704758\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Training step No.365:\n",
      "Loss: 0.040349896997213364\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.366:\n",
      "Loss: 0.030185338109731674\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.367:\n",
      "Loss: 0.030249817296862602\n",
      "Accuracy: 0.9951923489570618\n",
      ">>> Training step No.368:\n",
      "Loss: 0.03817855194211006\n",
      "Accuracy: 0.9925214052200317\n",
      ">>> Training step No.369:\n",
      "Loss: 0.035790860652923584\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.370:\n",
      "Loss: 0.03749304637312889\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.371:\n",
      "Loss: 0.03454574570059776\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.372:\n",
      "Loss: 0.03464450687170029\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Training step No.373:\n",
      "Loss: 0.028091898187994957\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Training step No.374:\n",
      "Loss: 0.030900536105036736\n",
      "Accuracy: 0.9957265257835388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3671806ca5ab4e0bb58bb92478b09392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.142:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.143:\n",
      "Loss: 0.02962273173034191\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.144:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.145:\n",
      "Loss: 0.03904840722680092\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.146:\n",
      "Loss: 0.02990005351603031\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.147:\n",
      "Loss: 0.030375981703400612\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.148:\n",
      "Loss: 0.030703479424118996\n",
      "Accuracy: 0.9957265257835388\n",
      ">>> Validation step No.149:\n",
      "Loss: nan\n",
      "Accuracy: 0.9957265853881836\n",
      ">>> Validation step No.150:\n",
      "Loss: nan\n",
      "Accuracy: 0.995726466178894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 375: 'val_loss' was not in top 2\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation step No.151:\n",
      "Loss: 0.03190481662750244\n",
      "Accuracy: 0.995726466178894\n",
      ">>> Epoch end loss: 0.03999999910593033\n"
     ]
    }
   ],
   "source": [
    "# trainer.fit(model, ckpt_path=\"/home/toghrul/SLR/sign-lang/checkpoints/last.ckpt\")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel.load_from_checkpoint(\n",
    "    checkpoint_path=\"/home/toghrul/SLR/sign-lang/checkpoints/last.ckpt\",\n",
    "    hparams_file=\"/home/toghrul/SLR/sign-lang/lightning_logs/version_38/hparams.yaml\",\n",
    "    map_location=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_res = trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_res = trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1373],\n",
       "         [ 1.2810],\n",
       "         [ 0.6021],\n",
       "         [-0.2140],\n",
       "         [-0.1674],\n",
       "         [-0.0197],\n",
       "         [ 0.5376],\n",
       "         [-0.6672]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(8, 1)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n",
       "        [ 1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
       "        [-1.04855297, -1.42001794, -1.70627019,  1.9507754 ],\n",
       "        [-0.50965218, -0.4380743 , -1.25279536,  0.77749036],\n",
       "        [-1.61389785, -0.21274028, -0.89546656,  0.3869025 ],\n",
       "        [-0.51080514, -1.18063218, -0.02818223,  0.42833187],\n",
       "        [ 0.06651722,  0.3024719 , -0.63432209, -0.36274117],\n",
       "        [-0.67246045, -0.35955316, -0.81314628, -1.7262826 ]]),\n",
       " array([3, 0, 3, 3, 3, 3, 1, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(8, 4)\n",
    "a, a.argmax(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sign-lang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a4e4d8fc4dcb6ce321df308d690f3398dc6d289b3efb6c91f90112c618c739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
