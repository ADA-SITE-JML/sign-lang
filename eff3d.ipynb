{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.nn.functional import InterpolationMode\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging \n",
    "import datetime\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_df_path = \"data_validation/processed_gloss.csv\"\n",
    "gloss_df = pd.read_csv(gloss_df_path)\n",
    "gloss_df.dropna(inplace=True)\n",
    "gloss_df.replace(to_replace=\"ASHAG\", value=\"AŞAĞI\", inplace=True)\n",
    "gloss_df['glossRange'] = gloss_df['glossEnd'] - gloss_df['glossStart']\n",
    "# gloss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(gloss_df.gloss.unique())\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "idx_to_class = {i: classes[i] for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler\n",
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorchvideo.data import labeled_video_dataset\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute,   \n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomAdjustSharpness,\n",
    "    Resize,\n",
    "    RandomHorizontalFlip\n",
    ")\n",
    "\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transform = Compose([\n",
    "    ApplyTransformToKey(key=\"video\",\n",
    "    transform=Compose([\n",
    "        UniformTemporalSubsample(25),\n",
    "        Lambda(lambda x: x/255),\n",
    "        Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "        # RandomShortSideScale(min_size=256, max_size=512),\n",
    "        CenterCropVideo(256),\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "    ]),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/toghrul/SLR/data/binary-data/train\"\n",
    "val_path = \"/home/toghrul/SLR/data/binary-data/val\"\n",
    "test_path = \"/home/toghrul/SLR/data/binary-data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_classes = []\n",
    "\n",
    "for gloss in os.listdir(test_path):\n",
    "    bin_classes.append(gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'MƏN', 1: 'VAR'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_classes = sorted(bin_classes)\n",
    "bin_class_to_idx = {bin_classes[i]: i for i in range(len(bin_classes))}\n",
    "bin_idx_to_class = {i: bin_classes[i] for i in range(len(bin_classes))}\n",
    "bin_idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "video_model = torch.hub.load('facebookresearch/pytorchvideo', 'efficient_x3d_xs', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = labeled_video_dataset(train_path, transform=video_transform, clip_sampler=make_clip_sampler('random', 2), decode_audio=False)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=8, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['video', 'video_name', 'video_index', 'clip_index', 'aug_index', 'label'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randn(size=(8, num_classes)).requires_grad_()\n",
    "# b = torch.randint(5, size=(8, ), dtype=torch.long)\n",
    "# a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = F.one_hot(b, num_classes=num_classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(input, target)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoModel(LightningModule):\n",
    "    def __init__(self, ):\n",
    "        super(VideoModel, self).__init__()\n",
    "\n",
    "        self.video_model = torch.hub.load('facebookresearch/pytorchvideo', 'efficient_x3d_xs', pretrained=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(400, 1)\n",
    "\n",
    "        self.lr = 1e-3\n",
    "        self.batch_size = 8\n",
    "        self.num_worker = 4\n",
    "        self.num_steps_train = 0\n",
    "        self.num_steps_val = 0\n",
    "\n",
    "        # self.metric = torchmetrics.classification.MultilabelAccuracy(num_labels=num_classes)\n",
    "        self.metric = torchmetrics.Accuracy()\n",
    "        \n",
    "        #loss\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.video_model(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(params=self.parameters(), lr = self.lr)\n",
    "        scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.05, patience=2, min_lr=1e-6)\n",
    "        # scheduler = CosineAnnealingLR(opt, T_max=10, eta_min=1e-6, last_epoch=-1)\n",
    "        return {'optimizer': opt,\n",
    "                'lr_scheduler': scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = labeled_video_dataset(train_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        # label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self(video)\n",
    "        print(f\"Label: {label}\\nPred: {out}\")\n",
    "        print(f\">>> Training step No.{self.num_steps_train}:\")\n",
    "        # print(\"Pred:\", out)\n",
    "        # print(\"GT:\", label)\n",
    "        # print(f\"Pred:\\n{out}\")\n",
    "        # print(f\"Pred shape:\\n{out.shape}\")\n",
    "        # print(f\"Label:\\n{label}\")\n",
    "        # print(f\"Label shape:\\n{label.shape}\")\n",
    "        # print(\">>> INFO: Computing Training Loss\")\n",
    "        \n",
    "        loss = self.criterion(out, label.float().unsqueeze(1))\n",
    "        \n",
    "        print(f\"Loss: {loss}\")\n",
    "        self.num_steps_train += 1\n",
    "        # print(\">>> INFO: Training Loss Computed\")\n",
    "        # print(\">>> INFO: Computing Training Metric\")\n",
    "        # metric = self.metric(out, label)\n",
    "        \n",
    "        # Below is for Accuracy\n",
    "        metric = self.metric(out, label.to(torch.int64).unsqueeze(1))\n",
    "        \n",
    "        print(f\"Accuracy: {metric}\")\n",
    "\n",
    "        values = {\"loss\": loss,\n",
    "                \"metric\": metric.detach()}\n",
    "        \n",
    "        self.log_dict({\"step_loss\": loss,\n",
    "                        \"step_metric\": metric.detach()})\n",
    "        \n",
    "        return values\n",
    "        \n",
    "        # return {\"loss\": loss}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        \n",
    "        self.log('training_loss', loss)\n",
    "        print(f\">>> Epoch end loss: {loss}\")\n",
    "        self.log('training_metric', metric)\n",
    "        \n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = labeled_video_dataset(val_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        # label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self(video)\n",
    "        print(f\"Label: {label}\\nPred: {out}\")\n",
    "        # print(\">>> INFO: Computing Val Loss\")\n",
    "        print(f\">>> Validation step No.{self.num_steps_val}:\")\n",
    "\n",
    "        loss = self.criterion(out, label.float().unsqueeze(1))\n",
    "        print()\n",
    "        print(f\"Loss: {loss}\")\n",
    "        self.num_steps_val += 1\n",
    "        # print(\">>> INFO: Val Loss Computed\")\n",
    "        # print(\">>> INFO: Computing Val Metric\")\n",
    "        # metric = self.metric(out, label)\n",
    "        # Below is for Accuracy\n",
    "        \n",
    "        metric = self.metric(out, label.to(torch.int64).unsqueeze(1))\n",
    "                \n",
    "        print(f\"Accuracy: {metric}\")\n",
    "        \n",
    "\n",
    "        return {\"loss\": loss,\n",
    "                \"metric\": metric.detach()}\n",
    "        \n",
    "        # return {\"loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_metric', metric)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = labeled_video_dataset(test_path, clip_sampler=make_clip_sampler('random', 2),\n",
    "                                         transform=video_transform, decode_audio=False)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_worker, pin_memory=True)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        # label = F.one_hot(label, num_classes=num_classes).float()\n",
    "        out = self.forward(video)\n",
    "        # metric = self.metric(out, label)\n",
    "\n",
    "        return {\"label\": label,\n",
    "                \"pred\": out.detach(),}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        label=torch.cat([x['label'] for x in outputs]).cpu().numpy()\n",
    "        pred = torch.cat([x['pred'] for x in outputs]).cpu().numpy()\n",
    "        # self.log('test_loss', loss)\n",
    "        # self.log('test_metric', metric)\n",
    "        \n",
    "        # Below is for MultiLabelClassification\n",
    "        # class_labels = label.argmax(axis=1)\n",
    "        # class_pred = pred.argmax(axis=1)\n",
    "        \n",
    "        \n",
    "        # Below is for BinaryClassification\n",
    "        class_labels = label\n",
    "        class_pred = np.where(pred > 0, 1, 0)\n",
    "        \n",
    "        print(f\">> Label: {class_labels}\")\n",
    "        print(f\">> Pred: {class_pred.squeeze()}\")\n",
    "              \n",
    "        print(classification_report(class_labels, class_pred))\n",
    "        \n",
    "        return {\"prediction\": class_pred,\n",
    "                \"labels\": class_labels}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath=\"checkpoints\", \n",
    "                                    verbose=True, save_last=True, save_top_k=2)\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VideoModel()\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=15,\n",
    "                accelerator=\"gpu\", devices=-1,\n",
    "                precision=16,\n",
    "                # accumulate_grad_batches=2,\n",
    "                enable_progress_bar=True,\n",
    "                # num_sanity_val_steps=0,\n",
    "                callbacks=[lr_monitor, checkpoint_callback],\n",
    "                log_every_n_steps=5,\n",
    "                limit_train_batches=25,\n",
    "                limit_val_batches=10,\n",
    "                limit_test_batches=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/envs/sign-lang/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/toghrul/SLR/sign-lang/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | video_model | EfficientX3d      | 3.8 M \n",
      "1 | relu        | ReLU              | 0     \n",
      "2 | fc          | Linear            | 401   \n",
      "3 | metric      | Accuracy          | 0     \n",
      "4 | criterion   | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "7.589     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd17c0f91a1245128ca3fe3a5141a1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.0410],\n",
      "        [-0.6724],\n",
      "        [-0.9170],\n",
      "        [-0.9272],\n",
      "        [-0.9751],\n",
      "        [-0.2600],\n",
      "        [-0.8491],\n",
      "        [-0.7397]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.0:\n",
      "\n",
      "Loss: 0.3777940571308136\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-0.6021],\n",
      "        [-0.5103],\n",
      "        [-0.9604],\n",
      "        [-0.8262],\n",
      "        [-0.2499],\n",
      "        [-0.5225],\n",
      "        [-0.9497],\n",
      "        [-0.6992]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.1:\n",
      "\n",
      "Loss: 0.48455989360809326\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01721a832c82417586b33a3f284c3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-0.5894],\n",
      "        [-0.1630],\n",
      "        [-0.5737],\n",
      "        [-0.2391],\n",
      "        [-0.0739],\n",
      "        [-0.0850],\n",
      "        [-0.0891],\n",
      "        [-0.4849]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.0:\n",
      "Loss: 0.5652141571044922\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.9570],\n",
      "        [-1.7227],\n",
      "        [-3.8359],\n",
      "        [-2.1289],\n",
      "        [-3.0488],\n",
      "        [-3.3555],\n",
      "        [-3.4355],\n",
      "        [-2.3027]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.1:\n",
      "Loss: 0.07973060756921768\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.4609],\n",
      "        [-6.0664],\n",
      "        [-7.1484],\n",
      "        [-6.7734],\n",
      "        [-6.4102],\n",
      "        [-5.2305],\n",
      "        [-8.2969],\n",
      "        [-5.4492]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.2:\n",
      "Loss: 1.457120656967163\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.4688],\n",
      "        [-6.7109],\n",
      "        [-6.5938],\n",
      "        [-6.8594],\n",
      "        [-6.0156],\n",
      "        [-5.0352],\n",
      "        [-6.2695],\n",
      "        [-6.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.3:\n",
      "Loss: 0.631536066532135\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.5781],\n",
      "        [-8.4141],\n",
      "        [-6.4844],\n",
      "        [-8.9297],\n",
      "        [-8.9297],\n",
      "        [-6.7148],\n",
      "        [-7.1914],\n",
      "        [-9.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.4:\n",
      "Loss: 0.0005312883295118809\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.1953],\n",
      "        [ -5.7383],\n",
      "        [-15.4766],\n",
      "        [-10.0156],\n",
      "        [-10.0625],\n",
      "        [ -9.2344],\n",
      "        [ -9.1484],\n",
      "        [-10.6875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.5:\n",
      "Loss: 2.5434114933013916\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.4922],\n",
      "        [ -9.7188],\n",
      "        [ -8.0312],\n",
      "        [ -5.8867],\n",
      "        [ -7.2227],\n",
      "        [ -5.9414],\n",
      "        [ -8.9844],\n",
      "        [-12.1875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.6:\n",
      "Loss: 0.736671507358551\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.6367],\n",
      "        [ -3.8340],\n",
      "        [ -7.4766],\n",
      "        [-17.6875],\n",
      "        [-13.8750],\n",
      "        [ -6.9805],\n",
      "        [ -6.6797],\n",
      "        [ -3.2500]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.7:\n",
      "Loss: 0.8815371990203857\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.4922],\n",
      "        [-6.0625],\n",
      "        [-8.4375],\n",
      "        [-2.2617],\n",
      "        [-8.9141],\n",
      "        [-8.3750],\n",
      "        [-8.2734],\n",
      "        [-3.9316]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.8:\n",
      "Loss: 0.7744142413139343\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.8652],\n",
      "        [ -3.3867],\n",
      "        [-10.3125],\n",
      "        [ -3.4277],\n",
      "        [ -3.9805],\n",
      "        [ -1.4111],\n",
      "        [ -5.1016],\n",
      "        [ -6.5156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.9:\n",
      "Loss: 0.04128212109208107\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.7148],\n",
      "        [-7.6367],\n",
      "        [-1.9219],\n",
      "        [-3.4141],\n",
      "        [-2.3691],\n",
      "        [-0.9458],\n",
      "        [-7.5469],\n",
      "        [-4.0742]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.10:\n",
      "Loss: 0.07666341960430145\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.7168],\n",
      "        [-1.6143],\n",
      "        [-2.3496],\n",
      "        [-2.5410],\n",
      "        [-7.7969],\n",
      "        [-4.5352],\n",
      "        [-2.5645],\n",
      "        [-6.6719]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.11:\n",
      "Loss: 0.062370479106903076\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.4766],\n",
      "        [ -3.9395],\n",
      "        [ -2.7949],\n",
      "        [ -1.4941],\n",
      "        [ -4.1914],\n",
      "        [-11.2578],\n",
      "        [ -3.5801],\n",
      "        [ -3.7344]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.12:\n",
      "Loss: 0.24025413393974304\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.8633],\n",
      "        [-6.4727],\n",
      "        [-1.6748],\n",
      "        [-2.5527],\n",
      "        [-5.0625],\n",
      "        [-5.4375],\n",
      "        [-2.0059],\n",
      "        [-4.5859]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.13:\n",
      "Loss: 0.050371114164590836\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.1172],\n",
      "        [ -2.8867],\n",
      "        [ -3.5059],\n",
      "        [ -1.3691],\n",
      "        [ -2.9492],\n",
      "        [ -2.8809],\n",
      "        [ -1.6660],\n",
      "        [ -6.2734]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.14:\n",
      "Loss: 1.1820415258407593\n",
      "Accuracy: 0.5\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.7930],\n",
      "        [-2.3691],\n",
      "        [-8.0781],\n",
      "        [-5.3281],\n",
      "        [-1.8213],\n",
      "        [-8.6875],\n",
      "        [-1.1729],\n",
      "        [-1.8555]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.15:\n",
      "Loss: 0.31115177273750305\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-0.2756],\n",
      "        [-0.7622],\n",
      "        [-1.8770],\n",
      "        [-5.7461],\n",
      "        [-7.9414],\n",
      "        [-3.4648],\n",
      "        [-1.9170],\n",
      "        [-2.0156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.16:\n",
      "Loss: 0.4474281668663025\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-0.5581],\n",
      "        [-5.6328],\n",
      "        [-1.6465],\n",
      "        [-1.1543],\n",
      "        [-4.2148],\n",
      "        [-3.3145],\n",
      "        [-2.3066],\n",
      "        [-0.3730]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.17:\n",
      "Loss: 0.24358513951301575\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-3.6582],\n",
      "        [-0.3738],\n",
      "        [-0.7354],\n",
      "        [-2.9570],\n",
      "        [-1.6406],\n",
      "        [ 0.1821],\n",
      "        [-7.8789],\n",
      "        [ 0.3755]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.18:\n",
      "Loss: 0.5151006579399109\n",
      "Accuracy: 0.75\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ 0.0705],\n",
      "        [-8.2969],\n",
      "        [-2.6426],\n",
      "        [-0.3586],\n",
      "        [-0.2949],\n",
      "        [-1.6641],\n",
      "        [-0.3594],\n",
      "        [-2.4590]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.19:\n",
      "Loss: 0.32485830783843994\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.1406],\n",
      "        [-5.2344],\n",
      "        [-1.1211],\n",
      "        [-2.2910],\n",
      "        [-5.4297],\n",
      "        [-0.0451],\n",
      "        [-2.3184],\n",
      "        [-1.1689]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.20:\n",
      "Loss: 0.21260222792625427\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-0.7573],\n",
      "        [ 0.0894],\n",
      "        [-6.1758],\n",
      "        [-6.5664],\n",
      "        [-0.9888],\n",
      "        [-5.3086],\n",
      "        [-0.7041],\n",
      "        [ 0.0521]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.21:\n",
      "Loss: 0.3146681487560272\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.2520],\n",
      "        [-2.4062],\n",
      "        [-7.8789],\n",
      "        [-4.6992],\n",
      "        [-0.2576],\n",
      "        [-9.0312],\n",
      "        [-0.9858],\n",
      "        [-2.5664]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.22:\n",
      "Loss: 0.14495301246643066\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.9375],\n",
      "        [ 0.1494],\n",
      "        [-0.2944],\n",
      "        [-0.3328],\n",
      "        [-1.1602],\n",
      "        [-3.1582],\n",
      "        [-9.8672],\n",
      "        [-8.5547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.23:\n",
      "Loss: 0.33254295587539673\n",
      "Accuracy: 0.625\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-11.3047],\n",
      "        [ -1.5830],\n",
      "        [ -9.5391],\n",
      "        [ -4.9805],\n",
      "        [  0.1686],\n",
      "        [ -8.5156],\n",
      "        [ -5.2734],\n",
      "        [ -0.0590]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.24:\n",
      "Loss: 0.1918129026889801\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f6409c10334a4d93ad2f9587ce1bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.6172],\n",
      "        [ -8.8594],\n",
      "        [-18.9844],\n",
      "        [ -9.4766],\n",
      "        [-23.1094],\n",
      "        [-24.9844],\n",
      "        [-27.9844],\n",
      "        [-21.5469]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.2:\n",
      "\n",
      "Loss: 1.3271788358688354\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.6758],\n",
      "        [-28.0625],\n",
      "        [-14.0703],\n",
      "        [ -1.8408],\n",
      "        [-18.7656],\n",
      "        [-22.5469],\n",
      "        [-24.0938],\n",
      "        [ -7.1367]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.3:\n",
      "\n",
      "Loss: 0.5914088487625122\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-22.6406],\n",
      "        [-20.2812],\n",
      "        [ -7.8789],\n",
      "        [-18.7188],\n",
      "        [-28.4688],\n",
      "        [-19.6875],\n",
      "        [-21.1562],\n",
      "        [-20.0312]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.4:\n",
      "\n",
      "Loss: 4.7317131247837096e-05\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.2734],\n",
      "        [-21.5625],\n",
      "        [-23.6094],\n",
      "        [-24.8281],\n",
      "        [ -5.5078],\n",
      "        [-24.6406],\n",
      "        [-23.3750],\n",
      "        [ -3.3047]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.5:\n",
      "\n",
      "Loss: 0.693489134311676\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-28.4844],\n",
      "        [ -0.6650],\n",
      "        [-30.0156],\n",
      "        [-22.1562],\n",
      "        [-14.1953],\n",
      "        [-22.6719],\n",
      "        [ -7.5312],\n",
      "        [-20.1875]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.6:\n",
      "\n",
      "Loss: 0.13506227731704712\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-21.7969],\n",
      "        [-27.6094],\n",
      "        [-21.4531],\n",
      "        [-23.9219],\n",
      "        [-15.1484],\n",
      "        [-27.5156],\n",
      "        [-25.8750],\n",
      "        [-20.3125]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.7:\n",
      "\n",
      "Loss: 2.9802318834981634e-08\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -0.3367],\n",
      "        [-27.4375],\n",
      "        [ -0.8452],\n",
      "        [-17.4219],\n",
      "        [-11.8125],\n",
      "        [-10.1328],\n",
      "        [ -1.6953],\n",
      "        [-22.8750]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.8:\n",
      "\n",
      "Loss: 0.4927462935447693\n",
      "Accuracy: 0.625\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.2891],\n",
      "        [-25.0000],\n",
      "        [-14.3984],\n",
      "        [-23.2344],\n",
      "        [-14.1484],\n",
      "        [-22.1250],\n",
      "        [-27.2812],\n",
      "        [ -2.5566]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.9:\n",
      "\n",
      "Loss: 0.32891878485679626\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 25: 'val_loss' reached 0.43000 (best 0.43000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=0-step=25.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.5156],\n",
      "        [ -8.6484],\n",
      "        [-14.6562],\n",
      "        [-18.9062],\n",
      "        [-21.3906],\n",
      "        [ -4.5859],\n",
      "        [-24.2188],\n",
      "        [-23.0312]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.10:\n",
      "\n",
      "Loss: 0.001289798878133297\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-26.1562],\n",
      "        [-25.1094],\n",
      "        [-25.3281],\n",
      "        [ -4.7734],\n",
      "        [-25.8438],\n",
      "        [-25.3906],\n",
      "        [ -0.5815],\n",
      "        [ -3.5586]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.11:\n",
      "\n",
      "Loss: 0.7294430136680603\n",
      "Accuracy: 0.75\n",
      ">>> Epoch end loss: 0.49000000953674316\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.0938],\n",
      "        [-8.2500],\n",
      "        [-9.0469],\n",
      "        [-0.2734],\n",
      "        [-5.6250],\n",
      "        [-9.0859],\n",
      "        [-1.7520],\n",
      "        [-9.1797]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.25:\n",
      "Loss: 0.10575992614030838\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-9.3750],\n",
      "        [-8.2891],\n",
      "        [-7.9883],\n",
      "        [-6.6367],\n",
      "        [-9.9141],\n",
      "        [-5.9805],\n",
      "        [-0.2175],\n",
      "        [-1.7422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.26:\n",
      "Loss: 0.12171994149684906\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.7148],\n",
      "        [ -0.4705],\n",
      "        [-14.0469],\n",
      "        [-14.3281],\n",
      "        [  0.1078],\n",
      "        [ -7.3398],\n",
      "        [-12.0703],\n",
      "        [ -1.6396]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.27:\n",
      "Loss: 0.1836937963962555\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.4976],\n",
      "        [ -9.5781],\n",
      "        [ -6.2461],\n",
      "        [-12.3828],\n",
      "        [ -5.2148],\n",
      "        [-11.8906],\n",
      "        [ -8.6484],\n",
      "        [ -3.2480]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.28:\n",
      "Loss: 0.06509075313806534\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.5625],\n",
      "        [-12.9609],\n",
      "        [ -6.0664],\n",
      "        [ -7.3125],\n",
      "        [ -2.0625],\n",
      "        [-12.8672],\n",
      "        [ -7.3945],\n",
      "        [ -8.5938]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.29:\n",
      "Loss: 0.015498439781367779\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.3516],\n",
      "        [-13.4141],\n",
      "        [-11.8516],\n",
      "        [ -6.8984],\n",
      "        [  0.8022],\n",
      "        [ -7.5156],\n",
      "        [ -9.7031],\n",
      "        [-12.3438]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.30:\n",
      "Loss: 0.047095220535993576\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.6484],\n",
      "        [-12.9531],\n",
      "        [ -0.8267],\n",
      "        [ -9.1016],\n",
      "        [-13.5703],\n",
      "        [  0.4307],\n",
      "        [ -9.9453],\n",
      "        [-14.2656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.31:\n",
      "Loss: 0.2113277018070221\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.3516],\n",
      "        [ -6.7383],\n",
      "        [ -9.0781],\n",
      "        [-10.1719],\n",
      "        [ -9.2266],\n",
      "        [ -0.7090],\n",
      "        [ -5.4414],\n",
      "        [-16.7188]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.32:\n",
      "Loss: 0.05074664205312729\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.0391],\n",
      "        [  2.1094],\n",
      "        [ -2.1152],\n",
      "        [-19.9844],\n",
      "        [ -4.3789],\n",
      "        [-10.4375],\n",
      "        [ -7.5117],\n",
      "        [-18.2969]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.33:\n",
      "Loss: 0.03028540126979351\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.4414],\n",
      "        [ -5.4648],\n",
      "        [-10.2578],\n",
      "        [-11.8984],\n",
      "        [-10.5078],\n",
      "        [-12.6875],\n",
      "        [-21.6719],\n",
      "        [ -2.2070]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.34:\n",
      "Loss: 0.013784176670014858\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-14.0938],\n",
      "        [  3.4102],\n",
      "        [ -2.9590],\n",
      "        [-17.3281],\n",
      "        [-17.0938],\n",
      "        [ -3.9824],\n",
      "        [-17.1562],\n",
      "        [  3.0156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.35:\n",
      "Loss: 0.018674291670322418\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  3.9219],\n",
      "        [-15.6094],\n",
      "        [-18.1562],\n",
      "        [-12.2891],\n",
      "        [ -2.9297],\n",
      "        [-10.8594],\n",
      "        [ -9.1094],\n",
      "        [-11.1172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.36:\n",
      "Loss: 0.008974486961960793\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.8828],\n",
      "        [  2.3770],\n",
      "        [-11.1172],\n",
      "        [ -2.6055],\n",
      "        [-11.8203],\n",
      "        [-12.4141],\n",
      "        [-21.7500],\n",
      "        [-10.9062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.37:\n",
      "Loss: 0.3171301484107971\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.5391],\n",
      "        [ -2.6191],\n",
      "        [-14.8516],\n",
      "        [-10.1797],\n",
      "        [-23.2344],\n",
      "        [-15.4219],\n",
      "        [  4.9453],\n",
      "        [-14.0703]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.38:\n",
      "Loss: 0.009749459102749825\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-20.4219],\n",
      "        [-14.4766],\n",
      "        [ -4.6484],\n",
      "        [  2.3965],\n",
      "        [-15.5234],\n",
      "        [-19.1875],\n",
      "        [ -3.8633],\n",
      "        [ -3.7207]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.39:\n",
      "Loss: 0.017671313136816025\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.5078],\n",
      "        [-22.1250],\n",
      "        [ -7.1367],\n",
      "        [ -9.7500],\n",
      "        [-12.5859],\n",
      "        [-12.4141],\n",
      "        [-12.5547],\n",
      "        [-10.3828]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.40:\n",
      "Loss: 0.0014822102384641767\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.3594],\n",
      "        [-19.8281],\n",
      "        [-16.1250],\n",
      "        [-11.0781],\n",
      "        [  3.1855],\n",
      "        [ -8.7109],\n",
      "        [-11.3672],\n",
      "        [-10.5078]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.41:\n",
      "Loss: 0.005122095812112093\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-23.0000],\n",
      "        [  3.9277],\n",
      "        [-14.4844],\n",
      "        [-10.6562],\n",
      "        [-10.3281],\n",
      "        [-20.8125],\n",
      "        [  2.4922],\n",
      "        [-14.1953]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.42:\n",
      "Loss: 0.012379858642816544\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.9219],\n",
      "        [-18.2656],\n",
      "        [ -7.2656],\n",
      "        [ -4.9375],\n",
      "        [ -2.1914],\n",
      "        [ -9.8281],\n",
      "        [-24.8594],\n",
      "        [ -6.6641]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.43:\n",
      "Loss: 0.014389822259545326\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.4062],\n",
      "        [-20.7656],\n",
      "        [ -9.7734],\n",
      "        [ -9.6797],\n",
      "        [  4.2227],\n",
      "        [-12.5078],\n",
      "        [-20.9531],\n",
      "        [-10.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.44:\n",
      "Loss: 0.0018389716278761625\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.7500],\n",
      "        [-10.6484],\n",
      "        [-18.0625],\n",
      "        [ -9.7266],\n",
      "        [ -8.4453],\n",
      "        [-23.5625],\n",
      "        [ -6.7266],\n",
      "        [-12.3047]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.45:\n",
      "Loss: 0.00018795978394336998\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.1055],\n",
      "        [-24.9062],\n",
      "        [-14.6094],\n",
      "        [  1.5264],\n",
      "        [  2.1055],\n",
      "        [-28.7812],\n",
      "        [ -7.0742],\n",
      "        [-16.5000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.46:\n",
      "Loss: 0.03933177888393402\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.0078],\n",
      "        [-11.4531],\n",
      "        [  4.9414],\n",
      "        [-19.2656],\n",
      "        [-11.9531],\n",
      "        [-20.1094],\n",
      "        [ -7.9961],\n",
      "        [-25.8281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.47:\n",
      "Loss: 0.0009361869306303561\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.9922],\n",
      "        [  1.9180],\n",
      "        [-11.3125],\n",
      "        [-11.2031],\n",
      "        [-11.9688],\n",
      "        [-19.5938],\n",
      "        [-25.0938],\n",
      "        [-15.0859]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.48:\n",
      "Loss: 0.01713821105659008\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.2188],\n",
      "        [-14.9688],\n",
      "        [-20.4375],\n",
      "        [-14.8438],\n",
      "        [-15.6172],\n",
      "        [ -9.5000],\n",
      "        [-14.3750],\n",
      "        [ -8.0703]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.49:\n",
      "Loss: 0.0007235566154122353\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c820c19219014667b7ebb949bb0a988d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.3828],\n",
      "        [ -6.0273],\n",
      "        [-17.6875],\n",
      "        [  5.5117],\n",
      "        [-21.1250],\n",
      "        [-19.3438],\n",
      "        [-27.3594],\n",
      "        [-10.0625]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.12:\n",
      "\n",
      "Loss: 0.0008104054140858352\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.7305],\n",
      "        [  5.2891],\n",
      "        [-16.2969],\n",
      "        [  3.4258],\n",
      "        [ 10.5703],\n",
      "        [-10.7109],\n",
      "        [-10.2031],\n",
      "        [-14.6562]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.13:\n",
      "\n",
      "Loss: 1.0950942039489746\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-20.0938],\n",
      "        [-37.4062],\n",
      "        [-16.2656],\n",
      "        [-15.5156],\n",
      "        [-19.6719],\n",
      "        [-16.3438],\n",
      "        [  4.4297],\n",
      "        [-12.4922]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.14:\n",
      "\n",
      "Loss: 0.5551924109458923\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.3984],\n",
      "        [-11.2969],\n",
      "        [-22.7188],\n",
      "        [ -1.8291],\n",
      "        [ -2.8691],\n",
      "        [ 11.7969],\n",
      "        [ -1.3105],\n",
      "        [-11.9688]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.15:\n",
      "\n",
      "Loss: 1.5301774740219116\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  7.9727],\n",
      "        [ -4.8281],\n",
      "        [-15.3359],\n",
      "        [ -6.8828],\n",
      "        [ -5.1133],\n",
      "        [-25.8125],\n",
      "        [-16.0000],\n",
      "        [ -0.2432]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.16:\n",
      "\n",
      "Loss: 0.7134445905685425\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.9531],\n",
      "        [ -7.0156],\n",
      "        [-13.6484],\n",
      "        [-21.6406],\n",
      "        [ 10.6797],\n",
      "        [-24.7656],\n",
      "        [-23.4375],\n",
      "        [  7.9961]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.17:\n",
      "\n",
      "Loss: 0.999674916267395\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.7500],\n",
      "        [-22.6406],\n",
      "        [-19.2031],\n",
      "        [ -9.5312],\n",
      "        [-26.6406],\n",
      "        [ -1.2900],\n",
      "        [-20.2812],\n",
      "        [ -2.9648]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.18:\n",
      "\n",
      "Loss: 0.03670798987150192\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  8.0938],\n",
      "        [ -4.6875],\n",
      "        [-13.6719],\n",
      "        [-22.2969],\n",
      "        [-17.0469],\n",
      "        [ -2.4199],\n",
      "        [-12.0859],\n",
      "        [-14.3047]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.19:\n",
      "\n",
      "Loss: 0.011834312230348587\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 50: 'val_loss' reached 0.51000 (best 0.43000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=1-step=50.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.3516],\n",
      "        [ -2.4863],\n",
      "        [-17.8906],\n",
      "        [ -8.4609],\n",
      "        [-23.1406],\n",
      "        [-19.5938],\n",
      "        [-19.3438],\n",
      "        [  0.1617]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.20:\n",
      "\n",
      "Loss: 0.10718964040279388\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.3984],\n",
      "        [ -8.2812],\n",
      "        [-22.6250],\n",
      "        [ -2.0508],\n",
      "        [-15.1016],\n",
      "        [-14.9531],\n",
      "        [-12.9141],\n",
      "        [-23.8594]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.21:\n",
      "\n",
      "Loss: 0.015168433077633381\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.05000000074505806\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.2734],\n",
      "        [-20.2812],\n",
      "        [ -7.7148],\n",
      "        [-15.4609],\n",
      "        [ -7.2617],\n",
      "        [-20.3594],\n",
      "        [-16.2656],\n",
      "        [-16.5156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.50:\n",
      "Loss: 0.0001754287804942578\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.4688],\n",
      "        [-22.1094],\n",
      "        [-20.4062],\n",
      "        [-20.5938],\n",
      "        [ -8.3438],\n",
      "        [-13.6484],\n",
      "        [ -6.7969],\n",
      "        [ -7.3398]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.51:\n",
      "Loss: 0.0002505744341760874\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.5469],\n",
      "        [ -9.9375],\n",
      "        [ -9.8672],\n",
      "        [-18.1562],\n",
      "        [-28.5156],\n",
      "        [-12.1875],\n",
      "        [-11.4219],\n",
      "        [ -7.0195]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.52:\n",
      "Loss: 0.0001262668811250478\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -0.1562],\n",
      "        [-26.0781],\n",
      "        [-22.6094],\n",
      "        [ -9.1797],\n",
      "        [-27.8594],\n",
      "        [-12.3281],\n",
      "        [-12.5469],\n",
      "        [  4.6914]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.53:\n",
      "Loss: 0.09794548153877258\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.6562],\n",
      "        [-23.9219],\n",
      "        [-17.5625],\n",
      "        [ -2.0312],\n",
      "        [-12.3125],\n",
      "        [-18.0156],\n",
      "        [ -4.7070],\n",
      "        [ -9.0469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.54:\n",
      "Loss: 0.01654628850519657\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.3672],\n",
      "        [-15.3125],\n",
      "        [  9.2344],\n",
      "        [ -9.2344],\n",
      "        [-27.3438],\n",
      "        [ -8.2812],\n",
      "        [-13.4375],\n",
      "        [-13.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.55:\n",
      "Loss: 5.648510705213994e-05\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ 12.5469],\n",
      "        [-17.4844],\n",
      "        [-11.9688],\n",
      "        [-26.1406],\n",
      "        [-16.6562],\n",
      "        [-13.5000],\n",
      "        [ -5.8438],\n",
      "        [-19.9688]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.56:\n",
      "Loss: 0.00036313896998763084\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -0.1567],\n",
      "        [-10.9688],\n",
      "        [-20.3594],\n",
      "        [  7.6484],\n",
      "        [-33.3125],\n",
      "        [  6.2344],\n",
      "        [-39.6562],\n",
      "        [  5.3203]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.57:\n",
      "Loss: 0.09773954749107361\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.6875],\n",
      "        [-10.3906],\n",
      "        [-16.6875],\n",
      "        [-14.5391],\n",
      "        [  6.2617],\n",
      "        [-18.7344],\n",
      "        [ -9.7422],\n",
      "        [ -6.2070]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.58:\n",
      "Loss: 0.0005011666216887534\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.3359],\n",
      "        [-12.6484],\n",
      "        [  5.5391],\n",
      "        [-14.6250],\n",
      "        [-25.0781],\n",
      "        [-14.6641],\n",
      "        [ -9.8125],\n",
      "        [ 12.8516]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.59:\n",
      "Loss: 2.299407482147217\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.3594],\n",
      "        [  9.2266],\n",
      "        [  1.4668],\n",
      "        [-20.5938],\n",
      "        [-11.1094],\n",
      "        [ -6.1328],\n",
      "        [  6.7969],\n",
      "        [-20.9062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.60:\n",
      "Loss: 1.0593278408050537\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  2.2852],\n",
      "        [ -7.4141],\n",
      "        [-12.7266],\n",
      "        [-14.3359],\n",
      "        [-16.3125],\n",
      "        [-16.4688],\n",
      "        [ -5.0391],\n",
      "        [ -1.0977]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.61:\n",
      "Loss: 0.3346312344074249\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  8.6562],\n",
      "        [-10.8828],\n",
      "        [-14.6484],\n",
      "        [-12.7422],\n",
      "        [-19.7656],\n",
      "        [-22.3594],\n",
      "        [-22.0781],\n",
      "        [  2.8281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.62:\n",
      "Loss: 0.36072036623954773\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.9844],\n",
      "        [ -7.2734],\n",
      "        [-28.5312],\n",
      "        [  2.4551],\n",
      "        [ -1.3809],\n",
      "        [-10.5859],\n",
      "        [ -8.9609],\n",
      "        [-36.5312]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.63:\n",
      "Loss: 0.3453216552734375\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Pred: tensor([[-21.7188],\n",
      "        [-15.1172],\n",
      "        [-44.6875],\n",
      "        [  4.4883],\n",
      "        [-21.8125],\n",
      "        [-16.7969],\n",
      "        [ -1.2012],\n",
      "        [ -8.0625]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.64:\n",
      "Loss: 1.1922719478607178\n",
      "Accuracy: 0.75\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.7500],\n",
      "        [-12.8594],\n",
      "        [-14.7266],\n",
      "        [-39.7500],\n",
      "        [-14.1875],\n",
      "        [-22.1875],\n",
      "        [-13.5312],\n",
      "        [  0.4646]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.65:\n",
      "Loss: 1.2127940654754639\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-34.3750],\n",
      "        [-16.7344],\n",
      "        [-17.0625],\n",
      "        [ -7.6250],\n",
      "        [ -5.9766],\n",
      "        [-17.3281],\n",
      "        [ -6.3242],\n",
      "        [-28.3125]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.66:\n",
      "Loss: 0.0006016132538206875\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-19.0781],\n",
      "        [ -8.0156],\n",
      "        [-17.3438],\n",
      "        [ -4.1289],\n",
      "        [ -6.4023],\n",
      "        [-19.9688],\n",
      "        [ -3.1504],\n",
      "        [-38.8125]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.67:\n",
      "Loss: 0.4012865722179413\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.2383],\n",
      "        [-28.6562],\n",
      "        [-27.3750],\n",
      "        [ -7.6602],\n",
      "        [-23.8594],\n",
      "        [  1.0576],\n",
      "        [-11.8672],\n",
      "        [ -0.0407]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.68:\n",
      "Loss: 0.12210962176322937\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-17.5156],\n",
      "        [-28.7344],\n",
      "        [ -9.5234],\n",
      "        [-22.0938],\n",
      "        [ -9.3203],\n",
      "        [ -4.5117],\n",
      "        [ -7.6250],\n",
      "        [  0.9482]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.69:\n",
      "Loss: 1.232806921005249\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.6641],\n",
      "        [ -7.7852],\n",
      "        [ -6.4844],\n",
      "        [ -1.5762],\n",
      "        [  0.8232],\n",
      "        [-10.0703],\n",
      "        [-25.3750],\n",
      "        [-19.7188]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.70:\n",
      "Loss: 0.06923501193523407\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-32.9688],\n",
      "        [-23.7344],\n",
      "        [  0.9390],\n",
      "        [ -7.5586],\n",
      "        [ -0.8984],\n",
      "        [ -9.3516],\n",
      "        [  0.1041],\n",
      "        [ -6.2969]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.71:\n",
      "Loss: 0.16457106173038483\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.2266],\n",
      "        [-17.8594],\n",
      "        [ -2.4121],\n",
      "        [ -4.1406],\n",
      "        [-25.2188],\n",
      "        [ -3.4434],\n",
      "        [ -9.7344],\n",
      "        [ -1.5762]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.72:\n",
      "Loss: 0.04016866534948349\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.3516],\n",
      "        [ -4.3047],\n",
      "        [-13.2266],\n",
      "        [ -4.1719],\n",
      "        [ -3.9766],\n",
      "        [-19.5469],\n",
      "        [ -2.8438],\n",
      "        [-13.2109]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.73:\n",
      "Loss: 0.012986000627279282\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -0.8594],\n",
      "        [ -4.0703],\n",
      "        [-16.2031],\n",
      "        [  1.9062],\n",
      "        [ -4.3984],\n",
      "        [-10.9844],\n",
      "        [ -0.2006],\n",
      "        [-19.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.74:\n",
      "Loss: 0.13983693718910217\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d37213c4df4527818890b88e0da57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.4922],\n",
      "        [ -0.7085],\n",
      "        [-19.8594],\n",
      "        [ -1.5781],\n",
      "        [-13.1719],\n",
      "        [ -1.2568],\n",
      "        [ -5.2461],\n",
      "        [-12.2188]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.22:\n",
      "\n",
      "Loss: 0.10920450836420059\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[  2.2539],\n",
      "        [-12.1875],\n",
      "        [ -0.4644],\n",
      "        [-18.7969],\n",
      "        [  0.9746],\n",
      "        [-29.4375],\n",
      "        [ -5.6836],\n",
      "        [  1.1572]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.23:\n",
      "\n",
      "Loss: 0.14805258810520172\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-29.4844],\n",
      "        [  1.6035],\n",
      "        [-26.7812],\n",
      "        [ -3.5039],\n",
      "        [ -3.0977],\n",
      "        [-13.3516],\n",
      "        [ -2.0684],\n",
      "        [-19.9375]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.24:\n",
      "\n",
      "Loss: 0.04701678454875946\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.4688],\n",
      "        [-11.6875],\n",
      "        [-15.4922],\n",
      "        [ -0.9458],\n",
      "        [-29.9219],\n",
      "        [-20.2188],\n",
      "        [ -5.6562],\n",
      "        [-32.9062]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.25:\n",
      "\n",
      "Loss: 0.04145347699522972\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.5820],\n",
      "        [  0.8433],\n",
      "        [ -0.8936],\n",
      "        [ -2.2285],\n",
      "        [ -0.9790],\n",
      "        [  1.8008],\n",
      "        [-16.1875],\n",
      "        [  1.6855]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.26:\n",
      "\n",
      "Loss: 0.18069306015968323\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.8906],\n",
      "        [  2.2871],\n",
      "        [ -1.3486],\n",
      "        [-28.9844],\n",
      "        [-26.0625],\n",
      "        [ -4.4727],\n",
      "        [  2.0117],\n",
      "        [-21.2344]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.27:\n",
      "\n",
      "Loss: 0.0580509752035141\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-37.0625],\n",
      "        [-33.5000],\n",
      "        [ -3.0977],\n",
      "        [-15.4141],\n",
      "        [  1.0947],\n",
      "        [  1.4766],\n",
      "        [-10.2188],\n",
      "        [-37.7812]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.28:\n",
      "\n",
      "Loss: 0.06732335686683655\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -0.2761],\n",
      "        [-12.8828],\n",
      "        [ -7.3281],\n",
      "        [-28.9531],\n",
      "        [  1.7646],\n",
      "        [-35.8750],\n",
      "        [ -3.9023],\n",
      "        [  1.5635]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.29:\n",
      "\n",
      "Loss: 0.11667969077825546\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -4.0742],\n",
      "        [ -8.7969],\n",
      "        [-36.4688],\n",
      "        [ -0.5542],\n",
      "        [-36.4688],\n",
      "        [-12.1016],\n",
      "        [-13.6484],\n",
      "        [  1.8672]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.30:\n",
      "\n",
      "Loss: 0.5861142873764038\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 75: 'val_loss' reached 0.14000 (best 0.14000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=2-step=75.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.1172],\n",
      "        [-21.3125],\n",
      "        [-13.5078],\n",
      "        [-22.7344],\n",
      "        [-30.1562],\n",
      "        [  1.3320],\n",
      "        [-14.4531],\n",
      "        [-13.1406]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.31:\n",
      "\n",
      "Loss: 0.029279999434947968\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.3700000047683716\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.6172],\n",
      "        [-24.4688],\n",
      "        [ -4.6680],\n",
      "        [ -0.5972],\n",
      "        [ -2.4629],\n",
      "        [ -9.4688],\n",
      "        [ -1.4180],\n",
      "        [ -6.1836]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.75:\n",
      "Loss: 0.09357792139053345\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.8359],\n",
      "        [ -3.9316],\n",
      "        [ -1.9023],\n",
      "        [  0.7993],\n",
      "        [-26.3594],\n",
      "        [ -2.0469],\n",
      "        [ -0.2803],\n",
      "        [-18.3281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.76:\n",
      "Loss: 0.4427863657474518\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.3203],\n",
      "        [-10.0625],\n",
      "        [-22.7344],\n",
      "        [ -3.2324],\n",
      "        [ -5.1250],\n",
      "        [  0.1344],\n",
      "        [ -2.4492],\n",
      "        [ -1.8740]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.77:\n",
      "Loss: 0.12911862134933472\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  1.3711],\n",
      "        [-14.3594],\n",
      "        [ -8.7500],\n",
      "        [ -3.5859],\n",
      "        [ -0.6313],\n",
      "        [  1.7686],\n",
      "        [-12.7812],\n",
      "        [-10.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.78:\n",
      "Loss: 0.10471616685390472\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.2793],\n",
      "        [ -8.2188],\n",
      "        [ -1.9199],\n",
      "        [-20.3438],\n",
      "        [ -0.4614],\n",
      "        [-10.4531],\n",
      "        [ -0.2576],\n",
      "        [ -7.1602]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.79:\n",
      "Loss: 0.16209879517555237\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.0400],\n",
      "        [-13.9922],\n",
      "        [ -9.3984],\n",
      "        [-14.0156],\n",
      "        [ -0.4993],\n",
      "        [ -0.5293],\n",
      "        [ -7.9102],\n",
      "        [ -0.6006]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.80:\n",
      "Loss: 0.2097315490245819\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.0781],\n",
      "        [ -9.0469],\n",
      "        [-12.7500],\n",
      "        [-11.0156],\n",
      "        [ -5.2852],\n",
      "        [ -2.4453],\n",
      "        [ -3.6992],\n",
      "        [ -0.8921]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.81:\n",
      "Loss: 0.05706673488020897\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.8438],\n",
      "        [ -1.2607],\n",
      "        [ -6.4609],\n",
      "        [ -6.1250],\n",
      "        [ -0.6089],\n",
      "        [ -4.4766],\n",
      "        [-24.9219],\n",
      "        [ -7.0820]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.82:\n",
      "Loss: 0.09454573690891266\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.1250],\n",
      "        [ -0.4983],\n",
      "        [ -1.1748],\n",
      "        [ -6.6992],\n",
      "        [ -1.0127],\n",
      "        [-16.6562],\n",
      "        [ -4.1055],\n",
      "        [-14.8438]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.83:\n",
      "Loss: 0.35715681314468384\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.9062],\n",
      "        [  0.9287],\n",
      "        [ -1.5996],\n",
      "        [-24.5469],\n",
      "        [ -4.9180],\n",
      "        [  1.0293],\n",
      "        [ -1.9170],\n",
      "        [ -7.3047]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.84:\n",
      "Loss: 0.360564649105072\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.4727],\n",
      "        [ -0.7607],\n",
      "        [ -3.7832],\n",
      "        [-10.1250],\n",
      "        [ -5.6602],\n",
      "        [ -1.5527],\n",
      "        [ -8.6875],\n",
      "        [-15.6328]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.85:\n",
      "Loss: 0.07539486140012741\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.3086],\n",
      "        [-10.5234],\n",
      "        [ -1.6895],\n",
      "        [ -9.8750],\n",
      "        [ -7.6094],\n",
      "        [  2.2812],\n",
      "        [ -4.0625],\n",
      "        [-12.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.86:\n",
      "Loss: 0.06543789803981781\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.3887],\n",
      "        [ -0.2206],\n",
      "        [-11.9375],\n",
      "        [  2.3281],\n",
      "        [-11.1719],\n",
      "        [ -5.5664],\n",
      "        [ -6.1484],\n",
      "        [ -3.5078]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.87:\n",
      "Loss: 0.12140168994665146\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  1.9473],\n",
      "        [-10.9531],\n",
      "        [ -3.3516],\n",
      "        [ -1.2451],\n",
      "        [  0.4849],\n",
      "        [ -8.5703],\n",
      "        [  2.6543],\n",
      "        [-17.0938]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.88:\n",
      "Loss: 0.12110254913568497\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -5.8203],\n",
      "        [-10.4531],\n",
      "        [-12.8438],\n",
      "        [ -0.8564],\n",
      "        [-11.0781],\n",
      "        [ -1.8936],\n",
      "        [ -5.4297],\n",
      "        [  1.9414]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.89:\n",
      "Loss: 0.07945585250854492\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.6553],\n",
      "        [ -2.4590],\n",
      "        [-23.3594],\n",
      "        [ -1.2549],\n",
      "        [ -3.8516],\n",
      "        [ -6.2266],\n",
      "        [ -1.6377],\n",
      "        [ -1.4062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.90:\n",
      "Loss: 0.11594760417938232\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-11.3516],\n",
      "        [ -1.7979],\n",
      "        [ -2.0488],\n",
      "        [ -6.9258],\n",
      "        [ -1.0205],\n",
      "        [-19.6719],\n",
      "        [ -7.8789],\n",
      "        [  5.7148]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.91:\n",
      "Loss: 0.07337057590484619\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.4609],\n",
      "        [  0.7314],\n",
      "        [ -2.3477],\n",
      "        [ -4.6367],\n",
      "        [ -1.5234],\n",
      "        [ -1.6504],\n",
      "        [ -7.6602],\n",
      "        [-24.4531]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.92:\n",
      "Loss: 0.2000085413455963\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.4844],\n",
      "        [-15.6484],\n",
      "        [ -0.4956],\n",
      "        [-15.0625],\n",
      "        [ -4.6953],\n",
      "        [ -3.1348],\n",
      "        [ -9.5312],\n",
      "        [ -2.0430]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.93:\n",
      "Loss: 0.6431244015693665\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.1875],\n",
      "        [ -7.5859],\n",
      "        [ -5.9883],\n",
      "        [ -1.2754],\n",
      "        [  5.2852],\n",
      "        [-11.9219],\n",
      "        [ -2.5410],\n",
      "        [ -9.1641]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.94:\n",
      "Loss: 0.041293006390333176\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.4941],\n",
      "        [-19.9062],\n",
      "        [-13.0547],\n",
      "        [ -5.2305],\n",
      "        [-11.4609],\n",
      "        [ -1.9102],\n",
      "        [ -5.1328],\n",
      "        [ -1.8379]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.95:\n",
      "Loss: 0.04704098775982857\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.8516],\n",
      "        [-18.3125],\n",
      "        [ -1.4180],\n",
      "        [  3.6699],\n",
      "        [ -3.9844],\n",
      "        [ -3.6094],\n",
      "        [-11.2344],\n",
      "        [ -8.2031]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.96:\n",
      "Loss: 0.035934604704380035\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.2903],\n",
      "        [-12.0156],\n",
      "        [ -9.5625],\n",
      "        [ -2.8672],\n",
      "        [-12.1875],\n",
      "        [ -6.3047],\n",
      "        [-11.8828],\n",
      "        [-10.3906]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.97:\n",
      "Loss: 0.07696850597858429\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-19.6875],\n",
      "        [-14.2266],\n",
      "        [-10.0156],\n",
      "        [ -4.4844],\n",
      "        [  0.7104],\n",
      "        [-22.3438],\n",
      "        [  0.6792],\n",
      "        [ -1.7363]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.98:\n",
      "Loss: 0.12292416393756866\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-18.9688],\n",
      "        [ -6.2031],\n",
      "        [-17.1250],\n",
      "        [-19.5938],\n",
      "        [ -7.0273],\n",
      "        [ -2.7246],\n",
      "        [-14.7109],\n",
      "        [  1.1709]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.99:\n",
      "Loss: 0.04206429049372673\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef2d2ef55d2449cb41440ac22dbf7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  2.2852],\n",
      "        [ -5.1719],\n",
      "        [  1.3291],\n",
      "        [-14.1406],\n",
      "        [-13.6484],\n",
      "        [-11.4141],\n",
      "        [-28.7344],\n",
      "        [-25.1094]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.32:\n",
      "\n",
      "Loss: 0.6886624693870544\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.3438],\n",
      "        [ -8.0547],\n",
      "        [  0.9502],\n",
      "        [ -8.5859],\n",
      "        [-35.4375],\n",
      "        [-22.2656],\n",
      "        [-27.5312],\n",
      "        [-25.6562]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.33:\n",
      "\n",
      "Loss: 0.0409257598221302\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.2051],\n",
      "        [-32.2188],\n",
      "        [-32.4062],\n",
      "        [-10.7109],\n",
      "        [ -2.8730],\n",
      "        [  3.5938],\n",
      "        [ -7.7695],\n",
      "        [-36.3438]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.34:\n",
      "\n",
      "Loss: 0.19371779263019562\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-21.2188],\n",
      "        [ -6.7148],\n",
      "        [-17.4844],\n",
      "        [-21.9219],\n",
      "        [ -9.7031],\n",
      "        [-30.2344],\n",
      "        [-13.2109],\n",
      "        [-11.5234]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.35:\n",
      "\n",
      "Loss: 2.0524067878723145\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.5312],\n",
      "        [-18.4688],\n",
      "        [-13.3750],\n",
      "        [  3.8086],\n",
      "        [-16.7812],\n",
      "        [-42.8125],\n",
      "        [ -8.2422],\n",
      "        [ -0.4341]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.36:\n",
      "\n",
      "Loss: 0.11947053670883179\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-10.2031],\n",
      "        [-22.4062],\n",
      "        [ -7.6055],\n",
      "        [-10.4297],\n",
      "        [  3.3379],\n",
      "        [-19.7188],\n",
      "        [-22.3594],\n",
      "        [  3.7109]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.37:\n",
      "\n",
      "Loss: 0.007452538702636957\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-37.6250],\n",
      "        [ -8.9766],\n",
      "        [-20.7969],\n",
      "        [-15.8672],\n",
      "        [-24.5156],\n",
      "        [-12.6562],\n",
      "        [-43.8750],\n",
      "        [-11.6328]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.38:\n",
      "\n",
      "Loss: 1.731414522510022e-05\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-37.9688],\n",
      "        [  1.3887],\n",
      "        [-41.5000],\n",
      "        [-17.1719],\n",
      "        [  2.4961],\n",
      "        [-31.7188],\n",
      "        [  0.4653],\n",
      "        [ -7.1250]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.39:\n",
      "\n",
      "Loss: 0.09874584525823593\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-31.1406],\n",
      "        [ -7.7891],\n",
      "        [-12.6016],\n",
      "        [ -7.4336],\n",
      "        [ -7.6875],\n",
      "        [-32.1250],\n",
      "        [-23.7969],\n",
      "        [  2.0273]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.40:\n",
      "\n",
      "Loss: 0.015646791085600853\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 100: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-20.9219],\n",
      "        [-17.1406],\n",
      "        [-10.6797],\n",
      "        [ -8.7344],\n",
      "        [-11.5312],\n",
      "        [ -2.9668],\n",
      "        [-13.4062],\n",
      "        [-20.3906]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.41:\n",
      "\n",
      "Loss: 2.0529286861419678\n",
      "Accuracy: 0.75\n",
      ">>> Epoch end loss: 0.15000000596046448\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -5.6445],\n",
      "        [-10.3984],\n",
      "        [-15.4609],\n",
      "        [-21.3125],\n",
      "        [ -9.1797],\n",
      "        [ -5.5508],\n",
      "        [-13.5938],\n",
      "        [  2.6426]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.100:\n",
      "Loss: 0.009537629783153534\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-14.4062],\n",
      "        [-28.8594],\n",
      "        [-13.7734],\n",
      "        [  2.0430],\n",
      "        [-10.2109],\n",
      "        [-10.1875],\n",
      "        [-12.8906],\n",
      "        [  2.3398]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.101:\n",
      "Loss: 0.0267450250685215\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.5117],\n",
      "        [ -5.2812],\n",
      "        [ -5.0469],\n",
      "        [-18.2656],\n",
      "        [ -5.1641],\n",
      "        [  2.9102],\n",
      "        [-32.9062],\n",
      "        [-17.4219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.102:\n",
      "Loss: 0.009281357750296593\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.0000],\n",
      "        [  0.7207],\n",
      "        [-11.6719],\n",
      "        [ -8.7812],\n",
      "        [-36.5938],\n",
      "        [ -8.7266],\n",
      "        [ -7.9492],\n",
      "        [ -5.7578]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.103:\n",
      "Loss: 0.05002504959702492\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-24.0469],\n",
      "        [  2.2090],\n",
      "        [ -8.8516],\n",
      "        [-20.0938],\n",
      "        [ -1.4521],\n",
      "        [-10.8438],\n",
      "        [-18.8125],\n",
      "        [ -8.7656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.104:\n",
      "Loss: 0.03935307264328003\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.2188],\n",
      "        [-26.9219],\n",
      "        [ -6.9805],\n",
      "        [ -5.9648],\n",
      "        [  0.2522],\n",
      "        [ -8.0000],\n",
      "        [-24.1094],\n",
      "        [-11.9375]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.105:\n",
      "Loss: 0.07235625386238098\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.8438],\n",
      "        [-17.6562],\n",
      "        [ -9.3203],\n",
      "        [  5.4648],\n",
      "        [-21.2031],\n",
      "        [ -5.9336],\n",
      "        [ -8.3203],\n",
      "        [-24.9688]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.106:\n",
      "Loss: 0.0009003339800983667\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.2227],\n",
      "        [ -4.4180],\n",
      "        [-17.2188],\n",
      "        [-25.8750],\n",
      "        [  5.3633],\n",
      "        [-21.5938],\n",
      "        [-11.1562],\n",
      "        [-22.7500]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.107:\n",
      "Loss: 0.002332190750166774\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.6523],\n",
      "        [-25.5000],\n",
      "        [-15.7578],\n",
      "        [ -7.3047],\n",
      "        [-16.4375],\n",
      "        [-15.2422],\n",
      "        [ -1.7773],\n",
      "        [ -5.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.108:\n",
      "Loss: 0.020248809829354286\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.5547],\n",
      "        [-11.2031],\n",
      "        [  5.9453],\n",
      "        [-16.5156],\n",
      "        [-10.7969],\n",
      "        [-22.3594],\n",
      "        [ -9.6719],\n",
      "        [-22.4375]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.109:\n",
      "Loss: 0.0016468542162328959\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.1406],\n",
      "        [ -7.9766],\n",
      "        [  4.1523],\n",
      "        [-15.2266],\n",
      "        [  3.4785],\n",
      "        [-24.3906],\n",
      "        [-21.3281],\n",
      "        [-15.9219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.110:\n",
      "Loss: 0.005792043171823025\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.3711],\n",
      "        [ -4.6836],\n",
      "        [  8.4453],\n",
      "        [-21.7031],\n",
      "        [-21.1719],\n",
      "        [ -8.8359],\n",
      "        [-32.2500],\n",
      "        [ -7.7344]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.111:\n",
      "Loss: 0.0014637307031080127\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.7305],\n",
      "        [ -7.2109],\n",
      "        [-36.7812],\n",
      "        [-12.3047],\n",
      "        [ -5.8867],\n",
      "        [-13.2734],\n",
      "        [  5.7578],\n",
      "        [-19.6094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.112:\n",
      "Loss: 0.7216581702232361\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.6406],\n",
      "        [  9.1094],\n",
      "        [ -6.6797],\n",
      "        [-14.0078],\n",
      "        [-30.2500],\n",
      "        [ -9.5312],\n",
      "        [-13.2969],\n",
      "        [-14.0859]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.113:\n",
      "Loss: 0.00018023420125246048\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.3750],\n",
      "        [ -8.3438],\n",
      "        [ -6.4688],\n",
      "        [-22.0781],\n",
      "        [-12.6719],\n",
      "        [-12.7812],\n",
      "        [-13.4453],\n",
      "        [-17.5469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.114:\n",
      "Loss: 0.00022440674365498126\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  7.7891],\n",
      "        [-12.9609],\n",
      "        [-11.9688],\n",
      "        [-29.5781],\n",
      "        [-24.2031],\n",
      "        [-26.5000],\n",
      "        [ -4.6992],\n",
      "        [ -8.8516]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.115:\n",
      "Loss: 0.0012033996172249317\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.7969],\n",
      "        [-27.7656],\n",
      "        [-14.4531],\n",
      "        [  8.1094],\n",
      "        [-11.1172],\n",
      "        [-12.3828],\n",
      "        [-19.5469],\n",
      "        [-10.1250]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.116:\n",
      "Loss: 4.504044045461342e-05\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.6953],\n",
      "        [-11.8438],\n",
      "        [-10.9688],\n",
      "        [  1.3545],\n",
      "        [ -9.7734],\n",
      "        [-18.7969],\n",
      "        [ -8.2188],\n",
      "        [-35.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.117:\n",
      "Loss: 0.19805358350276947\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.2500],\n",
      "        [ -6.6797],\n",
      "        [ -3.6895],\n",
      "        [-21.5781],\n",
      "        [ -9.8516],\n",
      "        [ -6.7891],\n",
      "        [-18.8594],\n",
      "        [-33.7812]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.118:\n",
      "Loss: 0.0033890223130583763\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.1641],\n",
      "        [-15.5000],\n",
      "        [ -4.5859],\n",
      "        [-10.6250],\n",
      "        [-34.4062],\n",
      "        [ -8.8516],\n",
      "        [-20.7188],\n",
      "        [-11.8984]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.119:\n",
      "Loss: 0.0012897249544039369\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-25.9375],\n",
      "        [-14.3047],\n",
      "        [  1.8311],\n",
      "        [-26.9062],\n",
      "        [-15.9453],\n",
      "        [  2.7051],\n",
      "        [-14.6641],\n",
      "        [-10.8906]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.120:\n",
      "Loss: 0.0266718789935112\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-31.4375],\n",
      "        [-18.6562],\n",
      "        [ -2.7578],\n",
      "        [-12.7031],\n",
      "        [-13.6250],\n",
      "        [ -8.3125],\n",
      "        [-15.2109],\n",
      "        [-19.9375]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.121:\n",
      "Loss: 0.3524452745914459\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-25.5469],\n",
      "        [  2.1172],\n",
      "        [-16.3594],\n",
      "        [-11.1797],\n",
      "        [-18.0625],\n",
      "        [-20.4375],\n",
      "        [-12.1328],\n",
      "        [-15.0625]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.122:\n",
      "Loss: 0.014209795743227005\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.1562],\n",
      "        [-18.0625],\n",
      "        [-12.5000],\n",
      "        [-18.0156],\n",
      "        [-26.1406],\n",
      "        [-14.6484],\n",
      "        [  2.4121],\n",
      "        [-15.5547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.123:\n",
      "Loss: 0.010729859583079815\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.0781],\n",
      "        [-19.3281],\n",
      "        [-28.3125],\n",
      "        [ -7.8164],\n",
      "        [-11.1016],\n",
      "        [ -8.5000],\n",
      "        [-10.5703],\n",
      "        [-14.8281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.124:\n",
      "Loss: 3.5391433238983154\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afbc4d022ce405f82262f6ebb76c99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.1875],\n",
      "        [-15.3125],\n",
      "        [-11.7109],\n",
      "        [-15.2109],\n",
      "        [-13.6797],\n",
      "        [  4.4219],\n",
      "        [-16.0625],\n",
      "        [-13.7812]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.42:\n",
      "\n",
      "Loss: 0.0014941341942176223\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  1.7754],\n",
      "        [-17.0781],\n",
      "        [-20.1875],\n",
      "        [-15.9531],\n",
      "        [ -7.7734],\n",
      "        [-16.2344],\n",
      "        [-17.1406],\n",
      "        [-16.7500]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.43:\n",
      "\n",
      "Loss: 0.019615814089775085\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.0391],\n",
      "        [-13.4844],\n",
      "        [ -8.5469],\n",
      "        [ -8.0781],\n",
      "        [ -0.8164],\n",
      "        [ -8.6797],\n",
      "        [-24.5312],\n",
      "        [-23.9844]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.44:\n",
      "\n",
      "Loss: 1.2328535318374634\n",
      "Accuracy: 0.75\n",
      "Label: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.9297],\n",
      "        [ -9.5469],\n",
      "        [  4.1016],\n",
      "        [  1.8545],\n",
      "        [  4.2422],\n",
      "        [-11.8984],\n",
      "        [-10.9453],\n",
      "        [-12.3672]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.45:\n",
      "\n",
      "Loss: 0.02292679250240326\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-15.7344],\n",
      "        [  2.2148],\n",
      "        [-16.9688],\n",
      "        [-13.7969],\n",
      "        [-13.7422],\n",
      "        [  4.5312],\n",
      "        [-12.5078],\n",
      "        [ -1.0215]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.46:\n",
      "\n",
      "Loss: 0.18041767179965973\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.3828],\n",
      "        [-20.1250],\n",
      "        [ -1.2598],\n",
      "        [-12.0547],\n",
      "        [ -9.5156],\n",
      "        [-17.9844],\n",
      "        [-11.6016],\n",
      "        [-11.5781]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.47:\n",
      "\n",
      "Loss: 1.3781577348709106\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.7656],\n",
      "        [-24.9062],\n",
      "        [  3.2148],\n",
      "        [-16.9688],\n",
      "        [-20.0312],\n",
      "        [-17.8906],\n",
      "        [ -6.1875],\n",
      "        [-15.2734]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.48:\n",
      "\n",
      "Loss: 0.7786161303520203\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.0098],\n",
      "        [-11.2266],\n",
      "        [-11.2891],\n",
      "        [-21.6250],\n",
      "        [-22.2188],\n",
      "        [-19.1875],\n",
      "        [-21.4375],\n",
      "        [-13.3281]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.49:\n",
      "\n",
      "Loss: 0.3822399377822876\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.6875],\n",
      "        [-18.7969],\n",
      "        [-17.7344],\n",
      "        [-15.6484],\n",
      "        [-11.7812],\n",
      "        [-11.1953],\n",
      "        [-21.6250],\n",
      "        [-14.1641]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.50:\n",
      "\n",
      "Loss: 2.8312051654211245e-06\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 125: 'val_loss' reached 0.40000 (best 0.14000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=4-step=125-v1.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.1719],\n",
      "        [-10.4922],\n",
      "        [-19.6875],\n",
      "        [-21.5000],\n",
      "        [-17.4531],\n",
      "        [-17.6406],\n",
      "        [-15.0234],\n",
      "        [-13.3828]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.51:\n",
      "\n",
      "Loss: 3.710340706675197e-06\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.20000000298023224\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.6562],\n",
      "        [-11.5625],\n",
      "        [ -7.1758],\n",
      "        [-15.5547],\n",
      "        [ -8.1406],\n",
      "        [-33.5938],\n",
      "        [ -9.3672],\n",
      "        [ -8.7422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.125:\n",
      "Loss: 0.00017185563046950847\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.9062],\n",
      "        [-11.0156],\n",
      "        [-12.4219],\n",
      "        [  2.8652],\n",
      "        [-14.2969],\n",
      "        [-20.6875],\n",
      "        [ -7.3594],\n",
      "        [-11.1641]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.126:\n",
      "Loss: 0.0070100328885018826\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.0703],\n",
      "        [ -9.7266],\n",
      "        [-10.6641],\n",
      "        [-10.2031],\n",
      "        [-13.7031],\n",
      "        [-12.1406],\n",
      "        [-11.0938],\n",
      "        [ -3.2637]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.127:\n",
      "Loss: 0.004748610779643059\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.7344],\n",
      "        [  2.9551],\n",
      "        [-10.9453],\n",
      "        [-11.4297],\n",
      "        [ -7.7188],\n",
      "        [ -8.3594],\n",
      "        [-13.3750],\n",
      "        [ -6.3906]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.128:\n",
      "Loss: 0.006643537897616625\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.6367],\n",
      "        [ -8.1719],\n",
      "        [ -6.4336],\n",
      "        [ -6.4258],\n",
      "        [ -8.2422],\n",
      "        [-10.5312],\n",
      "        [ -6.0195],\n",
      "        [ -7.6836]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.129:\n",
      "Loss: 0.0020408285781741142\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.4531],\n",
      "        [ -7.7109],\n",
      "        [ -6.8633],\n",
      "        [ -8.9531],\n",
      "        [ -8.3047],\n",
      "        [-12.7500],\n",
      "        [  4.5820],\n",
      "        [-10.8828]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.130:\n",
      "Loss: 0.0015357991214841604\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-10.8047],\n",
      "        [ -8.5156],\n",
      "        [-12.7188],\n",
      "        [ -8.0938],\n",
      "        [  2.7637],\n",
      "        [ -8.4688],\n",
      "        [ -6.8555],\n",
      "        [ -0.7642]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.131:\n",
      "Loss: 0.1511816680431366\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.8105],\n",
      "        [ -8.0781],\n",
      "        [-10.7031],\n",
      "        [ -7.6484],\n",
      "        [ -6.7773],\n",
      "        [ -5.7188],\n",
      "        [ -2.7793],\n",
      "        [ -0.3782]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.132:\n",
      "Loss: 0.0807151049375534\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-3.4883],\n",
      "        [-5.1328],\n",
      "        [-5.7539],\n",
      "        [ 0.7251],\n",
      "        [-7.2773],\n",
      "        [-6.1094],\n",
      "        [-6.5820],\n",
      "        [-7.1680]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.133:\n",
      "Loss: 0.14552929997444153\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.4785],\n",
      "        [ -0.6870],\n",
      "        [-11.6484],\n",
      "        [ -4.8633],\n",
      "        [ -1.2285],\n",
      "        [ -8.5625],\n",
      "        [ -8.5703],\n",
      "        [ -2.3301]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.134:\n",
      "Loss: 1.176028847694397\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.2539],\n",
      "        [-8.8281],\n",
      "        [-3.9863],\n",
      "        [-4.5859],\n",
      "        [-2.5684],\n",
      "        [-2.2578],\n",
      "        [-3.2734],\n",
      "        [ 0.6646]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.135:\n",
      "Loss: 0.1650940328836441\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.8936],\n",
      "        [ 4.2227],\n",
      "        [-9.0547],\n",
      "        [-1.0537],\n",
      "        [-5.0547],\n",
      "        [-3.7305],\n",
      "        [-6.3945],\n",
      "        [-7.4727]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.136:\n",
      "Loss: 0.06078634038567543\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.3857],\n",
      "        [-4.9570],\n",
      "        [-1.3418],\n",
      "        [ 0.1365],\n",
      "        [-8.2344],\n",
      "        [-1.3613],\n",
      "        [-3.9121],\n",
      "        [-5.0781]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.137:\n",
      "Loss: 0.18508028984069824\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-4.9023],\n",
      "        [-7.8711],\n",
      "        [-3.8105],\n",
      "        [-6.0312],\n",
      "        [-5.8555],\n",
      "        [-4.1953],\n",
      "        [-1.4629],\n",
      "        [ 2.9648]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.138:\n",
      "Loss: 0.03855758160352707\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.5820],\n",
      "        [-1.1475],\n",
      "        [-4.8477],\n",
      "        [-4.8164],\n",
      "        [-8.8516],\n",
      "        [-5.2070],\n",
      "        [ 2.0586],\n",
      "        [-4.6406]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.139:\n",
      "Loss: 0.19726531207561493\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.4590],\n",
      "        [-3.3652],\n",
      "        [-2.8652],\n",
      "        [ 0.9585],\n",
      "        [-5.2383],\n",
      "        [-5.7070],\n",
      "        [-4.7812],\n",
      "        [-6.9922]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.140:\n",
      "Loss: 0.06423909962177277\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.3984],\n",
      "        [-11.8984],\n",
      "        [ -2.6562],\n",
      "        [ -4.2461],\n",
      "        [ -7.3867],\n",
      "        [  1.3867],\n",
      "        [ -2.9766],\n",
      "        [ -4.1367]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.141:\n",
      "Loss: 0.05728568881750107\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-1.1045],\n",
      "        [-5.5078],\n",
      "        [-7.5469],\n",
      "        [-3.2969],\n",
      "        [-5.9492],\n",
      "        [-2.9316],\n",
      "        [-2.9512],\n",
      "        [-2.9805]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.142:\n",
      "Loss: 0.19832926988601685\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.0234],\n",
      "        [-0.4888],\n",
      "        [-8.3984],\n",
      "        [-1.5918],\n",
      "        [-6.1797],\n",
      "        [-4.6289],\n",
      "        [-1.9463],\n",
      "        [-4.3789]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.143:\n",
      "Loss: 0.10299885272979736\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.4883],\n",
      "        [-5.7734],\n",
      "        [-4.5547],\n",
      "        [-4.9688],\n",
      "        [ 1.6182],\n",
      "        [ 0.3647],\n",
      "        [-8.8203],\n",
      "        [-3.7734]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.144:\n",
      "Loss: 0.09401252120733261\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.3184],\n",
      "        [ -2.0664],\n",
      "        [ -7.0195],\n",
      "        [ -3.4570],\n",
      "        [  1.8926],\n",
      "        [-10.5469],\n",
      "        [ -5.2305],\n",
      "        [ -3.8242]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.145:\n",
      "Loss: 0.04425764083862305\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.9883],\n",
      "        [-4.8359],\n",
      "        [-4.4297],\n",
      "        [ 2.6504],\n",
      "        [-9.4844],\n",
      "        [-2.5898],\n",
      "        [ 0.8271],\n",
      "        [-6.9180]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.146:\n",
      "Loss: 0.06583496928215027\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.7734],\n",
      "        [ -4.6133],\n",
      "        [-11.3281],\n",
      "        [ -4.7773],\n",
      "        [ -7.0234],\n",
      "        [  4.3086],\n",
      "        [ -6.8477],\n",
      "        [ -4.0664]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.147:\n",
      "Loss: 0.006374272517859936\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.1875],\n",
      "        [-5.9062],\n",
      "        [-7.5938],\n",
      "        [-8.5000],\n",
      "        [ 3.0820],\n",
      "        [ 0.9736],\n",
      "        [-9.5391],\n",
      "        [-6.5781]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.148:\n",
      "Loss: 0.04696552827954292\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-3.6328],\n",
      "        [-5.6250],\n",
      "        [-4.5586],\n",
      "        [-8.9922],\n",
      "        [-4.4688],\n",
      "        [-5.2539],\n",
      "        [-6.0469],\n",
      "        [-8.0781]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.149:\n",
      "Loss: 0.007440933957695961\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7dde677e9745e0a8ce4cde84a83326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.2031],\n",
      "        [-11.6250],\n",
      "        [ -4.6016],\n",
      "        [-11.4609],\n",
      "        [ -5.8711],\n",
      "        [-10.9844],\n",
      "        [ -6.4883],\n",
      "        [ -6.2812]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.52:\n",
      "\n",
      "Loss: 0.002121439203619957\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.0234],\n",
      "        [ -7.7773],\n",
      "        [ -7.0547],\n",
      "        [ -8.2188],\n",
      "        [ -8.5000],\n",
      "        [ -9.0391],\n",
      "        [-10.5078],\n",
      "        [ -4.1953]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.53:\n",
      "\n",
      "Loss: 0.00211237370967865\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.7070],\n",
      "        [ -8.9219],\n",
      "        [ -3.1328],\n",
      "        [-11.1953],\n",
      "        [ -6.9180],\n",
      "        [-10.3203],\n",
      "        [ -8.9141],\n",
      "        [ -5.2305]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.54:\n",
      "\n",
      "Loss: 0.006220194511115551\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.1797],\n",
      "        [  6.5742],\n",
      "        [  9.1328],\n",
      "        [ -4.1641],\n",
      "        [ -6.5977],\n",
      "        [  5.1094],\n",
      "        [-10.3047],\n",
      "        [ -8.4688]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.55:\n",
      "\n",
      "Loss: 0.0030741593800485134\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.3281],\n",
      "        [  4.0898],\n",
      "        [ -8.0703],\n",
      "        [-10.6562],\n",
      "        [-11.0312],\n",
      "        [ -8.7344],\n",
      "        [ -9.6016],\n",
      "        [ -9.1016]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.56:\n",
      "\n",
      "Loss: 0.0021660439670085907\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.1797],\n",
      "        [  6.4727],\n",
      "        [ -8.2656],\n",
      "        [  5.3359],\n",
      "        [-11.2734],\n",
      "        [-10.3750],\n",
      "        [ -3.5371],\n",
      "        [-12.1562]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.57:\n",
      "\n",
      "Loss: 0.004418761469423771\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.4922],\n",
      "        [ 6.8125],\n",
      "        [-7.9805],\n",
      "        [-7.0000],\n",
      "        [-8.4141],\n",
      "        [-9.1797],\n",
      "        [-9.9844],\n",
      "        [-7.6250]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.58:\n",
      "\n",
      "Loss: 0.00042708986438810825\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ 11.1484],\n",
      "        [-11.5234],\n",
      "        [ -4.8828],\n",
      "        [ -6.1211],\n",
      "        [ -4.3398],\n",
      "        [ -9.4688],\n",
      "        [-10.5547],\n",
      "        [ -1.6367]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.59:\n",
      "\n",
      "Loss: 0.2296709418296814\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 150: 'val_loss' reached 0.03000 (best 0.03000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=5-step=150-v2.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.6484],\n",
      "        [ -6.1367],\n",
      "        [ -6.6133],\n",
      "        [-10.9688],\n",
      "        [  6.5195],\n",
      "        [-10.0312],\n",
      "        [ -6.8828],\n",
      "        [ -6.6602]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.60:\n",
      "\n",
      "Loss: 0.0009394786320626736\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.1172],\n",
      "        [ -7.8398],\n",
      "        [ -9.0859],\n",
      "        [ -5.2734],\n",
      "        [ -8.2422],\n",
      "        [ -9.3750],\n",
      "        [ -7.2461],\n",
      "        [ -6.5820]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.61:\n",
      "\n",
      "Loss: 0.0010131443850696087\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.11999999731779099\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.0117],\n",
      "        [-3.0801],\n",
      "        [-3.9570],\n",
      "        [-5.3125],\n",
      "        [-4.9453],\n",
      "        [-7.2930],\n",
      "        [-8.5000],\n",
      "        [-8.1328]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.150:\n",
      "Loss: 0.009937906637787819\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.6836],\n",
      "        [-7.3125],\n",
      "        [-5.8359],\n",
      "        [-5.8750],\n",
      "        [ 1.0645],\n",
      "        [-4.7383],\n",
      "        [-3.9766],\n",
      "        [-9.1016]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.151:\n",
      "Loss: 0.04241582751274109\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-3.9453],\n",
      "        [-6.1992],\n",
      "        [-8.5312],\n",
      "        [-7.5508],\n",
      "        [-7.4922],\n",
      "        [-8.0156],\n",
      "        [-5.9336],\n",
      "        [ 6.7461]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.152:\n",
      "Loss: 0.003327455371618271\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.4102],\n",
      "        [  0.4297],\n",
      "        [ -9.2031],\n",
      "        [-11.2266],\n",
      "        [ -8.5156],\n",
      "        [ -6.8867],\n",
      "        [  5.5312],\n",
      "        [ -8.5000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.153:\n",
      "Loss: 0.06341295689344406\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.6016],\n",
      "        [ -6.0938],\n",
      "        [ -6.8398],\n",
      "        [  4.9609],\n",
      "        [ -8.2344],\n",
      "        [  1.7676],\n",
      "        [ -8.0156],\n",
      "        [-13.7422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.154:\n",
      "Loss: 0.021069105714559555\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-10.7188],\n",
      "        [ -6.6016],\n",
      "        [ -5.5391],\n",
      "        [ -8.8125],\n",
      "        [ -6.8164],\n",
      "        [-10.1250],\n",
      "        [ -5.5547],\n",
      "        [  6.9727]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.155:\n",
      "Loss: 0.0014230639208108187\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.9961],\n",
      "        [-6.9883],\n",
      "        [-6.2109],\n",
      "        [-4.7656],\n",
      "        [-6.2461],\n",
      "        [-9.0547],\n",
      "        [-2.6191],\n",
      "        [-5.5859]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.156:\n",
      "Loss: 0.011056656017899513\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.8281],\n",
      "        [ -1.8564],\n",
      "        [ -7.0430],\n",
      "        [-12.1016],\n",
      "        [-11.1406],\n",
      "        [ -2.3359],\n",
      "        [ -7.2461],\n",
      "        [ -3.0820]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.157:\n",
      "Loss: 0.26755455136299133\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.7188],\n",
      "        [ -6.9297],\n",
      "        [ -8.5234],\n",
      "        [ -8.5703],\n",
      "        [ -7.3750],\n",
      "        [ -2.2773],\n",
      "        [ -5.2695],\n",
      "        [  7.9844]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.158:\n",
      "Loss: 0.01313756126910448\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.6719],\n",
      "        [ -6.6484],\n",
      "        [  1.1836],\n",
      "        [-10.2422],\n",
      "        [-12.3281],\n",
      "        [ -7.3125],\n",
      "        [  1.9102],\n",
      "        [ -6.0234]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.159:\n",
      "Loss: 0.4379764497280121\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-10.7812],\n",
      "        [ -8.9766],\n",
      "        [ -4.7422],\n",
      "        [ -5.4844],\n",
      "        [-13.9531],\n",
      "        [ -4.2109],\n",
      "        [ -7.8555],\n",
      "        [  8.6875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.160:\n",
      "Loss: 0.0035315053537487984\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.2031],\n",
      "        [  6.2812],\n",
      "        [  3.9863],\n",
      "        [ -5.2422],\n",
      "        [-13.4297],\n",
      "        [ -7.3672],\n",
      "        [ -8.0547],\n",
      "        [-12.5703]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.161:\n",
      "Loss: 0.003316580317914486\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.6094],\n",
      "        [  3.9180],\n",
      "        [ -6.4609],\n",
      "        [ -6.1523],\n",
      "        [-10.2734],\n",
      "        [ -4.0664],\n",
      "        [ -5.6406],\n",
      "        [ -9.5234]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.162:\n",
      "Loss: 0.49525701999664307\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.7344],\n",
      "        [ -8.2656],\n",
      "        [ -9.2188],\n",
      "        [  0.0364],\n",
      "        [ -6.6250],\n",
      "        [ -3.4082],\n",
      "        [-10.8047],\n",
      "        [ -3.1309]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.163:\n",
      "Loss: 0.09856810420751572\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.5195],\n",
      "        [-0.5894],\n",
      "        [-4.9453],\n",
      "        [-8.8984],\n",
      "        [-9.8828],\n",
      "        [-9.7656],\n",
      "        [-7.4336],\n",
      "        [-9.3594]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.164:\n",
      "Loss: 0.05634494125843048\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.0000],\n",
      "        [-15.7656],\n",
      "        [  1.9512],\n",
      "        [-12.0469],\n",
      "        [-10.0312],\n",
      "        [ -0.8345],\n",
      "        [ -1.2334],\n",
      "        [ -6.4570]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.165:\n",
      "Loss: 0.35262876749038696\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.4766],\n",
      "        [ -4.7539],\n",
      "        [ -6.1250],\n",
      "        [-15.9688],\n",
      "        [ -6.0938],\n",
      "        [ -1.6318],\n",
      "        [ -1.4834],\n",
      "        [-11.6953]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.166:\n",
      "Loss: 0.04954036325216293\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.5098],\n",
      "        [ -8.3828],\n",
      "        [ -2.2344],\n",
      "        [ -8.5156],\n",
      "        [-15.8359],\n",
      "        [ -1.4814],\n",
      "        [ -9.0703],\n",
      "        [ -7.3633]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.167:\n",
      "Loss: 0.04214680194854736\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.8438],\n",
      "        [  3.1484],\n",
      "        [ -8.8359],\n",
      "        [ -9.6953],\n",
      "        [ -9.1484],\n",
      "        [ -9.8359],\n",
      "        [ -5.3789],\n",
      "        [ -5.1875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.168:\n",
      "Loss: 0.006571286357939243\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.5107],\n",
      "        [ -8.3828],\n",
      "        [ -4.5859],\n",
      "        [ -7.6133],\n",
      "        [ -6.6953],\n",
      "        [-12.1875],\n",
      "        [ -4.1641],\n",
      "        [ -9.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.169:\n",
      "Loss: 0.06221114471554756\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.5000],\n",
      "        [ -7.5586],\n",
      "        [ -8.1719],\n",
      "        [ -3.8262],\n",
      "        [ -6.6367],\n",
      "        [ -5.5586],\n",
      "        [-10.4297],\n",
      "        [ -7.0977]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.170:\n",
      "Loss: 0.003572473069652915\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.0781],\n",
      "        [  2.0156],\n",
      "        [ -7.8320],\n",
      "        [-12.2422],\n",
      "        [  2.1602],\n",
      "        [-15.3359],\n",
      "        [-11.1250],\n",
      "        [ -9.4219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.171:\n",
      "Loss: 0.6648803353309631\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.5977],\n",
      "        [ -5.8750],\n",
      "        [ -5.8125],\n",
      "        [ -1.9688],\n",
      "        [ -7.9258],\n",
      "        [ -6.2422],\n",
      "        [-18.4844],\n",
      "        [ -7.4062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.172:\n",
      "Loss: 0.01759624108672142\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.6016],\n",
      "        [ -6.9570],\n",
      "        [ -7.6914],\n",
      "        [-12.6250],\n",
      "        [ -5.5312],\n",
      "        [ -2.7988],\n",
      "        [ -8.5781],\n",
      "        [ -6.7070]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.173:\n",
      "Loss: 0.008694952353835106\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  2.6992],\n",
      "        [ -4.8242],\n",
      "        [-21.4531],\n",
      "        [ -5.0742],\n",
      "        [ -3.0645],\n",
      "        [-13.8203],\n",
      "        [ -9.7891],\n",
      "        [ -4.8828]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.174:\n",
      "Loss: 0.016569582745432854\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f92c53d61b04775857619c3b0eeba59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-13.3281],\n",
      "        [ -6.7148],\n",
      "        [-12.0938],\n",
      "        [ -8.4219],\n",
      "        [-10.6016],\n",
      "        [-13.3516],\n",
      "        [-13.2188],\n",
      "        [  4.2031]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.62:\n",
      "\n",
      "Loss: 0.0020382192451506853\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.6875],\n",
      "        [  1.6104],\n",
      "        [-15.4375],\n",
      "        [-11.4688],\n",
      "        [ -6.2070],\n",
      "        [-12.7656],\n",
      "        [-13.8516],\n",
      "        [-11.7500]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.63:\n",
      "\n",
      "Loss: 0.023033389821648598\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.1875],\n",
      "        [ -9.3750],\n",
      "        [-10.6719],\n",
      "        [-12.7344],\n",
      "        [-10.6484],\n",
      "        [  3.1055],\n",
      "        [  3.0156],\n",
      "        [-13.4766]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.64:\n",
      "\n",
      "Loss: 0.01336086355149746\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[  0.4263],\n",
      "        [  2.4668],\n",
      "        [ -3.4199],\n",
      "        [-15.6172],\n",
      "        [ -3.6055],\n",
      "        [-16.1875],\n",
      "        [ -9.7734],\n",
      "        [  2.9629]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.65:\n",
      "\n",
      "Loss: 0.08668030798435211\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-13.3672],\n",
      "        [-11.2344],\n",
      "        [-12.5781],\n",
      "        [ -7.8906],\n",
      "        [ -6.8984],\n",
      "        [-12.7578],\n",
      "        [ -4.5078],\n",
      "        [  2.9473]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.66:\n",
      "\n",
      "Loss: 0.007939803414046764\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.6602],\n",
      "        [-14.6797],\n",
      "        [ -7.9688],\n",
      "        [-12.9219],\n",
      "        [-12.6172],\n",
      "        [ -9.7656],\n",
      "        [ -5.0938],\n",
      "        [ -7.2109]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.67:\n",
      "\n",
      "Loss: 0.002085575135424733\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.8047],\n",
      "        [ -6.6914],\n",
      "        [ -6.1211],\n",
      "        [  3.5039],\n",
      "        [-13.4766],\n",
      "        [-10.8828],\n",
      "        [  1.3701],\n",
      "        [ -7.9922]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.68:\n",
      "\n",
      "Loss: 0.03247872367501259\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.5508],\n",
      "        [  3.2637],\n",
      "        [-12.2109],\n",
      "        [ -4.6875],\n",
      "        [-13.0000],\n",
      "        [ -8.2656],\n",
      "        [  3.1660],\n",
      "        [ -8.5469]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.69:\n",
      "\n",
      "Loss: 0.011542964726686478\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.8086],\n",
      "        [ -7.6562],\n",
      "        [-10.8984],\n",
      "        [ -4.2461],\n",
      "        [ -9.9609],\n",
      "        [-13.0938],\n",
      "        [-13.4688],\n",
      "        [-11.3672]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.70:\n",
      "\n",
      "Loss: 0.004588630981743336\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 175: 'val_loss' reached 0.02000 (best 0.02000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=6-step=175.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.1797],\n",
      "        [-12.2891],\n",
      "        [ -6.5898],\n",
      "        [  5.0586],\n",
      "        [-11.5469],\n",
      "        [-11.6562],\n",
      "        [ -9.3984],\n",
      "        [-11.9219]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.71:\n",
      "\n",
      "Loss: 0.0009904110338538885\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.10999999940395355\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.8477],\n",
      "        [ -6.6992],\n",
      "        [ -4.8320],\n",
      "        [-13.9062],\n",
      "        [ -4.7734],\n",
      "        [ -5.1641],\n",
      "        [  3.0254],\n",
      "        [ -3.9922]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.175:\n",
      "Loss: 0.012099177576601505\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.6836],\n",
      "        [-7.3672],\n",
      "        [-8.2188],\n",
      "        [-7.9883],\n",
      "        [-2.5977],\n",
      "        [-3.5195],\n",
      "        [-6.7969],\n",
      "        [-7.6680]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.176:\n",
      "Loss: 0.013401255011558533\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.5820],\n",
      "        [-13.7656],\n",
      "        [ -3.5176],\n",
      "        [ -3.6289],\n",
      "        [ -4.6875],\n",
      "        [ -8.8750],\n",
      "        [ -5.4648],\n",
      "        [ -8.2578]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.177:\n",
      "Loss: 0.00882677361369133\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.5137],\n",
      "        [ -8.9922],\n",
      "        [-10.1328],\n",
      "        [ -9.6719],\n",
      "        [ -6.2266],\n",
      "        [-10.7188],\n",
      "        [ -4.4570],\n",
      "        [ -7.2656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.178:\n",
      "Loss: 0.0054756030440330505\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.9453],\n",
      "        [ -7.7969],\n",
      "        [ -7.2227],\n",
      "        [  3.8262],\n",
      "        [ -5.8086],\n",
      "        [ -8.3438],\n",
      "        [ -7.8711],\n",
      "        [ -5.0859]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.179:\n",
      "Loss: 0.004060809034854174\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.5078],\n",
      "        [-5.8906],\n",
      "        [-6.4414],\n",
      "        [-2.8965],\n",
      "        [-9.5781],\n",
      "        [-3.4336],\n",
      "        [-6.2461],\n",
      "        [-6.4961]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.180:\n",
      "Loss: 0.011858261190354824\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.0957],\n",
      "        [-11.9766],\n",
      "        [ -2.2793],\n",
      "        [  3.4512],\n",
      "        [ -9.2500],\n",
      "        [  3.5156],\n",
      "        [-11.4141],\n",
      "        [-10.6875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.181:\n",
      "Loss: 0.025293463841080666\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.0781],\n",
      "        [ -6.3867],\n",
      "        [ -6.6406],\n",
      "        [-10.1719],\n",
      "        [-10.2031],\n",
      "        [ -7.5664],\n",
      "        [ -4.1055],\n",
      "        [ -6.0664]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.182:\n",
      "Loss: 0.003557175863534212\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -5.4727],\n",
      "        [ -5.2656],\n",
      "        [ -9.0625],\n",
      "        [  3.2266],\n",
      "        [-12.9844],\n",
      "        [ -6.4180],\n",
      "        [-11.2344],\n",
      "        [  2.2715]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.183:\n",
      "Loss: 0.018526287749409676\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.3594],\n",
      "        [ -7.5469],\n",
      "        [-14.8438],\n",
      "        [ -4.0430],\n",
      "        [-17.0469],\n",
      "        [ -4.6875],\n",
      "        [  2.5215],\n",
      "        [ -7.2969]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.184:\n",
      "Loss: 0.013209817931056023\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.7852],\n",
      "        [-17.2031],\n",
      "        [ -3.7129],\n",
      "        [  0.9546],\n",
      "        [ -6.7969],\n",
      "        [ -8.5078],\n",
      "        [-12.9688],\n",
      "        [ -2.3926]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.185:\n",
      "Loss: 0.17518460750579834\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.4609],\n",
      "        [ -3.3672],\n",
      "        [-12.7656],\n",
      "        [  0.8159],\n",
      "        [ -6.6250],\n",
      "        [-14.5703],\n",
      "        [ -1.6680],\n",
      "        [ -8.1016]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.186:\n",
      "Loss: 0.07182616740465164\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.8164],\n",
      "        [-13.5391],\n",
      "        [ -7.0781],\n",
      "        [ -3.1797],\n",
      "        [ -3.9082],\n",
      "        [ -6.1250],\n",
      "        [-14.7031],\n",
      "        [ -7.7617]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.187:\n",
      "Loss: 0.00901913084089756\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.1094],\n",
      "        [  3.1328],\n",
      "        [ -8.8516],\n",
      "        [  4.1602],\n",
      "        [-14.9531],\n",
      "        [ -4.7031],\n",
      "        [ -5.4688],\n",
      "        [-16.4531]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.188:\n",
      "Loss: 0.008941932581365108\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.3047],\n",
      "        [ -4.1836],\n",
      "        [ -9.5312],\n",
      "        [ -8.2969],\n",
      "        [  2.1250],\n",
      "        [ -9.2344],\n",
      "        [ -8.2031],\n",
      "        [-11.3203]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.189:\n",
      "Loss: 0.016082601621747017\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.2881],\n",
      "        [  3.9609],\n",
      "        [-10.1016],\n",
      "        [ -8.6484],\n",
      "        [-13.5703],\n",
      "        [ -3.5215],\n",
      "        [-12.4219],\n",
      "        [ -9.0469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.190:\n",
      "Loss: 0.03648810833692551\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.2188],\n",
      "        [ -6.6797],\n",
      "        [ -4.1641],\n",
      "        [-11.8281],\n",
      "        [ -6.1680],\n",
      "        [-10.9922],\n",
      "        [ -9.0234],\n",
      "        [-11.7969]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.191:\n",
      "Loss: 0.0023993784561753273\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.2656],\n",
      "        [ -3.8867],\n",
      "        [ -7.8633],\n",
      "        [-15.4375],\n",
      "        [-15.0156],\n",
      "        [-10.1797],\n",
      "        [  3.7578],\n",
      "        [-10.8125]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.192:\n",
      "Loss: 0.006120962556451559\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.7031],\n",
      "        [ -6.3906],\n",
      "        [-12.8281],\n",
      "        [ -5.8711],\n",
      "        [-17.4531],\n",
      "        [ -9.9766],\n",
      "        [ -4.9023],\n",
      "        [ -4.2422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.193:\n",
      "Loss: 0.003284661564975977\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.1797],\n",
      "        [-14.9219],\n",
      "        [ -5.1328],\n",
      "        [-11.6094],\n",
      "        [-10.8359],\n",
      "        [-11.3516],\n",
      "        [ -5.4961],\n",
      "        [ -9.0703]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.194:\n",
      "Loss: 0.001266838749870658\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.0781],\n",
      "        [ -9.2188],\n",
      "        [  2.4629],\n",
      "        [-11.1875],\n",
      "        [-12.1484],\n",
      "        [-10.3516],\n",
      "        [ -8.5234],\n",
      "        [ -5.9414]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.195:\n",
      "Loss: 0.010591637343168259\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.3906],\n",
      "        [-15.4922],\n",
      "        [-18.3594],\n",
      "        [  1.8594],\n",
      "        [-14.2500],\n",
      "        [  3.1914],\n",
      "        [ -5.3320],\n",
      "        [-12.5547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.196:\n",
      "Loss: 0.023735634982585907\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  3.0332],\n",
      "        [-14.0156],\n",
      "        [-18.2188],\n",
      "        [-12.6094],\n",
      "        [ -1.7861],\n",
      "        [-12.1953],\n",
      "        [  2.6055],\n",
      "        [-23.6250]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.197:\n",
      "Loss: 0.03415881097316742\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.4297],\n",
      "        [-11.0625],\n",
      "        [-11.6641],\n",
      "        [-12.4766],\n",
      "        [  3.3008],\n",
      "        [ -8.4531],\n",
      "        [-12.3281],\n",
      "        [-10.7500]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.198:\n",
      "Loss: 0.004631499294191599\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.4180],\n",
      "        [-10.7422],\n",
      "        [-10.4922],\n",
      "        [-12.9297],\n",
      "        [-16.0312],\n",
      "        [ -8.8281],\n",
      "        [-10.2578],\n",
      "        [-12.1484]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.199:\n",
      "Loss: 0.0015281566884368658\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048f066e9bde425c8baef97d47f53da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.0938],\n",
      "        [-14.6406],\n",
      "        [ -6.7305],\n",
      "        [ -1.4482],\n",
      "        [-13.0859],\n",
      "        [-10.7188],\n",
      "        [-11.4844],\n",
      "        [ -6.7773]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.72:\n",
      "\n",
      "Loss: 0.20770828425884247\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.7344],\n",
      "        [-14.5156],\n",
      "        [-15.9453],\n",
      "        [ -8.1016],\n",
      "        [  6.0469],\n",
      "        [-14.6719],\n",
      "        [  7.7695],\n",
      "        [-13.3125]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.73:\n",
      "\n",
      "Loss: 0.00038643836160190403\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.5234],\n",
      "        [-18.1719],\n",
      "        [  2.7188],\n",
      "        [-15.5312],\n",
      "        [-13.2422],\n",
      "        [  6.6328],\n",
      "        [  5.3750],\n",
      "        [-13.0938]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.74:\n",
      "\n",
      "Loss: 0.00872679054737091\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.8086],\n",
      "        [ -7.2578],\n",
      "        [-15.2266],\n",
      "        [-13.7578],\n",
      "        [-12.2656],\n",
      "        [-17.3438],\n",
      "        [ -2.7383],\n",
      "        [  3.1406]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.75:\n",
      "\n",
      "Loss: 0.013267334550619125\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.7969],\n",
      "        [ -6.7695],\n",
      "        [-10.8047],\n",
      "        [-14.0000],\n",
      "        [ -8.2031],\n",
      "        [-11.7344],\n",
      "        [-10.4766],\n",
      "        [ -9.2734]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.76:\n",
      "\n",
      "Loss: 0.00019656296353787184\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.0547],\n",
      "        [-17.9375],\n",
      "        [-14.4766],\n",
      "        [ -6.3945],\n",
      "        [-15.6562],\n",
      "        [-10.6484],\n",
      "        [  7.4727],\n",
      "        [-12.1953]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.77:\n",
      "\n",
      "Loss: 0.0005763752269558609\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.3516],\n",
      "        [-13.3750],\n",
      "        [-14.7812],\n",
      "        [-12.6797],\n",
      "        [-12.9844],\n",
      "        [-12.2500],\n",
      "        [ -8.2109],\n",
      "        [-12.2734]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.78:\n",
      "\n",
      "Loss: 3.65777341357898e-05\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-19.1094],\n",
      "        [ -5.9727],\n",
      "        [ -9.8359],\n",
      "        [ -6.1875],\n",
      "        [-15.1953],\n",
      "        [ -6.7617],\n",
      "        [ -6.6484],\n",
      "        [ -6.2148]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.79:\n",
      "\n",
      "Loss: 0.0011375207686796784\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-19.6875],\n",
      "        [-16.1250],\n",
      "        [  2.7812],\n",
      "        [ -9.7578],\n",
      "        [-17.0625],\n",
      "        [ -5.1836],\n",
      "        [-17.5625],\n",
      "        [  5.5312]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.80:\n",
      "\n",
      "Loss: 0.008715078234672546\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 200: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.0781],\n",
      "        [-15.1250],\n",
      "        [-10.1328],\n",
      "        [-13.6016],\n",
      "        [ -8.5781],\n",
      "        [  8.2578],\n",
      "        [-13.6797],\n",
      "        [ -4.3828]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.81:\n",
      "\n",
      "Loss: 0.08347241580486298\n",
      "Accuracy: 0.875\n",
      ">>> Epoch end loss: 0.019999999552965164\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.1094],\n",
      "        [-11.8984],\n",
      "        [ -4.2891],\n",
      "        [-11.2188],\n",
      "        [  5.1484],\n",
      "        [ -8.5469],\n",
      "        [-10.2500],\n",
      "        [-22.1719]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.200:\n",
      "Loss: 0.002458285540342331\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.1641],\n",
      "        [ -9.3906],\n",
      "        [ -9.1875],\n",
      "        [-20.4688],\n",
      "        [ -6.4883],\n",
      "        [ -9.3516],\n",
      "        [-15.8359],\n",
      "        [  1.4453]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.201:\n",
      "Loss: 0.026676643639802933\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.9141],\n",
      "        [-17.5156],\n",
      "        [ -9.1484],\n",
      "        [ -6.1875],\n",
      "        [-11.3672],\n",
      "        [-11.0547],\n",
      "        [ -6.0781],\n",
      "        [ -8.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.202:\n",
      "Loss: 0.0009255630429834127\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.7969],\n",
      "        [-10.5312],\n",
      "        [ -4.9727],\n",
      "        [-14.5234],\n",
      "        [  3.2598],\n",
      "        [ -7.4609],\n",
      "        [-18.0781],\n",
      "        [-10.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.203:\n",
      "Loss: 0.0056533715687692165\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.0469],\n",
      "        [-16.1719],\n",
      "        [ -8.2422],\n",
      "        [ -5.5859],\n",
      "        [ -1.4072],\n",
      "        [ -9.3672],\n",
      "        [-10.0078],\n",
      "        [-14.9609]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.204:\n",
      "Loss: 0.20379650592803955\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.6133],\n",
      "        [-12.3750],\n",
      "        [-21.0625],\n",
      "        [  1.9834],\n",
      "        [-14.1094],\n",
      "        [-15.0703],\n",
      "        [-14.1641],\n",
      "        [ -5.4961]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.205:\n",
      "Loss: 0.016795393079519272\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  7.6094],\n",
      "        [-15.7891],\n",
      "        [ -8.1406],\n",
      "        [ -4.5938],\n",
      "        [-16.7969],\n",
      "        [ -9.6797],\n",
      "        [-15.6172],\n",
      "        [ -4.9141]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.206:\n",
      "Loss: 0.576497495174408\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.8750],\n",
      "        [  4.1992],\n",
      "        [-10.1094],\n",
      "        [-12.2656],\n",
      "        [-16.1250],\n",
      "        [  7.4062],\n",
      "        [ -7.6016],\n",
      "        [-19.0781]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.207:\n",
      "Loss: 0.0020061449613422155\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.6172],\n",
      "        [-12.9531],\n",
      "        [ -2.8945],\n",
      "        [  8.4609],\n",
      "        [-14.8359],\n",
      "        [ -8.2344],\n",
      "        [-10.8125],\n",
      "        [-14.7578]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.208:\n",
      "Loss: 0.006794736720621586\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.7656],\n",
      "        [  4.1719],\n",
      "        [-12.7422],\n",
      "        [ -6.3359],\n",
      "        [  2.4746],\n",
      "        [  5.1562],\n",
      "        [-14.8750],\n",
      "        [-17.6094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.209:\n",
      "Loss: 0.012958012521266937\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.3125],\n",
      "        [ -3.6094],\n",
      "        [-12.3906],\n",
      "        [ -9.5312],\n",
      "        [ -7.5625],\n",
      "        [  5.5938],\n",
      "        [-13.6875],\n",
      "        [ -7.5508]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.210:\n",
      "Loss: 0.003943262621760368\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.8789],\n",
      "        [ -7.6133],\n",
      "        [  9.1641],\n",
      "        [ -8.2734],\n",
      "        [-10.2969],\n",
      "        [-12.8125],\n",
      "        [-10.3984],\n",
      "        [ -7.6562]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.211:\n",
      "Loss: 0.0005234470590949059\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.4766],\n",
      "        [-11.3594],\n",
      "        [ -5.7227],\n",
      "        [-11.3906],\n",
      "        [ 10.8438],\n",
      "        [ -3.2617],\n",
      "        [ -9.5078],\n",
      "        [-11.2031]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.212:\n",
      "Loss: 0.005125364288687706\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[  3.2031],\n",
      "        [-13.1953],\n",
      "        [ -1.7383],\n",
      "        [  2.2930],\n",
      "        [ -8.7969],\n",
      "        [ -8.6172],\n",
      "        [-16.5000],\n",
      "        [  3.7871]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.213:\n",
      "Loss: 0.2573762834072113\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.3086],\n",
      "        [ -2.7930],\n",
      "        [-12.5625],\n",
      "        [ 12.9922],\n",
      "        [ -6.7305],\n",
      "        [-11.4922],\n",
      "        [ -6.4766],\n",
      "        [-11.4531]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.214:\n",
      "Loss: 0.007858063094317913\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.0215],\n",
      "        [ -9.5938],\n",
      "        [ -1.4473],\n",
      "        [ -6.7773],\n",
      "        [ -3.1699],\n",
      "        [ -7.4141],\n",
      "        [-11.7891],\n",
      "        [ -3.7129]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.215:\n",
      "Loss: 0.07323140650987625\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.9219],\n",
      "        [-14.3047],\n",
      "        [ -3.0176],\n",
      "        [-15.5703],\n",
      "        [ -4.5664],\n",
      "        [ -4.2891],\n",
      "        [ 12.2422],\n",
      "        [ -6.7148]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.216:\n",
      "Loss: 0.00912417285144329\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.0280],\n",
      "        [ -5.2656],\n",
      "        [-13.8984],\n",
      "        [ -5.8086],\n",
      "        [ -9.0547],\n",
      "        [ -5.4609],\n",
      "        [ -4.0547],\n",
      "        [ -2.0605]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.217:\n",
      "Loss: 0.10710477828979492\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  5.1016],\n",
      "        [-11.7969],\n",
      "        [  6.8711],\n",
      "        [ -7.7969],\n",
      "        [-16.5312],\n",
      "        [ -4.9883],\n",
      "        [  8.8750],\n",
      "        [-14.9922]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.218:\n",
      "Loss: 0.0018073150422424078\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.1680],\n",
      "        [ -5.2148],\n",
      "        [ -6.8906],\n",
      "        [ -7.0195],\n",
      "        [ -2.2871],\n",
      "        [ -4.3945],\n",
      "        [-14.5391],\n",
      "        [ -3.6875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.219:\n",
      "Loss: 0.01955239474773407\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.8438],\n",
      "        [ -0.1647],\n",
      "        [ -8.6328],\n",
      "        [ -2.8125],\n",
      "        [ -7.7148],\n",
      "        [ -2.9199],\n",
      "        [-13.7891],\n",
      "        [ -5.4961]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.220:\n",
      "Loss: 0.09220210462808609\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.4453],\n",
      "        [-14.0469],\n",
      "        [ 12.4062],\n",
      "        [ -5.1562],\n",
      "        [ -6.6758],\n",
      "        [ -4.3477],\n",
      "        [ -9.6250],\n",
      "        [-12.7812]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.221:\n",
      "Loss: 0.0026902107056230307\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.9688],\n",
      "        [-11.2422],\n",
      "        [-12.9922],\n",
      "        [ -9.7656],\n",
      "        [ -0.0544],\n",
      "        [ -3.6172],\n",
      "        [ -5.1719],\n",
      "        [ -5.2461]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.222:\n",
      "Loss: 0.08798078447580338\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.7617],\n",
      "        [ -2.2832],\n",
      "        [ -7.5781],\n",
      "        [-10.6016],\n",
      "        [ -5.5312],\n",
      "        [ -8.7734],\n",
      "        [ -8.8672],\n",
      "        [ -4.0352]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.223:\n",
      "Loss: 0.01497836783528328\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.1953],\n",
      "        [ -9.5703],\n",
      "        [ -8.6250],\n",
      "        [-13.1953],\n",
      "        [ -6.4922],\n",
      "        [  1.8770],\n",
      "        [-12.2422],\n",
      "        [ -9.6328]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.224:\n",
      "Loss: 0.25274425745010376\n",
      "Accuracy: 0.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8008a535a54dc09589895dee9f0f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -8.5859],\n",
      "        [-12.0703],\n",
      "        [-12.0234],\n",
      "        [ -1.2402],\n",
      "        [  6.1953],\n",
      "        [-12.0625],\n",
      "        [ -7.4727],\n",
      "        [  9.2344]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.82:\n",
      "\n",
      "Loss: 0.032127369195222855\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ 10.4219],\n",
      "        [-12.4766],\n",
      "        [ -6.6016],\n",
      "        [-12.8438],\n",
      "        [ -4.4570],\n",
      "        [  2.7422],\n",
      "        [ -8.6562],\n",
      "        [ -7.9922]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.83:\n",
      "\n",
      "Loss: 0.009484309703111649\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.1406],\n",
      "        [-17.4219],\n",
      "        [ -9.8516],\n",
      "        [-11.9609],\n",
      "        [-11.3828],\n",
      "        [  0.6099],\n",
      "        [ -6.9062],\n",
      "        [ -6.8125]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.84:\n",
      "\n",
      "Loss: 0.05452195554971695\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.0391],\n",
      "        [  2.7363],\n",
      "        [-10.8125],\n",
      "        [-10.4453],\n",
      "        [  7.8359],\n",
      "        [-12.3594],\n",
      "        [-14.4453],\n",
      "        [ -3.3379]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.85:\n",
      "\n",
      "Loss: 0.35430869460105896\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.3945],\n",
      "        [-13.6094],\n",
      "        [-11.8906],\n",
      "        [-17.2188],\n",
      "        [ -4.9531],\n",
      "        [ -7.5781],\n",
      "        [  6.0781],\n",
      "        [ -5.8945]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.86:\n",
      "\n",
      "Loss: 0.001783226034604013\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.1172],\n",
      "        [ -3.1680],\n",
      "        [-11.7188],\n",
      "        [-16.2188],\n",
      "        [-10.3203],\n",
      "        [-17.9219],\n",
      "        [ -8.6484],\n",
      "        [-12.4375]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.87:\n",
      "\n",
      "Loss: 0.005181220825761557\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.9414],\n",
      "        [ -4.5078],\n",
      "        [ -5.8203],\n",
      "        [ -8.0156],\n",
      "        [ -7.6641],\n",
      "        [-16.9531],\n",
      "        [ -7.7500],\n",
      "        [  6.6055]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.88:\n",
      "\n",
      "Loss: 0.0021077829878777266\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-13.4609],\n",
      "        [-10.4219],\n",
      "        [-15.5234],\n",
      "        [ -6.4414],\n",
      "        [ -7.0039],\n",
      "        [ -4.7695],\n",
      "        [ -9.4844],\n",
      "        [ 10.5312]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.89:\n",
      "\n",
      "Loss: 0.0013854599092155695\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 225: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.9844],\n",
      "        [  8.7188],\n",
      "        [ -8.3125],\n",
      "        [-14.1406],\n",
      "        [  4.8125],\n",
      "        [-11.0234],\n",
      "        [ -1.8096],\n",
      "        [-11.5391]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.90:\n",
      "\n",
      "Loss: 0.020333826541900635\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.3281],\n",
      "        [ -5.3281],\n",
      "        [ -9.7734],\n",
      "        [ -7.5352],\n",
      "        [-11.9141],\n",
      "        [  9.0156],\n",
      "        [ -8.2812],\n",
      "        [-23.8281]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.91:\n",
      "\n",
      "Loss: 0.0007266996544785798\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.07000000029802322\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.8672],\n",
      "        [-13.3125],\n",
      "        [-10.2109],\n",
      "        [ -0.5518],\n",
      "        [-11.1250],\n",
      "        [-10.4922],\n",
      "        [-12.3828],\n",
      "        [ -9.4844]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.225:\n",
      "Loss: 0.06378898024559021\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.2109],\n",
      "        [ -7.1602],\n",
      "        [-14.5312],\n",
      "        [-13.6016],\n",
      "        [ -9.8203],\n",
      "        [-11.2422],\n",
      "        [-12.0547],\n",
      "        [ -5.3477]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.226:\n",
      "Loss: 0.000733903725631535\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.2500],\n",
      "        [  5.0547],\n",
      "        [-15.2812],\n",
      "        [-11.3984],\n",
      "        [ -9.4375],\n",
      "        [-18.5625],\n",
      "        [-14.1641],\n",
      "        [-10.8438]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.227:\n",
      "Loss: 0.0008090288029052317\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.3906],\n",
      "        [-14.8281],\n",
      "        [ -9.4688],\n",
      "        [-16.0156],\n",
      "        [-13.5078],\n",
      "        [-12.2109],\n",
      "        [  1.8711],\n",
      "        [-20.0469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.228:\n",
      "Loss: 0.017910446971654892\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.5000],\n",
      "        [-12.9141],\n",
      "        [ -7.9062],\n",
      "        [-15.9922],\n",
      "        [  0.3342],\n",
      "        [ -8.2422],\n",
      "        [ -9.7266],\n",
      "        [-16.8750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.229:\n",
      "Loss: 1.0558594465255737\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.1094],\n",
      "        [ -7.2539],\n",
      "        [-13.4766],\n",
      "        [-19.9375],\n",
      "        [-11.9844],\n",
      "        [-11.5234],\n",
      "        [-12.6641],\n",
      "        [-10.2422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.230:\n",
      "Loss: 0.00010926790855592117\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-20.4688],\n",
      "        [ -7.9414],\n",
      "        [-14.2344],\n",
      "        [ -7.6523],\n",
      "        [-13.7109],\n",
      "        [ -9.2031],\n",
      "        [-10.9609],\n",
      "        [-12.4062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.231:\n",
      "Loss: 0.00011930584150832146\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.2422],\n",
      "        [-20.0000],\n",
      "        [ -5.9766],\n",
      "        [-11.8125],\n",
      "        [-16.4375],\n",
      "        [ -7.7930],\n",
      "        [-16.6250],\n",
      "        [-12.0547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.232:\n",
      "Loss: 1.5065486431121826\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.8984],\n",
      "        [ -3.4590],\n",
      "        [-19.7188],\n",
      "        [-12.7891],\n",
      "        [ -6.6758],\n",
      "        [-10.3672],\n",
      "        [-13.1172],\n",
      "        [-11.0625]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.233:\n",
      "Loss: 0.004053229931741953\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.2188],\n",
      "        [ -5.3984],\n",
      "        [ -7.8750],\n",
      "        [-14.1797],\n",
      "        [-11.2812],\n",
      "        [-11.3984],\n",
      "        [ -4.2500],\n",
      "        [-11.3438]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.234:\n",
      "Loss: 0.0023883499670773745\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.3672],\n",
      "        [-10.5859],\n",
      "        [ -9.6719],\n",
      "        [ -5.2930],\n",
      "        [-10.1484],\n",
      "        [-11.3984],\n",
      "        [ -6.3398],\n",
      "        [ -9.9922]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.235:\n",
      "Loss: 0.012071041390299797\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.7344],\n",
      "        [-14.9844],\n",
      "        [  1.8369],\n",
      "        [-12.5391],\n",
      "        [  2.0098],\n",
      "        [ -6.9805],\n",
      "        [ -5.6523],\n",
      "        [-10.2031]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.236:\n",
      "Loss: 0.03477836400270462\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -0.9624],\n",
      "        [ -8.8281],\n",
      "        [ -9.7969],\n",
      "        [ -6.8672],\n",
      "        [ -1.4648],\n",
      "        [-10.5938],\n",
      "        [  3.1543],\n",
      "        [ -9.2344]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.237:\n",
      "Loss: 0.19212296605110168\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.0370e-03],\n",
      "        [-1.1219e+01],\n",
      "        [-6.8945e+00],\n",
      "        [-9.8203e+00],\n",
      "        [-6.4883e+00],\n",
      "        [ 3.8125e+00],\n",
      "        [-9.3047e+00],\n",
      "        [-7.9414e+00]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.238:\n",
      "Loss: 0.08962857723236084\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.8359],\n",
      "        [ -4.9492],\n",
      "        [ -5.5000],\n",
      "        [ -4.0898],\n",
      "        [ -9.6484],\n",
      "        [-11.1953],\n",
      "        [ -3.3281],\n",
      "        [ -2.6133]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.239:\n",
      "Loss: 0.01674170233309269\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.6387],\n",
      "        [ -6.6836],\n",
      "        [  3.6895],\n",
      "        [ -1.0957],\n",
      "        [-16.2344],\n",
      "        [-13.0000],\n",
      "        [  4.1328],\n",
      "        [ -6.5781]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.240:\n",
      "Loss: 0.044698648154735565\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.9043],\n",
      "        [-11.5234],\n",
      "        [ -7.7773],\n",
      "        [ -4.5391],\n",
      "        [ -5.1836],\n",
      "        [ -5.7344],\n",
      "        [ -4.1211],\n",
      "        [ -5.4336]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.241:\n",
      "Loss: 0.007535578683018684\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.2109],\n",
      "        [-14.3672],\n",
      "        [ -2.7578],\n",
      "        [ -0.0661],\n",
      "        [ -7.8789],\n",
      "        [ -2.0820],\n",
      "        [ -2.6797],\n",
      "        [ -4.8789]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.242:\n",
      "Loss: 0.11492130905389786\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-6.5078],\n",
      "        [-4.9258],\n",
      "        [-0.8389],\n",
      "        [-4.6250],\n",
      "        [-2.9180],\n",
      "        [-4.2031],\n",
      "        [-5.0430],\n",
      "        [-9.2578]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.243:\n",
      "Loss: 0.05646125227212906\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.2188],\n",
      "        [-5.8008],\n",
      "        [-9.5000],\n",
      "        [-2.9609],\n",
      "        [-4.7578],\n",
      "        [-6.4883],\n",
      "        [-4.5664],\n",
      "        [-0.7456]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.244:\n",
      "Loss: 0.0578165128827095\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.7266],\n",
      "        [-9.3516],\n",
      "        [-5.5039],\n",
      "        [-5.6758],\n",
      "        [-2.4492],\n",
      "        [-1.6621],\n",
      "        [-5.4766],\n",
      "        [-4.6289]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.245:\n",
      "Loss: 0.034809038043022156\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.7930],\n",
      "        [ -1.6680],\n",
      "        [ -9.5156],\n",
      "        [ -4.8398],\n",
      "        [ -4.0430],\n",
      "        [ -1.9922],\n",
      "        [ -5.4336],\n",
      "        [-12.6562]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.246:\n",
      "Loss: 0.04872576892375946\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.5000],\n",
      "        [ -3.1074],\n",
      "        [ -8.4297],\n",
      "        [ -0.7329],\n",
      "        [  7.5195],\n",
      "        [ -5.1250],\n",
      "        [-10.2109],\n",
      "        [ -8.5156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.247:\n",
      "Loss: 0.05545123293995857\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.9844],\n",
      "        [ -4.0156],\n",
      "        [-13.2969],\n",
      "        [  3.5801],\n",
      "        [  8.6641],\n",
      "        [ -7.9141],\n",
      "        [ -7.3047],\n",
      "        [ -7.6953]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.248:\n",
      "Loss: 0.005921335890889168\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.3555],\n",
      "        [ -6.4258],\n",
      "        [ -6.4258],\n",
      "        [-11.6562],\n",
      "        [ -6.5430],\n",
      "        [  8.6484],\n",
      "        [ -8.5312],\n",
      "        [ -2.7207]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.249:\n",
      "Loss: 0.008680924773216248\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d69b146d5854bd291e63d621614a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.9453],\n",
      "        [ -8.8281],\n",
      "        [ -9.5625],\n",
      "        [ -9.5000],\n",
      "        [  6.8711],\n",
      "        [-18.8125],\n",
      "        [-12.8516],\n",
      "        [-17.1875]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.92:\n",
      "\n",
      "Loss: 0.00016859700554050505\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  3.4805],\n",
      "        [-18.8125],\n",
      "        [ 10.7969],\n",
      "        [ -8.5391],\n",
      "        [ -3.3535],\n",
      "        [-18.9844],\n",
      "        [-18.5312],\n",
      "        [ -7.7227]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.93:\n",
      "\n",
      "Loss: 0.008168869651854038\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.8438],\n",
      "        [ -3.9805],\n",
      "        [-10.7422],\n",
      "        [ -7.7656],\n",
      "        [ -5.7617],\n",
      "        [  2.9062],\n",
      "        [ -9.0859],\n",
      "        [ -4.2461]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.94:\n",
      "\n",
      "Loss: 0.011207538656890392\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -6.8086],\n",
      "        [ -1.9600],\n",
      "        [ -4.8086],\n",
      "        [ -9.3828],\n",
      "        [  2.9375],\n",
      "        [ -8.4531],\n",
      "        [-14.9141],\n",
      "        [ 11.1562]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.95:\n",
      "\n",
      "Loss: 0.024121129885315895\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.8652],\n",
      "        [ 10.2656],\n",
      "        [  1.1719],\n",
      "        [-12.8516],\n",
      "        [-14.4609],\n",
      "        [-12.7031],\n",
      "        [ -7.8086],\n",
      "        [ -4.8711]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.96:\n",
      "\n",
      "Loss: 0.041669055819511414\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.8828],\n",
      "        [-16.8125],\n",
      "        [ -7.5859],\n",
      "        [ -5.0977],\n",
      "        [ -5.7852],\n",
      "        [ -8.1719],\n",
      "        [ -6.5430],\n",
      "        [-18.8750]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.97:\n",
      "\n",
      "Loss: 0.0014300846960395575\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.0020],\n",
      "        [ -7.4805],\n",
      "        [-13.9375],\n",
      "        [-13.8203],\n",
      "        [-11.6016],\n",
      "        [  8.8906],\n",
      "        [-14.7266],\n",
      "        [-15.0625]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.98:\n",
      "\n",
      "Loss: 0.006150979083031416\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.5703],\n",
      "        [-12.2266],\n",
      "        [ -4.8164],\n",
      "        [ -8.5312],\n",
      "        [  3.5625],\n",
      "        [ -5.4062],\n",
      "        [-18.6250],\n",
      "        [-14.6875]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.99:\n",
      "\n",
      "Loss: 0.0050928350538015366\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 250: 'val_loss' reached 0.02000 (best 0.02000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=9-step=250.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.4336],\n",
      "        [  7.6836],\n",
      "        [ -3.5293],\n",
      "        [-10.4297],\n",
      "        [ -8.6016],\n",
      "        [ -2.7715],\n",
      "        [-12.8438],\n",
      "        [ -5.0430]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.100:\n",
      "\n",
      "Loss: 0.01605803892016411\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  9.9141],\n",
      "        [ -2.5430],\n",
      "        [ -1.1592],\n",
      "        [-10.1797],\n",
      "        [-11.0156],\n",
      "        [ -5.7500],\n",
      "        [  6.4609],\n",
      "        [ -2.9609]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.101:\n",
      "\n",
      "Loss: 0.05048665031790733\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.14000000059604645\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.5430],\n",
      "        [ -8.6484],\n",
      "        [  1.2842],\n",
      "        [ -2.3848],\n",
      "        [-10.4062],\n",
      "        [ -3.4082],\n",
      "        [-13.3984],\n",
      "        [  6.5703]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.250:\n",
      "Loss: 0.04590395465493202\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-16.6250],\n",
      "        [  2.9609],\n",
      "        [-11.7891],\n",
      "        [  3.2168],\n",
      "        [ -4.2812],\n",
      "        [ -4.7031],\n",
      "        [ -5.6914],\n",
      "        [  3.0566]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.251:\n",
      "Loss: 0.020235201343894005\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.5156],\n",
      "        [ -3.2520],\n",
      "        [  4.9531],\n",
      "        [ -9.7656],\n",
      "        [ -9.7891],\n",
      "        [ -4.1328],\n",
      "        [ -4.8477],\n",
      "        [-13.7266]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.252:\n",
      "Loss: 0.008790634572505951\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.4590],\n",
      "        [  5.1641],\n",
      "        [ -9.5234],\n",
      "        [ -3.0430],\n",
      "        [-10.5781],\n",
      "        [ -2.4883],\n",
      "        [-16.5000],\n",
      "        [ -0.4207]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.253:\n",
      "Loss: 0.08349121361970901\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.1523],\n",
      "        [-6.2500],\n",
      "        [-9.5078],\n",
      "        [-7.4648],\n",
      "        [-7.4258],\n",
      "        [-5.7461],\n",
      "        [-2.2402],\n",
      "        [-0.6582]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.254:\n",
      "Loss: 0.06754469871520996\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.3984],\n",
      "        [-8.9531],\n",
      "        [ 4.8750],\n",
      "        [-1.7129],\n",
      "        [-3.2207],\n",
      "        [-8.2891],\n",
      "        [-7.4648],\n",
      "        [-7.7461]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.255:\n",
      "Loss: 0.02677164413034916\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.4844],\n",
      "        [  4.7656],\n",
      "        [ -6.7422],\n",
      "        [-13.4922],\n",
      "        [ -6.2109],\n",
      "        [-10.5156],\n",
      "        [ -7.2578],\n",
      "        [ -7.5352]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.256:\n",
      "Loss: 0.0030192043632268906\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.9023],\n",
      "        [-5.9258],\n",
      "        [-7.2891],\n",
      "        [-8.9609],\n",
      "        [-4.6133],\n",
      "        [-6.3633],\n",
      "        [-6.2461],\n",
      "        [-2.8535]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.257:\n",
      "Loss: 0.009472019970417023\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.9648],\n",
      "        [ -6.2070],\n",
      "        [  4.7148],\n",
      "        [ -7.1875],\n",
      "        [ -4.0586],\n",
      "        [  5.0078],\n",
      "        [-15.3594],\n",
      "        [-10.3984]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.258:\n",
      "Loss: 0.0053081149235367775\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.6992],\n",
      "        [ -3.5176],\n",
      "        [ -4.5898],\n",
      "        [ -3.6973],\n",
      "        [-11.5703],\n",
      "        [-11.4375],\n",
      "        [ -4.3711],\n",
      "        [ -3.1934]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.259:\n",
      "Loss: 0.01473192684352398\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.0703],\n",
      "        [ -3.1543],\n",
      "        [ -2.9062],\n",
      "        [ -2.2539],\n",
      "        [ -2.0488],\n",
      "        [ -6.3164],\n",
      "        [ -4.2539],\n",
      "        [-12.6172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.260:\n",
      "Loss: 0.041500553488731384\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.0078],\n",
      "        [ -6.1523],\n",
      "        [ -5.1133],\n",
      "        [-16.0469],\n",
      "        [ -7.3242],\n",
      "        [ -4.0312],\n",
      "        [ -0.9077],\n",
      "        [ -8.2656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.261:\n",
      "Loss: 0.08459174633026123\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.5391],\n",
      "        [ -3.3418],\n",
      "        [ -5.2188],\n",
      "        [ -3.6133],\n",
      "        [ -8.7344],\n",
      "        [ -6.3594],\n",
      "        [-10.8359],\n",
      "        [ -3.1855]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.262:\n",
      "Loss: 0.014978418126702309\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.4492],\n",
      "        [-11.5625],\n",
      "        [  6.5625],\n",
      "        [  5.8867],\n",
      "        [ -8.0859],\n",
      "        [ -2.5957],\n",
      "        [-11.6562],\n",
      "        [ -8.8516]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.263:\n",
      "Loss: 0.010110692121088505\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.8828],\n",
      "        [ -0.8965],\n",
      "        [ -5.0742],\n",
      "        [ -6.6055],\n",
      "        [-12.8828],\n",
      "        [-10.1953],\n",
      "        [ -5.9961],\n",
      "        [ -3.8047]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.264:\n",
      "Loss: 0.04680570960044861\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.2891],\n",
      "        [ -0.5430],\n",
      "        [ -5.3164],\n",
      "        [ -4.6875],\n",
      "        [-10.5625],\n",
      "        [ -8.3516],\n",
      "        [ -7.5703],\n",
      "        [ -4.6953]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.265:\n",
      "Loss: 0.06028270721435547\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.4844],\n",
      "        [-14.1953],\n",
      "        [ -3.2031],\n",
      "        [ -4.1289],\n",
      "        [  5.8672],\n",
      "        [ -6.0078],\n",
      "        [  5.5273],\n",
      "        [-10.1953]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.266:\n",
      "Loss: 0.008146176114678383\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.9844],\n",
      "        [-12.3047],\n",
      "        [ -5.9414],\n",
      "        [ -5.6094],\n",
      "        [ -9.7109],\n",
      "        [ -2.5664],\n",
      "        [ -6.0039],\n",
      "        [  0.1504]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.267:\n",
      "Loss: 0.10760053247213364\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.1094],\n",
      "        [ -7.4648],\n",
      "        [ -3.4883],\n",
      "        [ -8.5703],\n",
      "        [ -5.5234],\n",
      "        [ -3.1602],\n",
      "        [ -2.5254],\n",
      "        [ -8.5547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.268:\n",
      "Loss: 0.019200734794139862\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.9766],\n",
      "        [ -5.6016],\n",
      "        [-16.9375],\n",
      "        [ -2.0781],\n",
      "        [  5.2969],\n",
      "        [-10.2578],\n",
      "        [  5.4219],\n",
      "        [ -4.5039]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.269:\n",
      "Loss: 0.017773116007447243\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.5000],\n",
      "        [ -2.8652],\n",
      "        [ -7.5195],\n",
      "        [-13.1719],\n",
      "        [ -8.4922],\n",
      "        [ -6.3594],\n",
      "        [  8.3359],\n",
      "        [ -2.2266]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.270:\n",
      "Loss: 0.02145460434257984\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.4766],\n",
      "        [-13.5078],\n",
      "        [-16.2031],\n",
      "        [  7.3477],\n",
      "        [ -3.5566],\n",
      "        [ -8.8203],\n",
      "        [ -3.6797],\n",
      "        [ -0.6123]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.271:\n",
      "Loss: 0.06139574199914932\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-18.7812],\n",
      "        [ -1.8193],\n",
      "        [ -5.9453],\n",
      "        [ -1.9209],\n",
      "        [ -0.2917],\n",
      "        [-10.3125],\n",
      "        [ -2.3691],\n",
      "        [ -4.4688]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.272:\n",
      "Loss: 0.11853858828544617\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.8633],\n",
      "        [ 5.7812],\n",
      "        [-6.5391],\n",
      "        [-7.4922],\n",
      "        [-5.1484],\n",
      "        [-8.1016],\n",
      "        [-8.2969],\n",
      "        [-7.4883]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.273:\n",
      "Loss: 0.0015462571755051613\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.3281],\n",
      "        [ -5.8203],\n",
      "        [-13.1562],\n",
      "        [ -5.1992],\n",
      "        [  6.8828],\n",
      "        [ -2.5098],\n",
      "        [ -2.1387],\n",
      "        [-18.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.274:\n",
      "Loss: 0.025482572615146637\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74168dd673c2409394c652a1d429b630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.8984],\n",
      "        [ -2.7148],\n",
      "        [-13.2578],\n",
      "        [ -8.1094],\n",
      "        [  8.0625],\n",
      "        [ -7.7539],\n",
      "        [ -5.4453],\n",
      "        [-13.0000]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.102:\n",
      "\n",
      "Loss: 0.34808579087257385\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.4062],\n",
      "        [ -9.5234],\n",
      "        [ -0.6172],\n",
      "        [-12.3516],\n",
      "        [-16.3281],\n",
      "        [ -4.6836],\n",
      "        [ -1.1816],\n",
      "        [-11.2344]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.103:\n",
      "\n",
      "Loss: 0.08856389671564102\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.2734],\n",
      "        [-16.8906],\n",
      "        [  8.5781],\n",
      "        [  8.7656],\n",
      "        [ -4.3359],\n",
      "        [ -8.3750],\n",
      "        [  9.7422],\n",
      "        [-13.7266]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.104:\n",
      "\n",
      "Loss: 0.0017166442703455687\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Pred: tensor([[-14.6641],\n",
      "        [-11.9375],\n",
      "        [ -5.1562],\n",
      "        [ -9.5781],\n",
      "        [ -8.8594],\n",
      "        [ -2.6152],\n",
      "        [  6.8633],\n",
      "        [  6.3516]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.105:\n",
      "\n",
      "Loss: 0.00991892535239458\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-17.2188],\n",
      "        [ -9.2891],\n",
      "        [-13.7344],\n",
      "        [ -6.3672],\n",
      "        [-13.3203],\n",
      "        [ -4.6133],\n",
      "        [ -1.9131],\n",
      "        [ -8.9297]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.106:\n",
      "\n",
      "Loss: 0.018688397482037544\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.4141],\n",
      "        [ -4.9414],\n",
      "        [-13.2422],\n",
      "        [-13.4766],\n",
      "        [ -9.2891],\n",
      "        [ -5.3477],\n",
      "        [ -5.1641],\n",
      "        [ -8.3516]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.107:\n",
      "\n",
      "Loss: 0.003741778898984194\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.9766],\n",
      "        [-15.6797],\n",
      "        [-16.5781],\n",
      "        [ -3.0000],\n",
      "        [-13.7266],\n",
      "        [ -6.7930],\n",
      "        [-10.3047],\n",
      "        [ -6.1797]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.108:\n",
      "\n",
      "Loss: 0.006492298096418381\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.1133],\n",
      "        [-5.3398],\n",
      "        [ 5.2266],\n",
      "        [ 2.9238],\n",
      "        [-1.1191],\n",
      "        [-0.4180],\n",
      "        [ 5.4922],\n",
      "        [-3.6680]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.109:\n",
      "\n",
      "Loss: 0.2519487142562866\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-14.1328],\n",
      "        [ -2.0352],\n",
      "        [  7.4727],\n",
      "        [ -4.3438],\n",
      "        [-14.6875],\n",
      "        [ -8.7656],\n",
      "        [ -9.6328],\n",
      "        [-12.4141]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.110:\n",
      "\n",
      "Loss: 0.01706259697675705\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 275: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.1172],\n",
      "        [ 11.4297],\n",
      "        [ -7.4688],\n",
      "        [-13.2344],\n",
      "        [  7.4141],\n",
      "        [ -2.4004],\n",
      "        [  6.4844],\n",
      "        [ -5.7188]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.111:\n",
      "\n",
      "Loss: 0.011599899269640446\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.03999999910593033\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.3711],\n",
      "        [ -6.8750],\n",
      "        [  8.8828],\n",
      "        [ -6.3555],\n",
      "        [ -8.7656],\n",
      "        [ -6.3672],\n",
      "        [ -8.5625],\n",
      "        [-10.6641]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.275:\n",
      "Loss: 0.0288994237780571\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.1328],\n",
      "        [-11.8125],\n",
      "        [ -4.3789],\n",
      "        [ -6.5195],\n",
      "        [ -2.5664],\n",
      "        [ -6.9336],\n",
      "        [-11.5391],\n",
      "        [ -4.6719]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.276:\n",
      "Loss: 0.012551108375191689\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.4141],\n",
      "        [-10.5469],\n",
      "        [-12.4219],\n",
      "        [ -6.3633],\n",
      "        [ -7.4688],\n",
      "        [-14.2578],\n",
      "        [  0.4041],\n",
      "        [ -3.1758]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.277:\n",
      "Loss: 0.1305442750453949\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -5.0664],\n",
      "        [-13.4375],\n",
      "        [  1.3926],\n",
      "        [ -2.1973],\n",
      "        [  2.7598],\n",
      "        [-14.9453],\n",
      "        [-11.5391],\n",
      "        [  5.3516]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.278:\n",
      "Loss: 0.04995700344443321\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.6387],\n",
      "        [ -7.6484],\n",
      "        [ -5.2461],\n",
      "        [  6.8945],\n",
      "        [-14.7656],\n",
      "        [ -8.9375],\n",
      "        [ -4.2930],\n",
      "        [ -6.0352]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.279:\n",
      "Loss: 0.011482002213597298\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.3867],\n",
      "        [ -0.2416],\n",
      "        [ -6.4102],\n",
      "        [ -6.3320],\n",
      "        [ -4.9609],\n",
      "        [-15.5078],\n",
      "        [ -1.9014],\n",
      "        [-10.9453]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.280:\n",
      "Loss: 0.09270370006561279\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -3.6211],\n",
      "        [ -6.2930],\n",
      "        [ -5.5156],\n",
      "        [-12.2656],\n",
      "        [ -7.3477],\n",
      "        [ -7.5039],\n",
      "        [ -7.5352],\n",
      "        [  3.0469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.281:\n",
      "Loss: 0.010051406919956207\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -4.3594],\n",
      "        [-15.5312],\n",
      "        [-11.0781],\n",
      "        [  4.1836],\n",
      "        [  4.4023],\n",
      "        [-15.8438],\n",
      "        [ -5.5117],\n",
      "        [  4.2266]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.282:\n",
      "Loss: 0.007319003809243441\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.5371],\n",
      "        [ -9.2109],\n",
      "        [ -5.5820],\n",
      "        [  6.2109],\n",
      "        [-11.7188],\n",
      "        [ -7.3086],\n",
      "        [ -3.0000],\n",
      "        [ -2.5938]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.283:\n",
      "Loss: 0.01948600634932518\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.4766],\n",
      "        [ -9.4141],\n",
      "        [ -0.5635],\n",
      "        [ -5.7578],\n",
      "        [ -6.6758],\n",
      "        [-14.2500],\n",
      "        [ -3.6172],\n",
      "        [ -9.0312]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.284:\n",
      "Loss: 0.0607345812022686\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.3613],\n",
      "        [ -4.1719],\n",
      "        [ -9.3125],\n",
      "        [ -7.3984],\n",
      "        [ -8.1250],\n",
      "        [ -2.2539],\n",
      "        [ -3.4082],\n",
      "        [-10.7812]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.285:\n",
      "Loss: 0.029854269698262215\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.4062],\n",
      "        [ -8.1797],\n",
      "        [-11.2578],\n",
      "        [  1.7275],\n",
      "        [ -8.8125],\n",
      "        [ -7.5625],\n",
      "        [  8.7656],\n",
      "        [ -9.6172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.286:\n",
      "Loss: 0.020605964586138725\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.7373],\n",
      "        [ -9.1328],\n",
      "        [-10.7891],\n",
      "        [ -9.4844],\n",
      "        [  5.0273],\n",
      "        [  2.3047],\n",
      "        [-13.2109],\n",
      "        [ -4.2578]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.287:\n",
      "Loss: 0.06335950642824173\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -0.9375],\n",
      "        [  2.4043],\n",
      "        [ -8.7344],\n",
      "        [ -5.4023],\n",
      "        [ -5.2383],\n",
      "        [-11.2422],\n",
      "        [-12.7188],\n",
      "        [ -3.1191]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.288:\n",
      "Loss: 0.05876902863383293\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.4062],\n",
      "        [ -1.4600],\n",
      "        [ -4.0977],\n",
      "        [ -3.9297],\n",
      "        [ -3.4609],\n",
      "        [ -6.4141],\n",
      "        [ -6.2383],\n",
      "        [-14.6875]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.289:\n",
      "Loss: 0.03491034358739853\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.8242],\n",
      "        [ -6.2148],\n",
      "        [ -9.8828],\n",
      "        [ -3.3711],\n",
      "        [  0.4209],\n",
      "        [-13.2422],\n",
      "        [ -9.1094],\n",
      "        [ -1.6895]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.290:\n",
      "Loss: 0.14150303602218628\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.8047],\n",
      "        [ -8.7031],\n",
      "        [ -5.0000],\n",
      "        [ -2.7773],\n",
      "        [ -7.0195],\n",
      "        [  6.0938],\n",
      "        [ -7.0625],\n",
      "        [-10.1562]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.291:\n",
      "Loss: 0.00890889298170805\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.8281],\n",
      "        [ -9.3984],\n",
      "        [ -4.6836],\n",
      "        [ -4.3047],\n",
      "        [ -5.8945],\n",
      "        [ -5.7070],\n",
      "        [-10.8906],\n",
      "        [ -5.2773]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.292:\n",
      "Loss: 0.0052312221378088\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.1836],\n",
      "        [ -4.3320],\n",
      "        [-15.4766],\n",
      "        [  4.4492],\n",
      "        [ -0.1014],\n",
      "        [ -5.0000],\n",
      "        [ -8.0625],\n",
      "        [ -4.6602]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.293:\n",
      "Loss: 0.7239839434623718\n",
      "Accuracy: 0.75\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-2.3652],\n",
      "        [-9.4141],\n",
      "        [-6.6484],\n",
      "        [-4.4492],\n",
      "        [-5.0898],\n",
      "        [-5.1055],\n",
      "        [-3.5215],\n",
      "        [-9.5234]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.294:\n",
      "Loss: 0.0180195402354002\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.6641],\n",
      "        [ -8.5469],\n",
      "        [ -3.4648],\n",
      "        [  7.5273],\n",
      "        [-12.9219],\n",
      "        [ -4.6133],\n",
      "        [  4.5430],\n",
      "        [-13.8125]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.295:\n",
      "Loss: 0.006501693744212389\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.7305],\n",
      "        [-11.2344],\n",
      "        [-11.0234],\n",
      "        [ -5.4961],\n",
      "        [ -4.1797],\n",
      "        [ -5.6445],\n",
      "        [  7.7930],\n",
      "        [ -8.6484]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.296:\n",
      "Loss: 0.0029836036264896393\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.5430],\n",
      "        [ -6.0234],\n",
      "        [-11.1250],\n",
      "        [ -4.6328],\n",
      "        [ -8.6328],\n",
      "        [ -7.7656],\n",
      "        [ -1.9141],\n",
      "        [ -7.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.297:\n",
      "Loss: 0.019376032054424286\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.3926],\n",
      "        [ -7.1484],\n",
      "        [ -5.9961],\n",
      "        [ -7.6445],\n",
      "        [ -9.9453],\n",
      "        [ -3.2598],\n",
      "        [-12.7969],\n",
      "        [ -0.4807]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.298:\n",
      "Loss: 0.09309640526771545\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.6133],\n",
      "        [ -9.5781],\n",
      "        [ -4.5586],\n",
      "        [  5.7695],\n",
      "        [-12.8984],\n",
      "        [ -6.4922],\n",
      "        [ -9.3125],\n",
      "        [ -7.5898]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.299:\n",
      "Loss: 0.0021327247377485037\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c206ba5860724b84993c17cc52dc565f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.8594],\n",
      "        [ -9.3750],\n",
      "        [ -7.1836],\n",
      "        [ -7.3594],\n",
      "        [-11.0391],\n",
      "        [  9.2344],\n",
      "        [ -2.6094],\n",
      "        [ -4.8633]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.112:\n",
      "\n",
      "Loss: 0.010053801350295544\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.6719],\n",
      "        [ -1.5107],\n",
      "        [-11.0703],\n",
      "        [ -9.7031],\n",
      "        [  3.3496],\n",
      "        [ -5.0039],\n",
      "        [-11.6250],\n",
      "        [ -7.7070]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.113:\n",
      "\n",
      "Loss: 0.03014823980629444\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  9.5000],\n",
      "        [-13.1953],\n",
      "        [ -5.3398],\n",
      "        [-11.1172],\n",
      "        [ -6.9102],\n",
      "        [-11.1406],\n",
      "        [ 11.6484],\n",
      "        [ -7.9062]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.114:\n",
      "\n",
      "Loss: 0.0007831907132640481\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.3281],\n",
      "        [  8.8047],\n",
      "        [ -4.8320],\n",
      "        [-12.3750],\n",
      "        [ -7.8320],\n",
      "        [-11.7422],\n",
      "        [ -6.6719],\n",
      "        [-16.4844]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.115:\n",
      "\n",
      "Loss: 0.0012244654353708029\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-16.0938],\n",
      "        [ 11.4922],\n",
      "        [ -6.5430],\n",
      "        [ -3.6465],\n",
      "        [-10.3359],\n",
      "        [ -2.3789],\n",
      "        [ -1.1934],\n",
      "        [ -1.0342]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.116:\n",
      "\n",
      "Loss: 0.08560561388731003\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.9629],\n",
      "        [ -4.2578],\n",
      "        [-10.7500],\n",
      "        [ -6.9688],\n",
      "        [  5.5586],\n",
      "        [-10.7500],\n",
      "        [ -7.3828],\n",
      "        [-14.3359]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.117:\n",
      "\n",
      "Loss: 0.0047919852659106255\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.5547],\n",
      "        [ -4.6953],\n",
      "        [ -3.5996],\n",
      "        [-13.8281],\n",
      "        [ -5.1836],\n",
      "        [-15.8281],\n",
      "        [-11.3203],\n",
      "        [  6.6680]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.118:\n",
      "\n",
      "Loss: 0.005432898178696632\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.8047],\n",
      "        [ -6.0820],\n",
      "        [-13.2578],\n",
      "        [ -8.1250],\n",
      "        [-10.6875],\n",
      "        [ -7.0000],\n",
      "        [-14.6641],\n",
      "        [-12.7578]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.119:\n",
      "\n",
      "Loss: 0.0005780183710157871\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 300: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  6.5703],\n",
      "        [ -7.0820],\n",
      "        [-17.7969],\n",
      "        [ -8.8047],\n",
      "        [  5.8516],\n",
      "        [ -4.1836],\n",
      "        [  6.0664],\n",
      "        [ -8.6328]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.120:\n",
      "\n",
      "Loss: 0.0028606296982616186\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  5.9844],\n",
      "        [ -6.5273],\n",
      "        [ -5.2578],\n",
      "        [-10.5859],\n",
      "        [  5.1680],\n",
      "        [-18.0156],\n",
      "        [-16.8594],\n",
      "        [ -2.5449]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.121:\n",
      "\n",
      "Loss: 0.01130336057394743\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.07000000029802322\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.0703],\n",
      "        [ -6.2617],\n",
      "        [  3.8516],\n",
      "        [ -2.4746],\n",
      "        [ -7.8789],\n",
      "        [  2.3379],\n",
      "        [-12.8281],\n",
      "        [ -9.9531]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.300:\n",
      "Loss: 0.024548929184675217\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -3.3945],\n",
      "        [ -4.4023],\n",
      "        [ -9.0547],\n",
      "        [ -4.7852],\n",
      "        [-15.9297],\n",
      "        [ -4.5625],\n",
      "        [ -4.1758],\n",
      "        [  6.4219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.301:\n",
      "Loss: 0.010108429938554764\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  2.8730],\n",
      "        [ -6.8086],\n",
      "        [  3.5176],\n",
      "        [ -4.8086],\n",
      "        [ -4.4922],\n",
      "        [-18.0938],\n",
      "        [-12.5078],\n",
      "        [ -4.5039]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.302:\n",
      "Loss: 0.01444980502128601\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-9.2422],\n",
      "        [ 0.5176],\n",
      "        [-9.7422],\n",
      "        [-8.4766],\n",
      "        [-9.2344],\n",
      "        [-9.5312],\n",
      "        [-5.3984],\n",
      "        [ 9.2344]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.303:\n",
      "Loss: 0.05907774716615677\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.8555],\n",
      "        [ -6.5312],\n",
      "        [ -7.8086],\n",
      "        [ -2.3516],\n",
      "        [-11.4375],\n",
      "        [ -4.2461],\n",
      "        [ -7.5352],\n",
      "        [ -3.6797]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.304:\n",
      "Loss: 0.01661078818142414\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  7.1406],\n",
      "        [ -6.4023],\n",
      "        [-11.0781],\n",
      "        [ -3.5742],\n",
      "        [ -9.1016],\n",
      "        [ -6.4102],\n",
      "        [ -7.6719],\n",
      "        [ -8.9141]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.305:\n",
      "Loss: 0.004058774560689926\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.6953],\n",
      "        [ -6.0234],\n",
      "        [ -3.2148],\n",
      "        [-10.3594],\n",
      "        [-11.3438],\n",
      "        [ -4.8828],\n",
      "        [-12.9297],\n",
      "        [ -1.8545]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.306:\n",
      "Loss: 0.024372639134526253\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.8750],\n",
      "        [ -6.7227],\n",
      "        [  7.6172],\n",
      "        [ -8.5391],\n",
      "        [-12.6484],\n",
      "        [ -4.4414],\n",
      "        [ -6.6094],\n",
      "        [ -6.4805]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.307:\n",
      "Loss: 0.0024109159130603075\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  0.2449],\n",
      "        [ -7.4297],\n",
      "        [  1.8975],\n",
      "        [-12.0781],\n",
      "        [  6.8945],\n",
      "        [ -4.8164],\n",
      "        [ -8.4297],\n",
      "        [-16.5000]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.308:\n",
      "Loss: 0.09097477048635483\n",
      "Accuracy: 0.875\n",
      "Label: tensor([1, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  1.2656],\n",
      "        [ -3.7305],\n",
      "        [ -9.9297],\n",
      "        [  5.9375],\n",
      "        [  5.2266],\n",
      "        [ -8.2344],\n",
      "        [-21.8906],\n",
      "        [ -4.8906]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.309:\n",
      "Loss: 0.035995546728372574\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.7344],\n",
      "        [  4.9844],\n",
      "        [ -4.5781],\n",
      "        [-10.2500],\n",
      "        [ -7.6914],\n",
      "        [ -3.0801],\n",
      "        [ -6.4414],\n",
      "        [-10.1016]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.310:\n",
      "Loss: 0.008032536134123802\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.5703],\n",
      "        [  5.9961],\n",
      "        [ -8.8125],\n",
      "        [ -4.4258],\n",
      "        [-10.2266],\n",
      "        [ -6.2617],\n",
      "        [ -6.8359],\n",
      "        [ -9.2969]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.311:\n",
      "Loss: 0.002205686876550317\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.7539],\n",
      "        [  3.6055],\n",
      "        [  3.3359],\n",
      "        [ -7.6133],\n",
      "        [-10.2188],\n",
      "        [-17.8438],\n",
      "        [  1.6768],\n",
      "        [-13.7891]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.312:\n",
      "Loss: 0.029610389843583107\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.7500],\n",
      "        [-13.3672],\n",
      "        [ -7.2383],\n",
      "        [ -3.5273],\n",
      "        [ -8.3281],\n",
      "        [ -1.9434],\n",
      "        [ -6.0391],\n",
      "        [ -6.3125]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.313:\n",
      "Loss: 0.0210153479129076\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Pred: tensor([[ -1.8203],\n",
      "        [ -6.1211],\n",
      "        [-10.6875],\n",
      "        [-19.8281],\n",
      "        [ -9.8984],\n",
      "        [ -4.3750],\n",
      "        [  5.8242],\n",
      "        [  4.8594]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.314:\n",
      "Loss: 0.021946707740426064\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.6562],\n",
      "        [ -4.7500],\n",
      "        [ -6.7734],\n",
      "        [ -6.8750],\n",
      "        [ -5.2188],\n",
      "        [ -3.4824],\n",
      "        [-11.7188],\n",
      "        [ -7.3555]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.315:\n",
      "Loss: 0.005910133011639118\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.1484],\n",
      "        [ -4.3750],\n",
      "        [ -6.1992],\n",
      "        [ -4.9883],\n",
      "        [-11.7891],\n",
      "        [ -5.5391],\n",
      "        [ -4.7578],\n",
      "        [ -1.8477]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.316:\n",
      "Loss: 0.022556738927960396\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.4062],\n",
      "        [-6.1797],\n",
      "        [-4.7305],\n",
      "        [-5.2539],\n",
      "        [-8.1250],\n",
      "        [-5.0430],\n",
      "        [-3.8164],\n",
      "        [-8.4531]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.317:\n",
      "Loss: 0.00567305414006114\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.1504],\n",
      "        [  8.0000],\n",
      "        [-13.7734],\n",
      "        [ -8.8125],\n",
      "        [ -3.0547],\n",
      "        [ -8.5078],\n",
      "        [-11.7422],\n",
      "        [ -8.6797]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.318:\n",
      "Loss: 0.011108599603176117\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.6133],\n",
      "        [ -2.0684],\n",
      "        [ -4.0352],\n",
      "        [-10.0859],\n",
      "        [ -2.5215],\n",
      "        [ -4.7617],\n",
      "        [-13.8047],\n",
      "        [ -0.0816]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.319:\n",
      "Loss: 0.10990022122859955\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.1641],\n",
      "        [ -5.9648],\n",
      "        [ -6.7617],\n",
      "        [-10.2422],\n",
      "        [ -5.2266],\n",
      "        [ -4.3945],\n",
      "        [ -7.9062],\n",
      "        [ -2.7949]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.320:\n",
      "Loss: 0.010170094668865204\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.2891],\n",
      "        [ -6.6562],\n",
      "        [-11.7188],\n",
      "        [ -5.1719],\n",
      "        [ -3.5762],\n",
      "        [-15.0938],\n",
      "        [ -2.6582],\n",
      "        [ -3.6133]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.321:\n",
      "Loss: 0.01611468568444252\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.9453],\n",
      "        [-10.0547],\n",
      "        [ -7.5547],\n",
      "        [ -8.8125],\n",
      "        [ -6.7070],\n",
      "        [-10.4688],\n",
      "        [ -2.4766],\n",
      "        [ -7.8281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.322:\n",
      "Loss: 0.011267771013081074\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.9258],\n",
      "        [ -3.5957],\n",
      "        [ -4.2773],\n",
      "        [ -4.4648],\n",
      "        [-10.9766],\n",
      "        [ -2.6797],\n",
      "        [ -5.1641],\n",
      "        [ -9.2891]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.323:\n",
      "Loss: 0.015600532293319702\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-8.1797],\n",
      "        [-5.5156],\n",
      "        [-8.8516],\n",
      "        [-8.6094],\n",
      "        [-5.9844],\n",
      "        [-5.5898],\n",
      "        [-5.5938],\n",
      "        [-4.7227]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.324:\n",
      "Loss: 0.0029288565274327993\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d59bcb287b4244ae63ddf1ef9849d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.3359],\n",
      "        [-11.5312],\n",
      "        [ -7.0078],\n",
      "        [ -6.7070],\n",
      "        [  9.7188],\n",
      "        [ -5.5195],\n",
      "        [ -6.3203],\n",
      "        [-13.0312]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.122:\n",
      "\n",
      "Loss: 0.0010104553075507283\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.8906],\n",
      "        [  6.6992],\n",
      "        [ -9.6172],\n",
      "        [ -3.5469],\n",
      "        [ -6.9844],\n",
      "        [-11.9922],\n",
      "        [-11.9375],\n",
      "        [-11.1797]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.123:\n",
      "\n",
      "Loss: 0.003834502073004842\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.1055],\n",
      "        [-14.6094],\n",
      "        [-11.1797],\n",
      "        [ 11.1016],\n",
      "        [  9.3047],\n",
      "        [-17.4219],\n",
      "        [-14.1406],\n",
      "        [-10.2891]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.124:\n",
      "\n",
      "Loss: 0.00029792069108225405\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.2070],\n",
      "        [ -5.4180],\n",
      "        [-13.7500],\n",
      "        [-10.1094],\n",
      "        [ -6.9609],\n",
      "        [  8.3281],\n",
      "        [-13.8438],\n",
      "        [-10.0000]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.125:\n",
      "\n",
      "Loss: 0.0008056069491431117\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  7.4023],\n",
      "        [ -6.4453],\n",
      "        [-14.4062],\n",
      "        [-15.0859],\n",
      "        [ -2.3242],\n",
      "        [ -9.1094],\n",
      "        [  9.0391],\n",
      "        [-13.3516]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.126:\n",
      "\n",
      "Loss: 0.011973856016993523\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.3984],\n",
      "        [ -4.5469],\n",
      "        [-14.8906],\n",
      "        [ -9.3594],\n",
      "        [ -2.7930],\n",
      "        [ -6.5430],\n",
      "        [ -7.0625],\n",
      "        [ -9.3125]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.127:\n",
      "\n",
      "Loss: 0.009264588356018066\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.3828],\n",
      "        [ -9.0938],\n",
      "        [  6.0352],\n",
      "        [-14.4609],\n",
      "        [ -6.5352],\n",
      "        [ -6.9258],\n",
      "        [  7.6523],\n",
      "        [-10.7812]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.128:\n",
      "\n",
      "Loss: 0.0006793759530410171\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.3438],\n",
      "        [-10.0625],\n",
      "        [ -6.3828],\n",
      "        [-10.3203],\n",
      "        [ -7.0820],\n",
      "        [ -5.0742],\n",
      "        [ -5.6328],\n",
      "        [-16.3750]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.129:\n",
      "\n",
      "Loss: 0.00158135243691504\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 325: 'val_loss' reached 0.01000 (best 0.01000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=12-step=325.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.5020],\n",
      "        [ -5.4531],\n",
      "        [ -4.6406],\n",
      "        [ -5.1680],\n",
      "        [ -5.5664],\n",
      "        [-10.7891],\n",
      "        [ -5.7734],\n",
      "        [ -1.4932]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.130:\n",
      "\n",
      "Loss: 0.03848830983042717\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.6875],\n",
      "        [ -6.1133],\n",
      "        [ -8.9062],\n",
      "        [ -9.5234],\n",
      "        [ -9.7344],\n",
      "        [ -7.4453],\n",
      "        [  7.7109],\n",
      "        [  8.9688]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.131:\n",
      "\n",
      "Loss: 0.0004550968296825886\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.019999999552965164\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -9.6172],\n",
      "        [ -8.2578],\n",
      "        [ -3.6641],\n",
      "        [ -2.7812],\n",
      "        [ -4.5234],\n",
      "        [-13.1797],\n",
      "        [ -2.6406],\n",
      "        [ -9.1172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.325:\n",
      "Loss: 0.02069270610809326\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.3594],\n",
      "        [ -3.2383],\n",
      "        [ -6.2969],\n",
      "        [ -7.9922],\n",
      "        [ -7.4492],\n",
      "        [ -6.5820],\n",
      "        [ -2.9629],\n",
      "        [ -1.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.326:\n",
      "Loss: 0.04725134000182152\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  4.4727],\n",
      "        [ -3.6738],\n",
      "        [ -4.0938],\n",
      "        [-14.6641],\n",
      "        [-18.6250],\n",
      "        [ -5.7891],\n",
      "        [ -4.3398],\n",
      "        [-11.3359]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.327:\n",
      "Loss: 0.008622064255177975\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-5.8711],\n",
      "        [-5.5430],\n",
      "        [-7.3750],\n",
      "        [-7.0742],\n",
      "        [-7.1680],\n",
      "        [-7.8242],\n",
      "        [-4.1641],\n",
      "        [-7.4219]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.328:\n",
      "Loss: 0.003173608100041747\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.0117],\n",
      "        [ -9.7812],\n",
      "        [ -3.9219],\n",
      "        [ -4.5000],\n",
      "        [ -6.5508],\n",
      "        [ -3.9688],\n",
      "        [ -2.7363],\n",
      "        [-12.2734]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.329:\n",
      "Loss: 0.014320389367640018\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.6406],\n",
      "        [ -4.2812],\n",
      "        [ -8.4766],\n",
      "        [ -7.0195],\n",
      "        [  7.8867],\n",
      "        [ -8.7891],\n",
      "        [ -7.6367],\n",
      "        [-10.2031]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.330:\n",
      "Loss: 0.0019851685501635075\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.0547],\n",
      "        [ -8.5234],\n",
      "        [ -8.6094],\n",
      "        [-14.5234],\n",
      "        [ -3.5645],\n",
      "        [ -4.4961],\n",
      "        [ -0.8408],\n",
      "        [ -0.5283]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.331:\n",
      "Loss: 0.1077263131737709\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.8594],\n",
      "        [ -8.1953],\n",
      "        [-11.0156],\n",
      "        [ -9.4531],\n",
      "        [ -7.4414],\n",
      "        [  3.8340],\n",
      "        [  4.0195],\n",
      "        [ -5.9102]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.332:\n",
      "Loss: 0.005358383059501648\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.9219],\n",
      "        [ -6.9883],\n",
      "        [ -7.1797],\n",
      "        [ -4.1797],\n",
      "        [ -4.4766],\n",
      "        [ -7.6289],\n",
      "        [ -6.3594],\n",
      "        [ -9.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.333:\n",
      "Loss: 0.003815378062427044\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -2.2188],\n",
      "        [  5.5547],\n",
      "        [ -4.3164],\n",
      "        [-18.1719],\n",
      "        [-15.1484],\n",
      "        [  2.0566],\n",
      "        [  7.4102],\n",
      "        [-12.4141]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.334:\n",
      "Loss: 0.030162688344717026\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-4.7070],\n",
      "        [-4.0273],\n",
      "        [-8.6562],\n",
      "        [-6.4297],\n",
      "        [-6.9297],\n",
      "        [-7.8359],\n",
      "        [-9.7500],\n",
      "        [-1.7656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.335:\n",
      "Loss: 0.023474864661693573\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.2188],\n",
      "        [ -6.9336],\n",
      "        [ -4.9727],\n",
      "        [-11.0703],\n",
      "        [ -8.2422],\n",
      "        [ -6.4922],\n",
      "        [ -4.3516],\n",
      "        [ -4.3555]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.336:\n",
      "Loss: 0.004403994418680668\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -4.4766],\n",
      "        [-20.4531],\n",
      "        [  6.6562],\n",
      "        [ -7.2969],\n",
      "        [-15.7656],\n",
      "        [ -6.0898],\n",
      "        [ -0.9033],\n",
      "        [ -0.6396]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.337:\n",
      "Loss: 0.1773744821548462\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-11.2109],\n",
      "        [ -2.2852],\n",
      "        [ -7.9883],\n",
      "        [ -6.1523],\n",
      "        [ -7.5195],\n",
      "        [ -7.7773],\n",
      "        [ -3.3535],\n",
      "        [ -9.1172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.338:\n",
      "Loss: 0.016852660104632378\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.5234],\n",
      "        [ -7.2578],\n",
      "        [ -5.1797],\n",
      "        [-12.4688],\n",
      "        [  0.6919],\n",
      "        [ -9.9844],\n",
      "        [ -1.4766],\n",
      "        [ -4.9688]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.339:\n",
      "Loss: 0.1646037995815277\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.2773],\n",
      "        [  7.9766],\n",
      "        [ -6.9844],\n",
      "        [-12.7969],\n",
      "        [-12.5234],\n",
      "        [ -9.4844],\n",
      "        [ -7.0156],\n",
      "        [ -5.8750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.340:\n",
      "Loss: 0.0023547541350126266\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -9.0391],\n",
      "        [ -8.8750],\n",
      "        [ -6.2578],\n",
      "        [-10.6797],\n",
      "        [-11.1719],\n",
      "        [ -7.6328],\n",
      "        [ -2.2539],\n",
      "        [  8.0156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.341:\n",
      "Loss: 0.012857301160693169\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.6562],\n",
      "        [-10.8281],\n",
      "        [ -4.0117],\n",
      "        [ -1.2129],\n",
      "        [ -4.8203],\n",
      "        [ -7.0352],\n",
      "        [ -4.9219],\n",
      "        [ -5.0391]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.342:\n",
      "Loss: 0.037613339722156525\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.5449],\n",
      "        [-13.1484],\n",
      "        [ -7.2344],\n",
      "        [ -5.2227],\n",
      "        [ -9.3359],\n",
      "        [ -5.0078],\n",
      "        [ -4.1016],\n",
      "        [ -4.3750]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.343:\n",
      "Loss: 0.029392685741186142\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.1133],\n",
      "        [ -4.7930],\n",
      "        [ -9.2422],\n",
      "        [ -5.9492],\n",
      "        [ -5.3789],\n",
      "        [ -3.7129],\n",
      "        [ -5.4805],\n",
      "        [-12.2188]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.344:\n",
      "Loss: 0.005755680613219738\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -0.8374],\n",
      "        [ -9.5703],\n",
      "        [ -6.7891],\n",
      "        [-11.5625],\n",
      "        [ -5.2969],\n",
      "        [ 10.2109],\n",
      "        [-11.3672],\n",
      "        [-13.2422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.345:\n",
      "Loss: 0.04573792964220047\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.6094],\n",
      "        [ -5.2812],\n",
      "        [  6.4883],\n",
      "        [ -7.5000],\n",
      "        [-20.7812],\n",
      "        [ -4.5117],\n",
      "        [ -2.6426],\n",
      "        [ -1.5742]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.346:\n",
      "Loss: 0.0343908965587616\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.6484],\n",
      "        [ -7.8164],\n",
      "        [ -9.8125],\n",
      "        [  7.8008],\n",
      "        [ -9.6719],\n",
      "        [-12.9219],\n",
      "        [ -7.7031],\n",
      "        [ -4.5898]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.347:\n",
      "Loss: 0.0026272672694176435\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.6328],\n",
      "        [ -7.9688],\n",
      "        [-15.7188],\n",
      "        [ -3.5801],\n",
      "        [  5.4180],\n",
      "        [  5.7695],\n",
      "        [ -5.8359],\n",
      "        [-16.5469]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.348:\n",
      "Loss: 0.004951626993715763\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.1953],\n",
      "        [-12.8281],\n",
      "        [ -6.0039],\n",
      "        [ -9.7812],\n",
      "        [ -2.3438],\n",
      "        [ -4.5820],\n",
      "        [-12.2578],\n",
      "        [ -3.1094]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.349:\n",
      "Loss: 0.018535858020186424\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2b1297191047d98cc867191e446ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ 8.7109],\n",
      "        [-5.9414],\n",
      "        [-9.2734],\n",
      "        [-8.0938],\n",
      "        [-8.7344],\n",
      "        [ 8.6094],\n",
      "        [-9.5000],\n",
      "        [-0.8101]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.132:\n",
      "\n",
      "Loss: 0.04645001143217087\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-15.1875],\n",
      "        [ -4.1641],\n",
      "        [ -9.5312],\n",
      "        [-10.9531],\n",
      "        [ -8.8125],\n",
      "        [  7.2227],\n",
      "        [-11.7734],\n",
      "        [ -7.5820]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.133:\n",
      "\n",
      "Loss: 0.0021138412412256002\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.5879],\n",
      "        [ -7.3320],\n",
      "        [-13.9219],\n",
      "        [  2.4199],\n",
      "        [  9.6094],\n",
      "        [ -5.0586],\n",
      "        [-12.7344],\n",
      "        [ -9.2734]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.134:\n",
      "\n",
      "Loss: 0.01495357695966959\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.9766],\n",
      "        [-16.2031],\n",
      "        [ -5.9141],\n",
      "        [ -6.4492],\n",
      "        [ -3.8848],\n",
      "        [ -5.2617],\n",
      "        [ -9.7656],\n",
      "        [ -9.5000]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.135:\n",
      "\n",
      "Loss: 0.006063004024326801\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -9.1641],\n",
      "        [ -7.8203],\n",
      "        [ -9.9297],\n",
      "        [  3.7793],\n",
      "        [-15.6172],\n",
      "        [ -4.8906],\n",
      "        [-10.5625],\n",
      "        [  9.9375]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.136:\n",
      "\n",
      "Loss: 0.003837457625195384\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-13.8828],\n",
      "        [ -8.1641],\n",
      "        [  8.2812],\n",
      "        [  4.0508],\n",
      "        [ -9.0156],\n",
      "        [ -8.0547],\n",
      "        [-10.6406],\n",
      "        [ -4.4883]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.137:\n",
      "\n",
      "Loss: 0.0036797430366277695\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-17.3438],\n",
      "        [ -2.6348],\n",
      "        [ -2.1836],\n",
      "        [  4.4180],\n",
      "        [ -3.1133],\n",
      "        [ -8.6641],\n",
      "        [-12.4297],\n",
      "        [  5.0391]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.138:\n",
      "\n",
      "Loss: 0.029766106978058815\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-12.7812],\n",
      "        [ -8.9922],\n",
      "        [ -6.4492],\n",
      "        [-13.4219],\n",
      "        [ -8.7578],\n",
      "        [  3.8848],\n",
      "        [-12.3125],\n",
      "        [ -8.9062]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.139:\n",
      "\n",
      "Loss: 0.002793840365484357\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  9.7656],\n",
      "        [ -0.5884],\n",
      "        [-13.8438],\n",
      "        [  9.7031],\n",
      "        [ -8.7031],\n",
      "        [ -8.0625],\n",
      "        [ -6.4727],\n",
      "        [ -1.7393]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.140:\n",
      "\n",
      "Loss: 0.07569842785596848\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 350: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -3.4395],\n",
      "        [ -8.4453],\n",
      "        [ -5.7070],\n",
      "        [-12.1953],\n",
      "        [ -9.8672],\n",
      "        [-11.0938],\n",
      "        [-12.0781],\n",
      "        [  7.1094]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.141:\n",
      "\n",
      "Loss: 0.4344322681427002\n",
      "Accuracy: 0.875\n",
      ">>> Epoch end loss: 0.029999999329447746\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.8281],\n",
      "        [ -4.5820],\n",
      "        [ -9.8281],\n",
      "        [ -6.4219],\n",
      "        [-14.7109],\n",
      "        [  5.8828],\n",
      "        [ -5.1172],\n",
      "        [-10.4141]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.350:\n",
      "Loss: 0.02121058851480484\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.2637],\n",
      "        [ -0.9395],\n",
      "        [  9.5781],\n",
      "        [-11.7344],\n",
      "        [ -8.1484],\n",
      "        [ -3.8184],\n",
      "        [-16.0938],\n",
      "        [-15.2500]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.351:\n",
      "Loss: 0.04869202524423599\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -7.0781],\n",
      "        [-22.3281],\n",
      "        [  3.3516],\n",
      "        [ -3.7441],\n",
      "        [ -8.7266],\n",
      "        [ -1.4082],\n",
      "        [-11.9297],\n",
      "        [  6.0312]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.352:\n",
      "Loss: 0.21102814376354218\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.1719],\n",
      "        [ -4.4688],\n",
      "        [-10.8281],\n",
      "        [ -9.1172],\n",
      "        [ 10.1797],\n",
      "        [ -6.6445],\n",
      "        [-11.7031],\n",
      "        [ -6.8086]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.353:\n",
      "Loss: 0.002454242203384638\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.2969],\n",
      "        [ -8.6016],\n",
      "        [ -0.9800],\n",
      "        [-17.6406],\n",
      "        [  5.4648],\n",
      "        [  8.3359],\n",
      "        [-13.5859],\n",
      "        [ -6.3320]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.354:\n",
      "Loss: 0.1631406545639038\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.5078],\n",
      "        [ -6.0234],\n",
      "        [ -2.9902],\n",
      "        [-10.4609],\n",
      "        [ -4.4414],\n",
      "        [ -6.0234],\n",
      "        [ -9.0703],\n",
      "        [ -4.4297]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.355:\n",
      "Loss: 0.009724168106913567\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.1250],\n",
      "        [ -4.6719],\n",
      "        [-10.2188],\n",
      "        [-10.7969],\n",
      "        [ -8.4609],\n",
      "        [ -9.1953],\n",
      "        [  4.9531],\n",
      "        [ -9.5547]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.356:\n",
      "Loss: 0.0023717249277979136\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -4.3867],\n",
      "        [-10.1641],\n",
      "        [ -3.8262],\n",
      "        [ -5.1797],\n",
      "        [ -6.1836],\n",
      "        [-16.2656],\n",
      "        [ -3.2402],\n",
      "        [  5.5664]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.357:\n",
      "Loss: 0.010482712648808956\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-7.5352],\n",
      "        [-5.1562],\n",
      "        [-8.7266],\n",
      "        [-6.1953],\n",
      "        [-6.7422],\n",
      "        [-6.9492],\n",
      "        [-7.4648],\n",
      "        [-6.8945]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.358:\n",
      "Loss: 0.0015254337340593338\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -4.9102],\n",
      "        [ -8.4141],\n",
      "        [-14.4531],\n",
      "        [ -1.3877],\n",
      "        [ -7.7500],\n",
      "        [ -8.4297],\n",
      "        [ -6.3164],\n",
      "        [ -5.4570]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.359:\n",
      "Loss: 0.02964259497821331\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-16.7344],\n",
      "        [ -1.3135],\n",
      "        [ -3.7910],\n",
      "        [ -8.0547],\n",
      "        [ -7.5664],\n",
      "        [ -4.8828],\n",
      "        [-16.7188],\n",
      "        [  7.2812]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.360:\n",
      "Loss: 0.0336911678314209\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.3672],\n",
      "        [ -9.0703],\n",
      "        [-11.3906],\n",
      "        [  8.7344],\n",
      "        [ -5.0234],\n",
      "        [-11.7109],\n",
      "        [ -4.5977],\n",
      "        [ -5.8789]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.361:\n",
      "Loss: 0.002463284181430936\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-12.4844],\n",
      "        [ -8.7188],\n",
      "        [ -7.0820],\n",
      "        [  3.8379],\n",
      "        [-10.6172],\n",
      "        [ -3.7734],\n",
      "        [-13.0703],\n",
      "        [  5.3008]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.362:\n",
      "Loss: 0.006254022475332022\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[-18.5312],\n",
      "        [ -7.6484],\n",
      "        [ -5.5859],\n",
      "        [ -3.6992],\n",
      "        [-19.3906],\n",
      "        [  6.9141],\n",
      "        [ -2.6172],\n",
      "        [  3.2930]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.363:\n",
      "Loss: 0.017073871567845345\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.8750],\n",
      "        [ -9.6641],\n",
      "        [ -8.6094],\n",
      "        [ -6.0664],\n",
      "        [ -1.3555],\n",
      "        [  6.9961],\n",
      "        [ -8.1953],\n",
      "        [-14.4375]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.364:\n",
      "Loss: 0.02949303202331066\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -1.1660],\n",
      "        [-11.3047],\n",
      "        [-14.5703],\n",
      "        [  2.9375],\n",
      "        [ -1.4570],\n",
      "        [  5.7422],\n",
      "        [ -5.7383],\n",
      "        [-16.0156]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.365:\n",
      "Loss: 0.06733940541744232\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[  3.6289],\n",
      "        [  5.6445],\n",
      "        [-13.0078],\n",
      "        [ -4.1328],\n",
      "        [ -9.8828],\n",
      "        [-15.7734],\n",
      "        [ -4.8555],\n",
      "        [ -8.2656]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.366:\n",
      "Loss: 0.006713268347084522\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.0020],\n",
      "        [ -8.5312],\n",
      "        [  1.8242],\n",
      "        [-10.1328],\n",
      "        [ -9.9688],\n",
      "        [ -8.8906],\n",
      "        [-11.0312],\n",
      "        [ -5.6172]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.367:\n",
      "Loss: 0.025267284363508224\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -9.6719],\n",
      "        [-11.9453],\n",
      "        [  1.2578],\n",
      "        [ -7.5781],\n",
      "        [ -8.8594],\n",
      "        [  4.8047],\n",
      "        [-16.0938],\n",
      "        [  5.2109]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.368:\n",
      "Loss: 0.033064648509025574\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -3.9980],\n",
      "        [ -7.2969],\n",
      "        [-11.0234],\n",
      "        [-10.2109],\n",
      "        [ -9.9219],\n",
      "        [ -7.5820],\n",
      "        [ -2.1680],\n",
      "        [ -6.2539]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.369:\n",
      "Loss: 0.016215017065405846\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.9844],\n",
      "        [ -9.5547],\n",
      "        [-11.6719],\n",
      "        [  8.0625],\n",
      "        [ -6.3516],\n",
      "        [ -4.9727],\n",
      "        [-10.5938],\n",
      "        [ -8.6562]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.370:\n",
      "Loss: 0.001170298783108592\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.9023],\n",
      "        [ -9.6406],\n",
      "        [-11.0391],\n",
      "        [  2.4434],\n",
      "        [ -3.3652],\n",
      "        [ -3.3652],\n",
      "        [-11.7031],\n",
      "        [ -2.2461]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.371:\n",
      "Loss: 0.03153501823544502\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.9453],\n",
      "        [ -3.7090],\n",
      "        [ -4.7812],\n",
      "        [ -9.6797],\n",
      "        [ -6.3555],\n",
      "        [ -0.9766],\n",
      "        [-17.1250],\n",
      "        [-10.4062]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.372:\n",
      "Loss: 0.04437100142240524\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[  6.3828],\n",
      "        [ -3.2812],\n",
      "        [-16.7344],\n",
      "        [ -4.6992],\n",
      "        [ -0.4685],\n",
      "        [-16.2500],\n",
      "        [  4.0156],\n",
      "        [-14.6250]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.373:\n",
      "Loss: 0.12751300632953644\n",
      "Accuracy: 0.875\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.2305],\n",
      "        [ -2.2891],\n",
      "        [ -4.1797],\n",
      "        [-10.0391],\n",
      "        [ -8.3047],\n",
      "        [-13.2891],\n",
      "        [  3.9238],\n",
      "        [-14.5391]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      ">>> Training step No.374:\n",
      "Loss: 0.016695814207196236\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e204786991041a190d3f4f62196cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[  3.0391],\n",
      "        [  1.5684],\n",
      "        [ -7.3086],\n",
      "        [ -3.6973],\n",
      "        [-11.4688],\n",
      "        [ -6.6641],\n",
      "        [-18.3906],\n",
      "        [  5.9609]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.142:\n",
      "\n",
      "Loss: 0.03313415125012398\n",
      "Accuracy: 1.0\n",
      "Label: tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[  7.4023],\n",
      "        [-12.0312],\n",
      "        [-10.0391],\n",
      "        [ -4.4844],\n",
      "        [  5.3867],\n",
      "        [ -7.4375],\n",
      "        [-12.6562],\n",
      "        [  7.3281]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.143:\n",
      "\n",
      "Loss: 0.0022118762135505676\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.3633],\n",
      "        [-10.5781],\n",
      "        [ -5.0859],\n",
      "        [ -3.3164],\n",
      "        [ -6.9375],\n",
      "        [-13.8750],\n",
      "        [ -8.3125],\n",
      "        [-10.1406]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.144:\n",
      "\n",
      "Loss: 0.00546498317271471\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -7.1211],\n",
      "        [-16.6406],\n",
      "        [ -4.3320],\n",
      "        [  4.9883],\n",
      "        [-14.7969],\n",
      "        [ -3.9863],\n",
      "        [ -6.1172],\n",
      "        [ -8.8359]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.145:\n",
      "\n",
      "Loss: 0.005175312981009483\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -5.7383],\n",
      "        [-12.6562],\n",
      "        [-14.5156],\n",
      "        [-16.0312],\n",
      "        [-12.8281],\n",
      "        [ -5.7734],\n",
      "        [ -7.7070],\n",
      "        [ -6.3438]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.146:\n",
      "\n",
      "Loss: 0.0010664663277566433\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.5078],\n",
      "        [  7.3203],\n",
      "        [-12.6562],\n",
      "        [ -1.8574],\n",
      "        [-11.9453],\n",
      "        [-19.3125],\n",
      "        [ -5.5234],\n",
      "        [-16.5781]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.147:\n",
      "\n",
      "Loss: 0.018714148551225662\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Pred: tensor([[ -8.0625],\n",
      "        [  4.6523],\n",
      "        [ -9.6797],\n",
      "        [ -6.4219],\n",
      "        [-13.3359],\n",
      "        [-10.8047],\n",
      "        [-11.3203],\n",
      "        [  8.6172]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.148:\n",
      "\n",
      "Loss: 0.0014638915890827775\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -6.2266],\n",
      "        [-17.0625],\n",
      "        [  2.1230],\n",
      "        [-12.0391],\n",
      "        [-11.1406],\n",
      "        [-10.0547],\n",
      "        [-12.1406],\n",
      "        [ -6.5664]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.149:\n",
      "\n",
      "Loss: 0.014559979550540447\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 375: 'val_loss' reached 0.01000 (best 0.01000), saving model to '/home/toghrul/SLR/sign-lang/checkpoints/epoch=14-step=375.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[ -8.1406],\n",
      "        [ -8.9453],\n",
      "        [ -3.8809],\n",
      "        [-10.1172],\n",
      "        [ 10.6172],\n",
      "        [-15.5000],\n",
      "        [-10.7031],\n",
      "        [-18.3594]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.150:\n",
      "\n",
      "Loss: 0.0026165565941482782\n",
      "Accuracy: 1.0\n",
      "Label: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Pred: tensor([[-10.6172],\n",
      "        [ -7.4141],\n",
      "        [ -9.1484],\n",
      "        [-15.1094],\n",
      "        [ -4.8047],\n",
      "        [-11.4766],\n",
      "        [ -8.4453],\n",
      "        [ -4.1602]], device='cuda:0', dtype=torch.float16)\n",
      ">>> Validation step No.151:\n",
      "\n",
      "Loss: 0.0030751593876630068\n",
      "Accuracy: 1.0\n",
      ">>> Epoch end loss: 0.03999999910593033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "# trainer.fit(model, ckpt_path=\"/home/toghrul/SLR/sign-lang/checkpoints/last.ckpt\")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/toghrul/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel.load_from_checkpoint(\n",
    "    checkpoint_path=\"/home/toghrul/SLR/sign-lang/checkpoints/last-v4.ckpt\",\n",
    "    hparams_file=\"/home/toghrul/SLR/sign-lang/lightning_logs/version_45/hparams.yaml\",\n",
    "    map_location=None,\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../models/eff3d_bin.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoModel(\n",
       "  (video_model): EfficientX3d(\n",
       "    (s1): Sequential(\n",
       "      (pathway0_stem_conv_xy): Conv3dTemporalKernel1BnAct(\n",
       "        (kernel): Sequential(\n",
       "          (conv): Conv3d(3, 24, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "          (act): Identity(\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_stem_conv): Conv3d5x1x1BnAct(\n",
       "        (kernel): Sequential(\n",
       "          (conv): Conv3d(24, 24, kernel_size=(5, 1, 1), stride=(1, 1, 1), padding=(2, 0, 0), groups=24, bias=False)\n",
       "          (bn): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): Sequential(\n",
       "      (pathway0_res0): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (_res_proj): Conv3dTemporalKernel1BnAct(\n",
       "          (kernel): Sequential(\n",
       "            (conv): Conv3d(24, 24, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (bn): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Identity(\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=54, bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(54, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(8, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res1): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=54, bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res2): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(24, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 54, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=54, bias=False)\n",
       "              (bn): BatchNorm3d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(54, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(8, 54, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(54, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): Sequential(\n",
       "      (pathway0_res0): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (_res_proj): Conv3dTemporalKernel1BnAct(\n",
       "          (kernel): Sequential(\n",
       "            (conv): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Identity(\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(24, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=108, bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res1): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res2): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res3): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res4): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(48, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=108, bias=False)\n",
       "              (bn): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(108, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(8, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): Sequential(\n",
       "      (pathway0_res0): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (_res_proj): Conv3dTemporalKernel1BnAct(\n",
       "          (kernel): Sequential(\n",
       "            (conv): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Identity(\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(48, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res1): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res2): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res3): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res4): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res5): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res6): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res7): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res8): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res9): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res10): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)\n",
       "              (bn): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(216, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(16, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(216, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s5): Sequential(\n",
       "      (pathway0_res0): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (_res_proj): Conv3dTemporalKernel1BnAct(\n",
       "          (kernel): Sequential(\n",
       "            (conv): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Identity(\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(96, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res1): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res2): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res3): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res4): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res5): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pathway0_res6): X3dBottleneckBlock(\n",
       "        (_residual_add_func): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (final_act): ReLU(\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (conv_0): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_1): Conv3d3x3x3DwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=432, bias=False)\n",
       "              (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (se): SqueezeExcitation(\n",
       "              (block): Sequential(\n",
       "                (0): Conv3d(432, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(32, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (act_func_1): Swish(\n",
       "            (act): Swish()\n",
       "          )\n",
       "          (conv_2): Conv3dPwBnAct(\n",
       "            (kernel): Sequential(\n",
       "              (conv): Conv3d(432, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "              (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity(\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Sequential(\n",
       "      (conv_5): Conv3dPwBnAct(\n",
       "        (kernel): Sequential(\n",
       "          (conv): Conv3d(192, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avg_pool): AdaptiveAvgPool3dOutSize1(\n",
       "        (pool): AdaptiveAvgPool3d(output_size=1)\n",
       "      )\n",
       "      (lin_5): Conv3dPwBnAct(\n",
       "        (kernel): Sequential(\n",
       "          (conv): Conv3d(432, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (act): ReLU(\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (projection): FullyConnected(\n",
       "      (model): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "    (act): Identity(\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (fc): Linear(in_features=400, out_features=1, bias=True)\n",
       "  (metric): Accuracy()\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff3d = torch.load(\"../models/eff3d_bin.pt\")\n",
    "eff3d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e4038fded14e159c5ba7e9de61159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Label: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0]\n",
      ">> Pred: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        68\n",
      "           1       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.96      0.97        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_res = trainer.test(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.data.encoded_video import EncodedVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../data/binary-data/test/MƏN/2022-04-26 12-58-07.mp4\"\n",
    "video = EncodedVideo.from_path(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 25, 256, 256])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data = video.get_clip(0, 2)\n",
    "video_data = video_transform(video_data)\n",
    "\n",
    "inputs = video_data[\"video\"].cuda()\n",
    "inputs = inputs.unsqueeze(0)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/toghrul/SLR/sign-lang/eff3d.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(preds \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bin_idx_to_class[preds[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model(inputs).detach().cpu().numpy()\n",
    "preds = np.where(preds > 0, 1, 0)\n",
    "bin_idx_to_class[preds[0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_level_prediction(path_to_model, path_to_video):\n",
    "    model = torch.load(path_to_model)\n",
    "    video = EncodedVideo.from_path(path_to_video)\n",
    "\n",
    "    video_data = video.get_clip(0, 2)\n",
    "    # video_data = video_transform(video_data)\n",
    "\n",
    "    inputs = video_data[\"video\"].cuda()\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    \n",
    "    preds = model(inputs).detach().cpu().numpy()\n",
    "    preds = np.where(preds > 0, 1, 0)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 18.79 GiB already allocated; 98.19 MiB free; 19.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/toghrul/SLR/sign-lang/eff3d.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m word_level_prediction(\u001b[39m\"\u001b[39;49m\u001b[39m../models/eff3d_bin.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, video_path)\n",
      "\u001b[1;32m/home/toghrul/SLR/sign-lang/eff3d.ipynb Cell 40\u001b[0m in \u001b[0;36mword_level_prediction\u001b[0;34m(path_to_model, path_to_video)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m inputs \u001b[39m=\u001b[39m video_data[\u001b[39m\"\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(preds \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m preds\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/toghrul/SLR/sign-lang/eff3d.ipynb Cell 40\u001b[0m in \u001b[0;36mVideoModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo_model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/SLR/sign-lang/eff3d.ipynb#Y104sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/pytorchvideo/models/accelerator/mobile_cpu/efficient_x3d.py:160\u001b[0m, in \u001b[0;36mEfficientX3d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms1(x)\n\u001b[1;32m    159\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms2(x)\n\u001b[0;32m--> 160\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ms3(x)\n\u001b[1;32m    161\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms4(x)\n\u001b[1;32m    162\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms5(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/pytorchvideo/models/accelerator/mobile_cpu/residual_blocks.py:179\u001b[0m, in \u001b[0;36mX3dBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 179\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_residual:\n\u001b[1;32m    181\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_res_proj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/pytorchvideo/layers/accelerator/mobile_cpu/convolutions.py:300\u001b[0m, in \u001b[0;36mConv3d3x3x3DwBnAct.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 300\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(x)\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 18.79 GiB already allocated; 98.19 MiB free; 19.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "word_level_prediction(\"../models/eff3d_bin.pt\", video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_res = trainer.validate(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sign-lang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a4e4d8fc4dcb6ce321df308d690f3398dc6d289b3efb6c91f90112c618c739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
