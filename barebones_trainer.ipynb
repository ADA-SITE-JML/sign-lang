{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.nn.functional import InterpolationMode\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging\n",
    "import datetime\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_df_path = \"data_validation/processed_gloss.csv\"\n",
    "gloss_df = pd.read_csv(gloss_df_path)\n",
    "gloss_df.dropna(inplace=True)\n",
    "gloss_df.replace(to_replace=\"ASHAG\", value=\"AŞAĞI\", inplace=True)\n",
    "gloss_df['glossRange'] = gloss_df['glossEnd'] - gloss_df['glossStart']\n",
    "# gloss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(gloss_df.gloss.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler\n",
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.data import labeled_video_dataset\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomAdjustSharpness,\n",
    "    Resize\n",
    ")\n",
    "\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transform = Compose([\n",
    "    ApplyTransformToKey(key=\"video\",\n",
    "    transform=Compose([\n",
    "        UniformTemporalSubsample(25),\n",
    "        Lambda(lambda x: x/255),\n",
    "        Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "        RandomShortSideScale(min_size=224, max_size=256),\n",
    "        CenterCropVideo(224),\n",
    "    ]),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sign-lang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a4e4d8fc4dcb6ce321df308d690f3398dc6d289b3efb6c91f90112c618c739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
